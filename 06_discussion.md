# Discussion & Next Steps

The modeling results described in the last chapter highlight the nuances of model comparison. As they predict choice behavior on the sure-bet or gamble task, model 'CPUT + Softmax Sensitivity' estimated the joint posterior distribution for $\gamma$ and $\tau$ while the 'EUT + Softmax Sensitivity' model fit the joint posterior distribution for $\rho$ and $\tau$. The CPUT model seemingly offers a better explanation of *the observed data*. Indeed, the log of the Bayes Factor here is 50.2, which provides a fair amount evidence in favor of CPUT over EUT. At the same time, the ELPD and LOOIC suggest that expected utility theory is a better approximation for *unobserved choice data*. This means that if we asked a new person to complete the sure bet or gamble task, expected utility theory may better predict their data.

In thinking of these results, itâ€™s important to consider the broader context in which this work is presented. By this I mean that my goal was to develop a neurobiologically plausible theory of decision-making under risk. The culmination of that is counterfactual predicted utility theory, CPUT. On the one hand, I don't think the evidence presented here is sufficient to conclude that CPUT is a better theory of decision-making under risk than EUT. However, it seems to offer a better explanation for the data collected as part of the sure-bet or gamble task. And I think that I was able to provide evidence supporting CPUT as a generative theory of decision-making, which is exciting! 

Before concluding with future directions for investigating CPUT, I want to highlight a few things. First, an interesting case showing more complex models are not necessarily better. Referring back to Table \@ref(fig:model-fit-summary-table), you'll note that the model that best fits the observed choice data according to the marginal likelihood is the one that estimated a joint posterior distribution for $\gamma, \tau,$ and $\rho$, 'CPUT + Risk Aversion + Softmax Sensitivity.' The inclusion of the additional parameter did not improve the overall posterior predictive choice accuracy and impaired the ELPD predictive density and LOOIC. For this reason, and to avoid drawing conclusions on a (relatively, at least) overfit model, I did not pay it considerable attention here.

Second, in light of evidence supporting EUT as a fair theory of decision-making under risk, [^discussion-1] I want to highlight potential neural correlates of risk-aversion. In 2009, Chsitopoulous and colleagues reported that activity in the interior frontal gyrus, located near the dorsolateral prefrontal cortex, reflected the subjective perception of an option's riskiness but not objective evaluation of risk. Further, they describe that signals of the inferior frontal gyrus integrate with other areas, such as the striatum which was found to be sensitive to changes in magnitude, to inform choice behavior.[@christopoulos_neural_2009] 

[^discussion-1]: For this task design, at least!

On the other hand, Niv and colleagues did not find behavioral or neural evidence for risk sensitivity involving nonlinear utility functions.[@niv_neural_2012] One possibility they mention in referencing Matthew Rabin and Richard Thaler's 2001 paper on risk aversion[@matthew_rabin_anomalies_2001] is the general incompatability of nonlinear utility functions with small magnitudes.[@niv_neural_2012;] However, Rabin and Thaler assume a strict expected utility maximizer, which was not observed in our data (e.g., the softmax sensitivity parameter did not reflect deterministic choices).

To now entertain the possibility that CPUT provides a mechanistic explanation for choice behavior, as when discussing EUT, I want to focus on outstanding questions involving the potential neurobiological mechanisms. Specifically, a hitherto unanswered question from Kishida and colleagues 2016 paper[@kishida2016] surrounds the mechanism by which counterfactual prediction errors and reward prediction errors are integrated. One possibility proposed by Montague, Kishida, and colleagues is the serotonin system.[@montague_efficiency_2016] They describe an 'opponent-processing framework' where reward prediction errors and counterfactual prediction errors are independently encoded by distinct neural systems that are integrated through, as one possibility, the exchange of dopamine into predominantly serotonergic neurons and vice versa (e.g., cross-loading).[@montague_efficiency_2016; @zhou_corelease_2005] 

In 2021, Kishida and Sands proposed valence-partitioned reinforcement learning framework as part of a 'Dynamic Affective Core' that makes explicit predictions for how the dopaminergic system could interact with an opponent one and inform not only our choice behavior in situations with multi-valenced outcomes but also our associated subjective experiences and feelings.[@kishida_dynamic_2021] This valence-partitioned framework provides another basis for investigating the asymmetric choice behavior in decisions involving gains and losses.[@kahneman1979; @sokol-hessner2009] Although the neural correlates of such behavior are still under investigation, they are hypothesized to involve the striatum[@tom_neural_2007] and the amygdala, an area of the brain often associated with anxiety and fear.[@sokol-hessner_emotion_2013; @sokol-hessner_psychological_2019] 

To extend the work I presented here, I hope to incorporate the ideas of valence-partitioned reinforcement learning with the counterfactual signaling literature. Working towards my goal of developing a neurobiological theory of decision-making under risk, I will next look at how CPUT predicts choices involving losses. If CPUT's predictions generalize to both the gain and loss domain, I hope to conduct a neuroimaging study to identify the neural correlates of CPUT. Fortunately, I have a pretty good idea of where to look.
