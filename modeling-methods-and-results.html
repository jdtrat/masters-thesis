<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>6 Modeling Methods and Results | Counterfactuals, Dopamine, and Risky Behavior</title>
<meta name="author" content="Jonathan D. Trattner">
<meta name="description" content="Using the computational modeling techniques I introduced last chapter, I examined the ability of counterfactual predicted utility theory to explain human choice behavior on the sure bet or gamble...">
<meta name="generator" content="bookdown 0.25 with bs4_book()">
<meta property="og:title" content="6 Modeling Methods and Results | Counterfactuals, Dopamine, and Risky Behavior">
<meta property="og:type" content="book">
<meta property="og:url" content="https://masters-thesis.jdtrat.com/modeling-methods-and-results.html">
<meta property="og:description" content="Using the computational modeling techniques I introduced last chapter, I examined the ability of counterfactual predicted utility theory to explain human choice behavior on the sure bet or gamble...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="6 Modeling Methods and Results | Counterfactuals, Dopamine, and Risky Behavior">
<meta name="twitter:site" content="@jdtrat">
<meta name="twitter:description" content="Using the computational modeling techniques I introduced last chapter, I examined the ability of counterfactual predicted utility theory to explain human choice behavior on the sure bet or gamble...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Deriving a neurobiological theory of decision-making under risk">Counterfactuals, Dopamine, and Risky Behavior</a>:
        <small class="text-muted">Deriving a neurobiological theory of decision-making under risk</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Hello, World</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="evolution-of-decision-theory.html"><span class="header-section-number">2</span> Evolution of Decision Theory</a></li>
<li><a class="" href="neurobiology-of-decision-making.html"><span class="header-section-number">3</span> Neurobiology of Decision-Making</a></li>
<li><a class="" href="counterfactual-predicted-utility-theory.html"><span class="header-section-number">4</span> Counterfactual Predicted Utility Theory</a></li>
<li><a class="" href="computational-modeling-concepts.html"><span class="header-section-number">5</span> Computational Modeling Concepts</a></li>
<li><a class="active" href="modeling-methods-and-results.html"><span class="header-section-number">6</span> Modeling Methods and Results</a></li>
<li><a class="" href="references.html"><span class="header-section-number">7</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/jdtrat/masters-thesis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="modeling-methods-and-results" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Modeling Methods and Results<a class="anchor" aria-label="anchor" href="#modeling-methods-and-results"><i class="fas fa-link"></i></a>
</h1>
<p>Using the computational modeling techniques I introduced last chapter, I examined the ability of counterfactual predicted utility theory to explain human choice behavior on the sure bet or gamble task<span class="citation">(<a href="references.html#ref-liebenow2021" role="doc-biblioref">B. Liebenow et al. 2021</a>)</span>. To do this, I first simulated choice behavior generated from counterfactual predicted utility theory to confirm that the experimental design elicits behaviors assumed in the model.<span class="citation">(<a href="references.html#ref-wilson2019" role="doc-biblioref">Wilson and Collins 2019</a>)</span> With this confirmation, I fit variations of counterfactual predicted utility theory with and without risk-aversion parameter of expected utility theory and counterfactual predicted utility theory with that the task was able to relative to the veracity of counterfactual predicted utility theory as a generative theory of decision-making under risk. I did this by comparing the mode</p>
<p>First up is the explicit simulation and parameter recovery. In order to determine whether or not the sure bet or gamble task could capture the parameters of interest, I simulated fifty subjects</p>
<div id="simulating-choice-data" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Simulating Choice Data<a class="anchor" aria-label="anchor" href="#simulating-choice-data"><i class="fas fa-link"></i></a>
</h2>
<p>As a first step to simulate choice data on the sure-bet or gamble task, I looked at the results of Kahneman and Tversky’s prospect theory<span class="citation">(<a href="references.html#ref-kahneman1979" role="doc-biblioref">Kahneman and Tversky 1979</a>)</span> paper in search of information to inform a prior distribution. Although there is no record for each subject’s response on specific prospects, Kahneman and Tversky report the proportion of people that chose each option. For each of the nine prospects that follow the form depicted in Figures <a href="counterfactual-predicted-utility-theory.html#fig:prospect-diagram-general">4.1</a> and <a href="counterfactual-predicted-utility-theory.html#fig:prospect-diagram-kt">4.2</a>, I used the reported proportions to simulate choice behavior of one-hundred subjects.</p>
<p>I assumed that <span class="math inline">\(\gamma\)</span> was uniformly distributed between zero and one and fixed the softmax sensitivity parameter, <span class="math inline">\(\tau = 1\)</span>. I ran ten-thousand iterations using the Metropolis-Hastings algorithm described in the previous chapter. The posterior distribution, depicted in Figure <a href="modeling-methods-and-results.html#fig:kt-post-approx">6.1</a>, approximates a <span class="math inline">\(\text{Beta}(1.1,1.1)\)</span> distribution. This means that, in estimating <span class="math inline">\(\gamma\)</span> with the choice proportion data from Kahneman and Tversky, it’s plausible that <span class="math inline">\(\gamma\)</span> is any value between zero and one, though a little less likely towards the tails.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:kt-post-approx"></span>
<img src="figures/kt_post_approx_figure.png" alt="Posterior distribution of $\gamma$ as estimated from ten-thousand iterations of a Metropolis-Hastings algorithm assuming a uniform prior with choice proportion data from Kahneman and Tversyk's prospect theory[@kahneman1979]. This posterior distribution (orange-red line) is approximated with a $\text{Beta}(1.1,1.1)$ distribution (blue-gray), indicating slightly less plausibility to $\gamma$ values near the bounds of the zero-to-one interval relative to central values." width="95%"><p class="caption">
Figure 6.1: Posterior distribution of <span class="math inline">\(\gamma\)</span> as estimated from ten-thousand iterations of a Metropolis-Hastings algorithm assuming a uniform prior with choice proportion data from Kahneman and Tversyk’s prospect theory<span class="citation">(<a href="references.html#ref-kahneman1979" role="doc-biblioref">Kahneman and Tversky 1979</a>)</span>. This posterior distribution (orange-red line) is approximated with a <span class="math inline">\(\text{Beta}(1.1,1.1)\)</span> distribution (blue-gray), indicating slightly less plausibility to <span class="math inline">\(\gamma\)</span> values near the bounds of the zero-to-one interval relative to central values.
</p>
</div>
<p>Given the task design, participants saw a random subset of 252 prospects. The posterior distribution for <span class="math inline">\(\gamma\)</span> recovered from Kahneman and Tversky’s choice proportion data was used to generate <span class="math inline">\(\gamma\)</span> values for fifty subjects. I then simulated their choices on each of the 252 prospects, again fixing the softmax sensitivity parameter <span class="math inline">\(\tau = 1\)</span>. For five-thousand iterations of the Metropolis-Hastings algorithm, I sampled from the posterior distribution for each simulated subject.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Although I simulated participants’ counterfactual weighting term following the posterior from Kahneman and Tversky’s choice proportion data, &lt;span class="math inline"&gt;\(\gamma \sim \text{Beta}(1.1,1.1)\)&lt;/span&gt;, I used a uniform prior again when sampling from the Metropolis-Hastings algorithm for optimizing my analytical workflow. I felt this was justified because &lt;span class="math inline"&gt;\(\text{Beta}(1.1,1.1)\)&lt;/span&gt; is (relatively) uninformative prior and the decision would not have a large impact on the recoverability of parameter values (with the possible exception of model fitting time). Further, I wanted to maintain consistency with the uniform distribution of the individual-level priors defined in the hierarchical Bayesian model with the inverse Probit transformation.&lt;span class="citation"&gt;(&lt;a href="references.html#ref-ahn2014" role="doc-biblioref"&gt;Ahn et al. 2014&lt;/a&gt;; &lt;a href="references.html#ref-ahn2017" role="doc-biblioref"&gt;Ahn, Haines, and Zhang 2017&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>7</sup></a> With the same simulated choice data, I also fit a hierarchical Bayesian model in Stan with the non-centered reparameterization as described in the last chapter. I ran the Hamiltonian Monte Carlo (Stan) sampler for 5000 iterations across four parallel sampling chains for a total of 20,000 samples from the posterior.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;I included a warmup of 2000 iterations, during which time the Hamiltonian Monte Carlo sampling algorithm was tuned to improve efficiency when sampling from the posterior distribution. See &lt;a href="https://mc-stan.org/docs/2_29/cmdstan-guide/mcmc-config.html"&gt;Chapter 9 of the CmdStan User’s Guide&lt;/a&gt; for more information on ‘MCMC Sampling using Hamiltonian Monte Carlo’&lt;span class="citation"&gt;(&lt;a href="references.html#ref-standevelopmentteam2022" role="doc-biblioref"&gt;Stan Development Team 2022&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>8</sup></a> Figure <a href="modeling-methods-and-results.html#fig:sbg-sim-parameter-recovery">6.2</a> shows the 95% highest density interval recovered from each sampler’s posterior distribution.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sbg-sim-parameter-recovery"></span>
<img src="figures/sbg_sim_parameter_recovery_figure.png" alt="95% highest density interval of the posterior distribution of $\gamma$ as estimated from five-thousand iterations of a Metropolis-Hastings algorithm and five-thousand iterations across four parallel chains with the Hamiltonian Monte Carlo Sampler (estimated using Stan[@standevelopmentteam2022]). The simulated gamma values for each subject are represented as sky-blue dots if they fall within the 95% highest density interval and red dots if they fall outside of it." width="95%"><p class="caption">
Figure 6.2: 95% highest density interval of the posterior distribution of <span class="math inline">\(\gamma\)</span> as estimated from five-thousand iterations of a Metropolis-Hastings algorithm and five-thousand iterations across four parallel chains with the Hamiltonian Monte Carlo Sampler (estimated using Stan<span class="citation">(<a href="references.html#ref-standevelopmentteam2022" role="doc-biblioref">Stan Development Team 2022</a>)</span>). The simulated gamma values for each subject are represented as sky-blue dots if they fall within the 95% highest density interval and red dots if they fall outside of it.
</p>
</div>
<p>For most subjects, the simulated <span class="math inline">\(\gamma\)</span> values are within the highest-density interval. This suggests that the sure-bet or gamble task is able to elicit the behaviors of interest in a way measurable with counterfactual predicted utility theory.</p>
</div>
<div id="parameter-estimation" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Parameter Estimation<a class="anchor" aria-label="anchor" href="#parameter-estimation"><i class="fas fa-link"></i></a>
</h2>
<p>With the confirmation that I am able to accurately recover simulated parameters from the sure-bet or gamble task, I move on to the next stage of computational modeling, parameter estimation. Specifically, I compare how counterfactual predicted utility theory explains the human choice data from the sure-bet or gamble task relative to expected utility theory. I primarily do this for two reasons:</p>
<ol style="list-style-type: decimal">
<li>Counterfactual predicted utility theory suggests that, if <span class="math inline">\(\gamma = 0\)</span>, the counterfactual utility of an option is equivalent to the expected value. The expected value is a special case of expected utility theory where the risk aversion parameter, <span class="math inline">\(\rho = 1\)</span>.</li>
<li>The sure-bet or gamble task does not include losses, which prohibits me from comparing counterfactual predicted utility theory to prospect theory.</li>
</ol>
<p>In total, I estimated parameters for seven variants of expected utility theory and counterfactual utility theory on the human choice data (Table <a href="modeling-methods-and-results.html#fig:model-definition-table">6.3</a>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:model-definition-table"></span>
<img src="figures/model_definition_table.png" alt="Parameters for, and description of, the different models fit on human choice data from the sure-bet or gamble task. All models were sampled with Stan for 5000 iterations across four parallel chains using a hierarchical implementation.[@ahn2017] Individual parameters were drawn from a normally distributed group-level distribution and bounded with an inverse Probit transformation resulting in a uniform prior spanning from zero to one $(\gamma)$, two $(\rho)$, and thirty $(\tau)$." width="95%"><p class="caption">
Figure 6.3: Parameters for, and description of, the different models fit on human choice data from the sure-bet or gamble task. All models were sampled with Stan for 5000 iterations across four parallel chains using a hierarchical implementation.<span class="citation">(<a href="references.html#ref-ahn2017" role="doc-biblioref">Ahn, Haines, and Zhang 2017</a>)</span> Individual parameters were drawn from a normally distributed group-level distribution and bounded with an inverse Probit transformation resulting in a uniform prior spanning from zero to one <span class="math inline">\((\gamma)\)</span>, two <span class="math inline">\((\rho)\)</span>, and thirty <span class="math inline">\((\tau)\)</span>.
</p>
</div>
<p>All models were sampled for 5000 iterations across four parallel chains with the hierarchical Bayesian model formulation previously described.<span class="citation">(<a href="references.html#ref-ahn2017" role="doc-biblioref">Ahn, Haines, and Zhang 2017</a>)</span> For each model, chain convergence for group-level and transformed individual-level parameters was checked with Gelman-Rubin statistics, <span class="math inline">\(\hat{R} \leq 1.1\)</span>, suggesting between-chain variance is lower than within chain variance.<span class="citation">(<a href="references.html#ref-gelman1992" role="doc-biblioref">Gelman and Rubin 1992</a>)</span> A histogram representing samples from the population level posterior distribution for each parameter per model is shown in Figure <a href="modeling-methods-and-results.html#fig:population-level-post-param-figure">6.4</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:population-level-post-param-figure"></span>
<img src="05_modeling_results_files/figure-html/population-level-post-param-figure-1.png" alt="Placeholder caption." width="672"><p class="caption">
Figure 6.4: Placeholder caption.
</p>
</div>
</div>
<div id="model-comparison" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Model Comparison<a class="anchor" aria-label="anchor" href="#model-comparison"><i class="fas fa-link"></i></a>
</h2>
<p>With the estimated posterior distributions for each model type, I sought to determine which model best explains choice behavior. To do this, I used three different methods to compare models, the results of which are summarized in Table <a href="modeling-methods-and-results.html#fig:model-fit-summary-table">6.5</a>:</p>
<ol style="list-style-type: decimal">
<li><p>Posterior predictive checks where, for each model, I simulated choices given the (joint) posterior distribution of each participants’ estimated model parameter(s). This was included in Stan’s generated quantities block, which is only executed after a posterior sample has been generated. <span class="citation">(<a href="references.html#ref-standevelopmentteam2022" role="doc-biblioref">Stan Development Team 2022</a>)</span> I then compared the percentage of predicted choices that matches the observed data and summarized the mean and standard deviation for each model.</p></li>
<li><p>Comparing the marginal likelihoods of each model. This is the probability of observing the choice behavior for a given model, <span class="math inline">\(M\)</span>, <span class="math inline">\(P(\text{Choices}|M)\)</span>. The marginal likelihood of each model was estimated using bridge sampling.<span class="citation">(<a href="references.html#ref-gronau2020" role="doc-biblioref">Gronau, Singmann, and Wagenmakers 2020</a>)</span> Marginal likelihoods are often included in calculations of Bayes factors, which describes the relative evidence in favor of one model over another by quantifying the ratio between the probability of observing the data given two models. The marginal likelihoods are computed as log-scaled for computational efficiency, which means that the more positive, or less negative, marginal likelihood indicates a better fit.</p></li>
<li><p>Assessing penalized model fit with each model’s leave-one-out cross validation predictive accuracy.<span class="citation">(<a href="references.html#ref-vehtari2017" role="doc-biblioref">Vehtari, Gelman, and Gabry 2017</a>)</span> This is approximated with importance sampling of the posterior distribution to calculate the expected log pointwise predictive density (ELPD), which is the logged sum of pointwise posterior predictive distribution for held out data. By multiplying the ELPD by negative two, we get the leave-one-out information criterion, LOOIC. This transformation makes it easier to compare with other information criterion (e.g., AIC, DIC), highlighting the penalization of model complexity.<span class="citation">(<a href="references.html#ref-plummer2008" role="doc-biblioref">Plummer 2008</a>)</span> I include both ELPD and LOOIC for easy comparison. Note that a less negative ELPD and a smaller (closer to zero) LOOIC are indicative of better model fits.</p></li>
</ol>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:model-fit-summary-table"></span>
<img src="figures/model_fit_summary_table.png" alt="Parameters for, and description of, the different models fit on human choice data from the sure-bet or gamble task along with model comparison metrics. Posterior predictive choice accuracy represents the mean and standard deviation of correctly predicted choices for individual participants given simulations from the (joint) posterior distribution. ELPD Predictive Density and LOOIC details how well models perform on unobserved data (leave-one-out cross validation). Parantheses for ELPD and LOOIC indicate Monte Carlo sampling error. Marginal likelihood model evidence indicates the plausibility of the data given each model with parantheses representing the interquartile range of the likeihood estimations. In general, better models have smaller LOOIC and higher posterior predictive choice accuracy, ELPD predictive accuracy (less negative), and marginal likelihood model evidence (less negative). CPUT + Softmax Sensitivity and EUT + Softmax Sensitivity are highlighted for easy reference when discussed." width="95%"><p class="caption">
Figure 6.5: Parameters for, and description of, the different models fit on human choice data from the sure-bet or gamble task along with model comparison metrics. Posterior predictive choice accuracy represents the mean and standard deviation of correctly predicted choices for individual participants given simulations from the (joint) posterior distribution. ELPD Predictive Density and LOOIC details how well models perform on unobserved data (leave-one-out cross validation). Parantheses for ELPD and LOOIC indicate Monte Carlo sampling error. Marginal likelihood model evidence indicates the plausibility of the data given each model with parantheses representing the interquartile range of the likeihood estimations. In general, better models have smaller LOOIC and higher posterior predictive choice accuracy, ELPD predictive accuracy (less negative), and marginal likelihood model evidence (less negative). CPUT + Softmax Sensitivity and EUT + Softmax Sensitivity are highlighted for easy reference when discussed.
</p>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="computational-modeling-concepts.html"><span class="header-section-number">5</span> Computational Modeling Concepts</a></div>
<div class="next"><a href="references.html"><span class="header-section-number">7</span> References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#modeling-methods-and-results"><span class="header-section-number">6</span> Modeling Methods and Results</a></li>
<li><a class="nav-link" href="#simulating-choice-data"><span class="header-section-number">6.1</span> Simulating Choice Data</a></li>
<li><a class="nav-link" href="#parameter-estimation"><span class="header-section-number">6.2</span> Parameter Estimation</a></li>
<li><a class="nav-link" href="#model-comparison"><span class="header-section-number">6.3</span> Model Comparison</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/jdtrat/masters-thesis/blob/main/thesis-documents/05_modeling_results.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/jdtrat/masters-thesis/edit/main/thesis-documents/05_modeling_results.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Counterfactuals, Dopamine, and Risky Behavior</strong>: Deriving a neurobiological theory of decision-making under risk" was written by Jonathan D. Trattner. It was last built on 2022-04-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
