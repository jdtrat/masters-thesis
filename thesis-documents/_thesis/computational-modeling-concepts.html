<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>7 Computational Modeling Concepts | Counterfactuals, Dopamine, and Risky Behavior</title>
<meta name="author" content="Jonathan D. Trattner">
<meta name="description" content="In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper Ten simple rules for the...">
<meta name="generator" content="bookdown 0.25 with bs4_book()">
<meta property="og:title" content="7 Computational Modeling Concepts | Counterfactuals, Dopamine, and Risky Behavior">
<meta property="og:type" content="book">
<meta property="og:url" content="https://masters-thesis.jdtrat.com/computational-modeling-concepts.html">
<meta property="og:description" content="In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper Ten simple rules for the...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="7 Computational Modeling Concepts | Counterfactuals, Dopamine, and Risky Behavior">
<meta name="twitter:site" content="@jdtrat">
<meta name="twitter:description" content="In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper Ten simple rules for the...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Deriving a neurobiological theory of decision-making under risk">Counterfactuals, Dopamine, and Risky Behavior</a>:
        <small class="text-muted">Deriving a neurobiological theory of decision-making under risk</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Dedication and Acknowledgements</a></li>
<li><a class="" href="abstract.html"><span class="header-section-number">2</span> Abstract</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">3</span> Introduction</a></li>
<li><a class="" href="evolution-of-decision-theory.html"><span class="header-section-number">4</span> Evolution of Decision Theory</a></li>
<li><a class="" href="neurobiology-of-decision-making.html"><span class="header-section-number">5</span> Neurobiology of Decision-Making</a></li>
<li><a class="" href="counterfactual-predicted-utility-theory.html"><span class="header-section-number">6</span> Counterfactual Predicted Utility Theory</a></li>
<li><a class="active" href="computational-modeling-concepts.html"><span class="header-section-number">7</span> Computational Modeling Concepts</a></li>
<li><a class="" href="modeling-methods-and-results.html"><span class="header-section-number">8</span> Modeling Methods and Results</a></li>
<li><a class="" href="discussion-next-steps.html"><span class="header-section-number">9</span> Discussion &amp; Next Steps</a></li>
<li><a class="" href="references.html"><span class="header-section-number">10</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/jdtrat/masters-thesis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="computational-modeling-concepts" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> Computational Modeling Concepts<a class="anchor" aria-label="anchor" href="#computational-modeling-concepts"><i class="fas fa-link"></i></a>
</h1>
<p>In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper <em>Ten simple rules for the computational modeling of behavioral data</em>.<span class="citation"><sup>[<a href="references.html#ref-wilson2019" role="doc-biblioref">38</a>]</sup></span>At a high level, they state that computational modeling allows us to make better sense of behavioral data with mathematical models that may provide insight into mechanisms underlying behavior. Although the exact form of the models differ, the basic steps to assess a model’s descriptive and predictive efficacy are similar.</p>
<p>The first two steps Wilson and Collins discuss are designing an experiment and developing a model. For my thesis, I fit CPUT with data collected from an ongoing study by Brittany Liebenow and colleagues<span class="citation"><sup>[<a href="references.html#ref-liebenow2021" role="doc-biblioref">37</a>]</sup></span> where forty-five healthy adults (ages 18-65) were recruited to complete a sure-bet or gamble task (Figure <a href="computational-modeling-concepts.html#fig:sborg-task-description">7.1</a>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sborg-task-description"></span>
<img src="figures/sborg_task-diagram.png" alt="Schematic of a trial from the Sure Bet or Gamble task and subjective rating prompt. A prospect is presented for a random duration based on a Poisson distribution $(\lambda = 6\text{s})$. Assuming a timely response, a choice screen was shown for two seconds followed by an outcome screen for one second. Trials were separated with a fixation cross whose inter-trial interval was a random duration from a Poisson distribution with $\lambda = 3\text{s}$." width="95%"><p class="caption">
Figure 7.1: Schematic of a trial from the Sure Bet or Gamble task and subjective rating prompt. A prospect is presented for a random duration based on a Poisson distribution <span class="math inline">\((\lambda = 6\text{s})\)</span>. Assuming a timely response, a choice screen was shown for two seconds followed by an outcome screen for one second. Trials were separated with a fixation cross whose inter-trial interval was a random duration from a Poisson distribution with <span class="math inline">\(\lambda = 3\text{s}\)</span>.
</p>
</div>
<p>For thirty minutes, participants indicated their preference for a sure bet (values between $1-$6 in $1 increments) or a fifty-fifty gamble between two non-identical values ($0 - $6 in $1 increments). The lateral presentation of the sure bet and gambles were randomized, and each prospect was presented for a random duration based on a Poisson distribution <span class="math inline">\((\lambda = 6\text{s})\)</span>. If the participant answered within the alloted time, their choice was displayed for two seconds before they were shown the outcome for one second. If they did not answer in time, they were shown a late screen for one second. Rounds were separated with a fixation cross whose inter-trial interval was a Poisson distribution <span class="math inline">\((\lambda = 6\text{s}\)</span>, zeros removed<span class="math inline">\()\)</span>. After one-third of of the rounds where choices were made, respondents were asked “How do you feel about the last outcome?” and adjusted a slider ranging from ‘very bad’ to ‘very good.’ Participants were paid $20 per hour and told they would receive winnings from a randomly selected round as bonus compensation.</p>
<p>Using this data from this task, we can group the remaining computational modeling steps into three stages:<span class="citation"><sup>[<a href="references.html#ref-wilson2019" role="doc-biblioref">38</a>]</sup></span></p>
<ul>
<li><p><strong>Simulation &amp; Parameter Recovery</strong>: Use the candidate model (CPUT) to generate ‘fake’ behavioral data and attempt to recover the parameters of interest following the proposed analysis method for experimental data.</p></li>
<li><p><strong>Parameter Estimation:</strong> Find the set of parameters that best account for the experimental data given the candidate model.</p></li>
<li><p><strong>Model Comparison:</strong> Compare the candidate models to others (EUT) that may provide alternative explanations of the behavioral data.</p></li>
</ul>
<p>Before detailing the methods and results for each stage in my analysis, it is important to understand the mathematics behind our model-fitting. In the general case, when estimating a model’s parameters for a decision-making task, we want to know what parameter(s) best explain the observed choices. For tasks with two outcomes, this can be represented as a binary choice vector where a choice for an option is indicated as a 1 if chosen and a 0 if not.</p>
<span class="math display">\[\begin{equation*}
\begin{split}
\text{Chose Option 1} =
    \begin{bmatrix}
    1 \\
    1 \\
    1 \\
    0 \\
    1 \\
    0
\end{bmatrix}
\end{split}
\qquad
\begin{split}
\text{Chose Option 2} =
    \begin{bmatrix}
    0 \\
    0 \\
    0 \\
    1 \\
    0 \\
    1
    \end{bmatrix} 
\end{split}
\end{equation*}\]</span>
<p>Consider the prospect depicted in Figure <a href="computational-modeling-concepts.html#fig:sborg-task-description">7.1</a>. Given the stated outcomes and probabilities, we can calculate the counterfactual utilities for each option for any <span class="math inline">\(\gamma\)</span> value according to Equations <a href="counterfactual-predicted-utility-theory.html#eq:calculating-uc">(6.2)</a> and <a href="counterfactual-predicted-utility-theory.html#eq:eut-cput-transformations">(6.4)</a>. For <span class="math inline">\(0 \leq \gamma \leq 0.5\)</span>, we can see the utilities of the sure bet option ($3) and the gamble (50% chance of $2 or $5) in Figure <a href="computational-modeling-concepts.html#fig:sbg-demo-gamma-range">7.2</a>). From this, we might assume that people that place low weight on counterfactual information would more often choose the gamble. At some point (here when <span class="math inline">\(\gamma \approx 0.16\)</span>), an individual is equally likely to choose either option. As people place more weight on counterfactual information, they are more likely to choose the sure bet for this prospect.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sbg-demo-gamma-range"></span>
<img src="figures/sbg_demo_figure.png" alt="Counterfactual utilities for a sample prospect from the sure bet or gamble task simulated for $0 \leq \gamma \leq 0.5$. Blue line represents the counterfactual utility of choosing the 'Sure Bet' and receiving three dollars; red line represents the counterfactual utility of choosing the 'Gamble' and having a 50 percent chance of receiving two dollars or five dollars. The 'indifference' point of choosing one option over the other occurs when $\gamma \approx 0.16$." width="95%"><p class="caption">
Figure 7.2: Counterfactual utilities for a sample prospect from the sure bet or gamble task simulated for <span class="math inline">\(0 \leq \gamma \leq 0.5\)</span>. Blue line represents the counterfactual utility of choosing the ‘Sure Bet’ and receiving three dollars; red line represents the counterfactual utility of choosing the ‘Gamble’ and having a 50 percent chance of receiving two dollars or five dollars. The ‘indifference’ point of choosing one option over the other occurs when <span class="math inline">\(\gamma \approx 0.16\)</span>.
</p>
</div>
<p>Although we can determine the utility of each option, we only have peoples’ choice behavior from which to fit the model. This means that we need to determine what the most likely parameter value that would give us the observed data. To help answer this question, I looked towards Bayesian statistics, which offers a way to incorporate <em>prior</em> information about parameters in a statistical model with observed data to define a <em>posterior</em> probability distribution representing the most plausible parameter values.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;For excellent resources on Bayesian statistics, I highly recommend the textbooks &lt;em&gt;Statistical Rethinking: A Bayesian Course with Examples in R and Stan&lt;/em&gt; by Richard McElreath&lt;span class="citation"&gt;&lt;sup&gt;[&lt;a href="references.html#ref-richardmcelreath2020" role="doc-biblioref"&gt;39&lt;/a&gt;]&lt;/sup&gt;&lt;/span&gt; and &lt;em&gt;Bayes Rules! An Introduction to Applied Bayesian Modeling&lt;/em&gt; by Alicia A. Johnson, Miles Q. Ott, and Mine Dogucu.&lt;span class="citation"&gt;&lt;sup&gt;[&lt;a href="references.html#ref-dogucu" role="doc-biblioref"&gt;40&lt;/a&gt;]&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;'><sup>7</sup></a></p>
<p>The first step in performing Bayesian inference is to construct a <em>prior</em> probability model for our parameters of interest. Because I end up fitting multiple models (e.g., perform model comparison), I will outline the procedure here in the general case using <span class="math inline">\(\theta\)</span> to represent a given model’s parameters. Our prior probability model, <span class="math inline">\(\pi(\theta)\)</span> contains available information about a parameter’s distribution before observing any data. This information could come from, for example, previous experiments. If no information is available, we might assume a uniform prior distribution, which assigns equal probability to all values within the defined range.</p>
<p>The next step in Bayesian inference involves calculating the <em>likelihood</em> of observing data given a set of parameters, <span class="math inline">\(\theta\)</span>. For my analysis, I focused on the likelihood that an individual chose Option 1 (the sure bet), which we represent as follows:</p>
<span class="math display" id="eq:likelihood">\[\begin{equation}
L(\text{Chose Option 1}|\theta)
\tag{7.1}
\end{equation}\]</span>
<p>To translate binary choice behavior to a likelihood, we need a way of relating an option’s utilities into a probability. This can be done with a softmax choice rule, a logistic transformation of the difference in utilities for each option:<span class="citation"><sup>[<a href="references.html#ref-sokol-hessner2009" role="doc-biblioref">41</a>]</sup></span></p>
<span class="math display" id="eq:softmax-choose-1">\[\begin{equation}
P(\text{Chose Option 1}) = \frac{1}{1 + e^{(-\tau \cdot (U_1 - U_2))}}
\tag{7.2}
\end{equation}\]</span>
<p>where <span class="math inline">\(U_1, U_2\)</span> are the utilities (according to the proposed model such as CPUT or EUT), and <span class="math inline">\(\tau &gt; 0\)</span> is a sensitivity parameter that relates how sensitive one’s choice is to a difference in utilities. To complement Figure <a href="computational-modeling-concepts.html#fig:sbg-demo-gamma-range">7.2</a>, we can see how the probability of choosing the sure bet changes as <span class="math inline">\(\gamma\)</span> (and subsequently the utility of Option 1) increases:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sbg-demo-softmax-figure"></span>
<img src="figures/sbg_demo_softmax_figure.png" alt="Probability of choosing Option 1 ('Sure Bet') calculated by a logistic transformation of the difference in utilities for the counterfactual utilities of each option as shown in Figure \@ref(fig:sbg-demo-gamma-range) across $0 \leq \gamma \leq 0.5$. As  $\tau$ increases, individuals are more likely to maximize utility. Note that the 'indifference' point of choosing one option over the other occurs when $\gamma \approx 0.16$, regardless of $\tau$." width="95%"><p class="caption">
Figure 7.3: Probability of choosing Option 1 (‘Sure Bet’) calculated by a logistic transformation of the difference in utilities for the counterfactual utilities of each option as shown in Figure <a href="computational-modeling-concepts.html#fig:sbg-demo-gamma-range">7.2</a> across <span class="math inline">\(0 \leq \gamma \leq 0.5\)</span>. As <span class="math inline">\(\tau\)</span> increases, individuals are more likely to maximize utility. Note that the ‘indifference’ point of choosing one option over the other occurs when <span class="math inline">\(\gamma \approx 0.16\)</span>, regardless of <span class="math inline">\(\tau\)</span>.
</p>
</div>
<p>The third step in Bayesian inference is to generate the posterior distribution, <span class="math inline">\(Pr(\theta|\text{Choices})\)</span>, which represents the range most likely range of parameter values given the observed choices. In terms of our analysis, the posterior distribution is defined as follows:</p>
<span class="math display" id="eq:posterior-propto">\[\begin{equation}
Pr(\theta|\text{Choices}) \propto L(\text{Chose Option 1}|\theta) \times \pi(\theta)
\tag{7.3}
\end{equation}\]</span>
<p>Where the probability of <span class="math inline">\(\theta\)</span> being some value given the observed choice data, our posterior distribution <span class="math inline">\(Pr(\theta|\text{Choices})\)</span>, is <em>proportional to</em><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Note that this is a form of Bayes’ theorem that excludes the marginal likelihood of the data – that is, the total probability of observing the data – which acts as a normalizing constant to ensure the posterior distribution is a valid probability density function. For more details on this ‘posterior shortcut,’ see section 2.3.6 of &lt;em&gt;Bayes Rules!&lt;/em&gt;.&lt;span class="citation"&gt;&lt;sup&gt;[&lt;a href="references.html#ref-dogucu" role="doc-biblioref"&gt;40&lt;/a&gt;]&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;'><sup>8</sup></a> the likelihood of observing that data given that parameter value, <span class="math inline">\(L(\text{Chose Option 1}|\theta)\)</span>, times the prior plausibility of the parameter being that value, <span class="math inline">\(\pi(\theta)\)</span>.</p>
<p>To estimate the posterior distribution, I used two ‘Markov Chain Monte Carlo’ methods. For my first attempt, I manually implemented the Metropolis-Hastings algorithm.<span class="citation"><sup>[<a href="references.html#ref-dogucu" role="doc-biblioref">40</a>,<a href="references.html#ref-haines2018" role="doc-biblioref">42</a>]</sup></span> At a high level, the Metropolis-Hastings algorithm involves the following steps:</p>
<p>For iteration <span class="math inline">\(n \in 1:N\)</span> do the following:</p>
<ol style="list-style-type: decimal">
<li>Propose a value, <span class="math inline">\(\theta_n^*\)</span> near the current estimate <span class="math inline">\(\theta_n\)</span>, propose a value <span class="math inline">\(\theta^*\)</span>
</li>
<li>Calculate the acceptance probability for proposal <span class="math inline">\(\theta_n^*\)</span> defined as the ratio between the posterior distribution evaluated at <span class="math inline">\(\theta_n^*\)</span> to that of <span class="math inline">\(\theta_n\)</span>
</li>
<li>Draw a random number between zero and one. If it is less than or equal to the acceptance probability, set <span class="math inline">\(\theta_{n+1} = \theta_n^*\)</span>, otherwise <span class="math inline">\(\theta_{n+1} = \theta_n\)</span>.</li>
</ol>
<p>I then validated my implementation by comparing it to posterior distributions computed with a hierarchical Bayesian approach. Hierarchical Bayesian Analysis was implemented in the probabilistic programming language, Stan, which implements an efficient variant of Markov Chain Monte Carlo called the Hamiltonian Monte Carlo sampler.<span class="citation"><sup>[<a href="references.html#ref-standevelopmentteam2022" role="doc-biblioref">43</a>]</sup></span> Hierarchical Bayesian Analysis allows for simultaneous estimation of individual and group-level parameters in a mutually-constraining fashion. This has been shown to improve parameter estimates relative to other methods (e.g., maximum likelihood estimation), resulting in more stable and reliable estimates for individual-level parameters as they are informed by group trends.<span class="citation"><sup>[<a href="references.html#ref-ahn2011" role="doc-biblioref">44</a>]</sup></span></p>
<p>The specific implementation of hierarchical models I follow has been detailed elsewhere.<span class="citation"><sup>[<a href="references.html#ref-ahn2017" role="doc-biblioref">45</a>]</sup></span> At a high level, individual-participant parameters are assumed to be drawn from normally distributed group-level distributions. Bounded parameters, such as <span class="math inline">\(\gamma\)</span>, were estimated in an unconstrained space and transformed with the ‘Matt Trick,’<span class="citation"><sup>[<a href="references.html#ref-standevelopmentteam2022" role="doc-biblioref">43</a>]</sup></span> an inverse Probit transformation. This is to optimize the MCMC sampling.<span class="citation"><sup>[<a href="references.html#ref-ahn2017" role="doc-biblioref">45</a>]</sup></span> More formally,</p>
<span class="math display" id="eq:matt-trick">\[\begin{equation}
\begin{aligned}
\mu_\theta &amp;\sim \text{Normal}(0,1) \\
\sigma_\theta &amp;\sim \text{Half-Normal}(0,0.2) \\
\mathbf{\theta}^\prime &amp;\sim \text{Normal}(0,1) \\
\mathbf{\theta} &amp;\sim \text{Probit}^{-1}(\mu_\theta + \sigma_\theta \cdot \mathbf{\theta}^\prime) \times U.B.
\end{aligned}
\tag{7.4}
\end{equation}\]</span>
<p>where <span class="math inline">\(- \infty &lt; \mu_\theta &lt; + \infty\)</span> and <span class="math inline">\(- \infty &lt; \sigma_\theta &lt; + \infty\)</span> are the group-level mean and standard deviation, respectively; <span class="math inline">\(\theta^\prime\)</span> is the unconstrained parameter that gets transformed via the inverse Probit transformation and scaled to some upper bound, <span class="math inline">\(U.B\)</span>. As an example, for <span class="math inline">\(\gamma\)</span>, <span class="math inline">\(U.B. = 1\)</span>; for <span class="math inline">\(\tau\)</span>, <span class="math inline">\(U.B. = 30\)</span>. This non-centered reparameterization results in a uniform prior for individual participants’ parameters across the full range.<span class="citation"><sup>[<a href="references.html#ref-ahn2017" role="doc-biblioref">45</a>,<a href="references.html#ref-ahn2014" role="doc-biblioref">46</a>]</sup></span></p>
<p>With a better grasp of the concepts I employed for my thesis, it’s time to revisit each of the three stages of computational modeling I introduced in the chapter introduction.<span class="citation"><sup>[<a href="references.html#ref-wilson2019" role="doc-biblioref">38</a>]</sup></span> In the next chapter, I outline my methods and results from simulating choice data according to counterfactual predicted utility theory, estimating parameters from observed data, and comparing evidence from seven candidate models.</p>

</div>

  <div class="chapter-nav">
<div class="prev"><a href="counterfactual-predicted-utility-theory.html"><span class="header-section-number">6</span> Counterfactual Predicted Utility Theory</a></div>
<div class="next"><a href="modeling-methods-and-results.html"><span class="header-section-number">8</span> Modeling Methods and Results</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#computational-modeling-concepts"><span class="header-section-number">7</span> Computational Modeling Concepts</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/jdtrat/masters-thesis/blob/main/thesis-documents/04_modeling.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/jdtrat/masters-thesis/edit/main/thesis-documents/04_modeling.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Counterfactuals, Dopamine, and Risky Behavior</strong>: Deriving a neurobiological theory of decision-making under risk" was written by Jonathan D. Trattner. It was last built on 2022-04-13.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
