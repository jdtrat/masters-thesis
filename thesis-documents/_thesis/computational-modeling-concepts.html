<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>7 Computational Modeling Concepts | Counterfactuals, Dopamine, and Risky Behavior</title>
<meta name="author" content="Jonathan D. Trattner">
<meta name="description" content="In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper Ten simple rules for the...">
<meta name="generator" content="bookdown 0.25 with bs4_book()">
<meta property="og:title" content="7 Computational Modeling Concepts | Counterfactuals, Dopamine, and Risky Behavior">
<meta property="og:type" content="book">
<meta property="og:url" content="https://masters-thesis.jdtrat.com/computational-modeling-concepts.html">
<meta property="og:description" content="In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper Ten simple rules for the...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="7 Computational Modeling Concepts | Counterfactuals, Dopamine, and Risky Behavior">
<meta name="twitter:site" content="@jdtrat">
<meta name="twitter:description" content="In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper Ten simple rules for the...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Deriving a neurobiological theory of decision-making under risk">Counterfactuals, Dopamine, and Risky Behavior</a>:
        <small class="text-muted">Deriving a neurobiological theory of decision-making under risk</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Dedication and Acknowledgements</a></li>
<li><a class="" href="abstract.html"><span class="header-section-number">2</span> Abstract</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">3</span> Introduction</a></li>
<li><a class="" href="evolution-of-decision-theory.html"><span class="header-section-number">4</span> Evolution of Decision Theory</a></li>
<li><a class="" href="neurobiology-of-decision-making.html"><span class="header-section-number">5</span> Neurobiology of Decision-Making</a></li>
<li><a class="" href="counterfactual-predicted-utility-theory.html"><span class="header-section-number">6</span> Counterfactual Predicted Utility Theory</a></li>
<li><a class="active" href="computational-modeling-concepts.html"><span class="header-section-number">7</span> Computational Modeling Concepts</a></li>
<li><a class="" href="computational-modeling-methods-and-results.html"><span class="header-section-number">8</span> Computational Modeling Methods and Results</a></li>
<li><a class="" href="discussion-next-steps.html"><span class="header-section-number">9</span> Discussion &amp; Next Steps</a></li>
<li><a class="" href="references.html"><span class="header-section-number">10</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/jdtrat/masters-thesis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="computational-modeling-concepts" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> Computational Modeling Concepts<a class="anchor" aria-label="anchor" href="#computational-modeling-concepts"><i class="fas fa-link"></i></a>
</h1>
<p>In an attempt to robustly, and transparently, fit CPUT to behavioral data, I follow the general guidelines presented in Robert Wilson and Anne Collins’s paper <em>Ten simple rules for the computational modeling of behavioral data</em>.<span class="citation"><sup>[<a href="references.html#ref-wilson2019" role="doc-biblioref">36</a>]</sup></span>At a high level, they state that computational modeling allows us to make better sense of behavioral data with mathematical models that may provide insight into mechanisms underlying behavior. Although the exact form of the models may differ, the basic process of assessing a model’s descriptive and predictive efficacy are similar.</p>
<p>The first two steps Wilson and Collins discuss are designing an experiment and developing a model. For my thesis, I fit CPUT with data collected from an ongoing study by Brittany Liebenow and colleagues<span class="citation"><sup>[<a href="references.html#ref-liebenow2021" role="doc-biblioref">35</a>]</sup></span> where forty-five healthy adults (ages 18-65) were recruited to complete a sure-bet or gamble task (Figure <a href="computational-modeling-concepts.html#fig:sborg-task-description">7.1</a>).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sborg-task-description"></span>
<img src="figures/sborg_task-diagram.png" alt="Schematic of a trial from the Sure Bet or Gamble task and subjective rating prompt. A prospect is presented for a random duration based on a Poisson distribution $(\lambda = 6\text{s})$. Assuming a timely response, a choice screen was shown for two seconds followed by an outcome screen for one second. Trials were separated with a fixation cross whose inter-trial interval was a random duration from a Poisson distribution with $\lambda = 3\text{s}$." width="95%"><p class="caption">
Figure 7.1: Schematic of a trial from the Sure Bet or Gamble task and subjective rating prompt. A prospect is presented for a random duration based on a Poisson distribution <span class="math inline">\((\lambda = 6\text{s})\)</span>. Assuming a timely response, a choice screen was shown for two seconds followed by an outcome screen for one second. Trials were separated with a fixation cross whose inter-trial interval was a random duration from a Poisson distribution with <span class="math inline">\(\lambda = 3\text{s}\)</span>.
</p>
</div>
<p>For thirty minutes, participants indicated their preference for a sure bet (values between $1-$6 in $1 increments) or a fifty-fifty gamble between two non-identical values ($0 - $6 in $1 increments). The lateral presentation of the sure bet and gambles were randomized, and each prospect was presented for a random duration based on a Poisson distribution <span class="math inline">\((\lambda = 6\text{s})\)</span>. If the participant answered within the allotted time, their choice was displayed for two seconds before they were shown the outcome for one second. If they did not answer in time, they were shown a late screen for one second. Rounds were separated with a fixation cross whose inter-trial interval was a Poisson distribution <span class="math inline">\((\lambda = 6\text{s}\)</span>, zeros removed<span class="math inline">\()\)</span>. After one-third of of the rounds where choices were made, respondents were asked “How do you feel about the last outcome?” and adjusted a slider ranging from ‘very bad’ to ‘very good.’ Participants were paid $20 per hour and told they would receive winnings from a randomly selected round as bonus compensation.</p>
<p>Using this data from this task, we can group the remaining computational modeling steps into three stages:<span class="citation"><sup>[<a href="references.html#ref-wilson2019" role="doc-biblioref">36</a>]</sup></span></p>
<ul>
<li><p><strong>Simulation &amp; Parameter Recovery</strong>: Use the candidate model (CPUT) to generate ‘fake’ behavioral data and attempt to recover the parameters of interest following the proposed analysis method for experimental data.</p></li>
<li><p><strong>Parameter Estimation:</strong> Find the set of parameters that best account for the experimental data given the candidate model.</p></li>
<li><p><strong>Model Comparison:</strong> Compare the candidate models to others (EUT) that may provide alternative explanations of the behavioral data.</p></li>
</ul>
<p>Before detailing the methods and results for each stage in my analysis, it is important to understand the mathematics behind our model-fitting. In the remaining sections of this chapter, I discuss how Bayesian inference can help us infer from choice data the most plausible parameter values for a model.</p>
<div id="using-bayes-theorem-to-estimate-parameters-from-choice-behavior" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Using Bayes’ Theorem to Estimate Parameters from Choice Behavior<a class="anchor" aria-label="anchor" href="#using-bayes-theorem-to-estimate-parameters-from-choice-behavior"><i class="fas fa-link"></i></a>
</h2>
<p>Data from the sure bet or gamble task is represented as a binary variable. That is, for each prospect, if someone chose option one (the sure bet), we denote that with 1. Otherwise, it’s 0. and zero otherwise. For example, someone’s choice behavior for six prospects may look like this:</p>
<span class="math display">\[\begin{equation*}
\begin{split}
\text{Chose Option 1} =
    \begin{bmatrix}
    0 \\
    1 \\
    1 \\
    1 \\
    1 \\
    0
\end{bmatrix}
\end{split}
\qquad
\begin{split}
\text{Chose Option 2} =
    \begin{bmatrix}
    1 \\
    0 \\
    0 \\
    0 \\
    0 \\
    1
    \end{bmatrix} 
\end{split}
\end{equation*}\]</span>
<p>Given this binary choice behavior, the question becomes how we can estimate our parameter(s) of interest. And the answer is with Bayes’ Theorem! In the general case, Bayes’ Theorem states that the <strong><span style="color: purple;">probability</span></strong> a parameter of interest, <span class="math inline">\(\theta\)</span>, is some value <em>given the observed data</em> is proportional to the <strong><span style="color: maroon;">likelihood</span></strong> of observing the data <em>given that parameter value</em> times the <strong><span style="color: royalblue;">prior plausibility</span></strong> of the parameter being said value (Equation <a href="computational-modeling-concepts.html#eq:bayes-Theorem-general">(7.1)</a>).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Note that this is a form of Bayes’ Theorem that excludes the marginal likelihood of the data – that is, the total probability of observing the data – which acts as a normalizing constant to ensure the posterior distribution is a valid probability density function. For more details on this ‘posterior shortcut,’ see section 2.3.6 of &lt;em&gt;Bayes Rules!&lt;/em&gt;.&lt;span class="citation"&gt;&lt;sup&gt;[&lt;a href="references.html#ref-dogucu" role="doc-biblioref"&gt;37&lt;/a&gt;]&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;'><sup>8</sup></a></p>
<span class="math display" id="eq:bayes-Theorem-general">\[\begin{equation}
\color{purple}{Pr(\theta|\text{Data})} \propto \color{maroon}{L(\text{Data}|\theta)} \times \color{royalblue}{\pi(\theta)}
\tag{7.1}
\end{equation}\]</span>
<p>We can rewrite Bayes’ Theorem in the context of estimating the counterfactual weighting term, <span class="math inline">\(\gamma\)</span> from the human choice data. That is, the <strong><span style="color: purple;">probability</span></strong> of <span class="math inline">\(\gamma\)</span> being some value <em>given the observed choices</em> is proportional to the <strong><span style="color: maroon;">likelihood</span></strong> of observing a choice <em>given that <span class="math inline">\(\gamma\)</span> value</em> times the <strong><span style="color: royalblue;">prior plausibility</span></strong> of <span class="math inline">\(\gamma\)</span> being that value (Equation <a href="computational-modeling-concepts.html#eq:bayes-Theorem-gamma">(7.2)</a>).</p>
<span class="math display" id="eq:bayes-Theorem-gamma">\[\begin{equation}
\color{purple}{Pr(\gamma|\text{Choices})} \propto \color{maroon}{L(\text{Choice}|\gamma)} \times \color{RoyalBlue}{\pi(\gamma)}
\tag{7.2}
\end{equation}\]</span>
<p>In Bayesian inference, unknown parameters (e.g., <span class="math inline">\(\gamma\)</span>) are considered as random variables from which we can relate to the observed data with a “likelihood function.<span class="citation"><sup>[<a href="references.html#ref-van_de_schoot_bayesian_2021" role="doc-biblioref">38</a>]</sup></span> The parameter of interest when assessing the descriptive and predictive validity of CPUT using human choice data is <span class="math inline">\(\gamma\)</span>. In defining the prior plausibility of <span class="math inline">\(\gamma\)</span>, I am able to incorporate existing information into my modeling.</p>
<p>Prior information may be influenced by previous experiments. Here, I make assumptions about the distribution of <span class="math inline">\(\gamma\)</span> in light of the potential data-generating model, CPUT. Specifically, from the idea that people account for counterfactual information when making decisions, I assume that <span class="math inline">\(\gamma \ge 0\)</span>. I further assume people do not place <em>more</em> weight on counterfactual outcomes relative to factual ones. This constrains <span class="math inline">\(\gamma \le 1\)</span>. Together, the prior information I incorporate into my models suggests that values of <span class="math inline">\(0 \leq \gamma \leq 1\)</span> are equally plausible. That is, <span class="math inline">\(\gamma\)</span> is distributed from a uniform distribution between zero and one.</p>
<p>To refine our estimate of <span class="math inline">\(\gamma\)</span> using Bayes’ Theorem, we need some way of defining the likelihood of observing a binary choice for a specific <span class="math inline">\(\gamma\)</span> value. The likelihood describes the statistical model assumed to generate the choice behavior, relating the possible values for <span class="math inline">\(\gamma\)</span> and the observed choices.<span class="citation"><sup>[<a href="references.html#ref-van_de_schoot_bayesian_2021" role="doc-biblioref">38</a>]</sup></span></p>
<p>CPUT offers a way of determining utilities for a prospect’s options. In order to generate the data, we need some likelihood function that can transform these utilities into a valid statistical model. There are a number of these ‘action-selection’ methods<span class="citation"><sup>[<a href="references.html#ref-sutton-barto-2018" role="doc-biblioref">15</a>]</sup></span>. One common to both the psychological literature and the reinforcement learning field is the ‘soft-max’ choice rule: a logistic transformation of the difference in utilities for each option (Equation <a href="computational-modeling-concepts.html#eq:likelihood-softmax">(7.3)</a>).<span class="citation"><sup>[<a href="references.html#ref-sokol-hessner2009" role="doc-biblioref">39</a>]</sup></span> This introduces an additional parameter, <span class="math inline">\(\tau &gt; 0\)</span>, that relates how sensitive one’s choice is to a difference in utilities. In the limit, as <span class="math inline">\(\tau \rightarrow \infty\)</span>, the probability of choosing the option with a higher utility approaches 1.</p>
<span class="math display" id="eq:likelihood-softmax">\[\begin{equation}
\begin{aligned}
L_{\text{Softmax}}(\text{Chose Option 1} | U_1, U_2, \tau) &amp;= \frac{1}{1 + e^{(-\tau \cdot (U_1 - U_2))}} \\
L_{\text{Softmax}}(\text{Chose Option 2} | U_1, U_2, \tau) &amp;= \frac{1}{1 + e^{(-\tau \cdot (U_2 - U_1))}}
\end{aligned}
\tag{7.3}
\end{equation}\]</span>
<p>For my analysis, I used the softmax transformation as the likelihood function to relate the probability of choosing option one, the sure bet, with <span class="math inline">\(\gamma\)</span>. That is, the mathematical description of the model I used to assess CPUT’s veracity, represented in Equation <a href="computational-modeling-concepts.html#eq:cput-model-definition">(7.4)</a>, says:</p>
<ul>
<li>An individual choice for option 1 is made with probability <span class="math inline">\(p\)</span>, where</li>
<li>
<span class="math inline">\(p\)</span> is determined through a softmax transformation of the counterfactual utilities for each option, <span class="math inline">\(U_{C1}(\gamma), U_{C2}(\gamma)\)</span>, and a sensitivity parameter, <span class="math inline">\(\tau\)</span>, where</li>
<li>
<span class="math inline">\(\tau\)</span> is assumed to be uniform between zero and thirty, and</li>
<li>
<span class="math inline">\(\gamma\)</span> is assumed to be uniform between zero and one.</li>
</ul>
<span class="math display" id="eq:cput-model-definition">\[\begin{equation}
\begin{aligned}
\text{Chose Option 1} &amp;\sim \text{Bernoulli}(p) \\
p &amp;= L_{\text{Softmax}}\Big(\text{Chose Option 1} \ | \ U_{C1}(\gamma), U_{C2}(\gamma), \tau \Big) \\
\tau &amp;\sim \text{Uniform}(0, 30) \\
\gamma &amp;\sim \text{Uniform}(0, 1)
\end{aligned}
\tag{7.4}
\end{equation}\]</span>
</div>
<div id="visualizing-bayes-theorem-with-choice-datamodeling-concepts-2" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Visualizing Bayes’ Theorem with Choice Data<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;This entire section was heavily influenced by Richard McElreath’s incredible textbook, &lt;em&gt;Statistical Rethinking&lt;/em&gt;, and his &lt;a href="https://github.com/rmcelreath/stat_rethinking_2022"&gt;open-sourced lectures&lt;/a&gt;. Specifically, Figure &lt;a href="computational-modeling-concepts.html#fig:sbg-nine-choices"&gt;7.3&lt;/a&gt; and the explanation of it are drawn directly from McElreath’s discussion of Bayesian updating (Figure 2.5, Section 2.2.2 of &lt;em&gt;Statistical Rethinking&lt;/em&gt;).&lt;span class="citation"&gt;&lt;sup&gt;[&lt;a href="references.html#ref-richardmcelreath2020" role="doc-biblioref"&gt;40&lt;/a&gt;]&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;'><sup>9</sup></a><a class="anchor" aria-label="anchor" href="#visualizing-bayes-theorem-with-choice-datamodeling-concepts-2"><i class="fas fa-link"></i></a>
</h2>
<p>To build an intuition for how we can estimate the model’s parameters of interest, we can begin the ‘Simulation &amp; Parameter Recovery’ step described in the chapter introduction. Figure <a href="computational-modeling-concepts.html#fig:sbg-utilities-to-choice">7.2</a> depicts the process of simulating a choice for the prospect included at the top of Figure <a href="computational-modeling-concepts.html#fig:sborg-task-description">7.1</a>. We first calculate counterfactual utilities for a prospect. Next, we apply the softmax choice rule to translate the utilities into a probability of choosing either option. Lastly, we ‘make’ a choice by flipping a weighted coin.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sbg-utilities-to-choice"></span>
<img src="figures/sbg_demo_utilities_to_choice_figure.png" alt="Depiction of the data generating process for modeling choice behavior with CPUT on the sure bet or gamble task. The left panel highlights the first step where counterfactual utilities are calculated. The middle panel shows the softmax transformation of the utilities into a probability of choosing either option; opacity of the logistic function increases with the softmax sensitivity parameter, $\tau$, signaling a utility maximizing tendency. The right panel conveys how a choice is made by 'flipping a weighted coin'." width="100%"><p class="caption">
Figure 7.2: Depiction of the data generating process for modeling choice behavior with CPUT on the sure bet or gamble task. The left panel highlights the first step where counterfactual utilities are calculated. The middle panel shows the softmax transformation of the utilities into a probability of choosing either option; opacity of the logistic function increases with the softmax sensitivity parameter, <span class="math inline">\(\tau\)</span>, signaling a utility maximizing tendency. The right panel conveys how a choice is made by ‘flipping a weighted coin.’
</p>
</div>
<p>When fitting a model on behavioral data, we assume that the statistical model represents how the data is generated. We can therefore work backwards by observing choices to infer the parameter values that are <em>most plausible given the data</em>. Bayes’ Theorem provides a way to update the most plausible parameter values for each choice observed.</p>
<p>To visualize a concrete example of this, I simulated nine choices between a sure bet of three dollars and a fifty-fifty gamble of two or five dollars (top panel from Figure <a href="computational-modeling-concepts.html#fig:sborg-task-description">7.1</a>) for an agent with <span class="math inline">\(\gamma = 0.25\)</span> and <span class="math inline">\(\tau = 2.2\)</span>. For a given <span class="math inline">\(\tau\)</span>, our likelihood function assigns the probability of observing a choice for any <span class="math inline">\(\gamma\)</span> value.</p>
<p>Consider the top left panel of Figure <a href="computational-modeling-concepts.html#fig:sbg-nine-choices">7.3</a>. Before observing any data, as specified in Equation <a href="computational-modeling-concepts.html#eq:cput-model-definition">(7.4)</a>, our prior (black, dashed line) is uniformly distributed between zero and one. The first choice our agent makes is a gamble. Multiplying our prior by the likelihood of choosing a gamble gives us the posterior plausibility for <span class="math inline">\(\gamma\)</span> (purple, solid line). You may notice that the posterior distribution for this panel resembles the likelihood of choosing a gamble depicted in Figure <a href="computational-modeling-concepts.html#fig:sbg-utilities-to-choice">7.2</a>. This is because the prior distribution for <span class="math inline">\(\gamma\)</span> is initially uniform, so with one choice observed, the posterior plausibility becomes the likelihood.</p>
<p>This distribution becomes the starting point for future inference. In the next panel, our model observes a sure bet choice. Our most recent plausibility (purple, dashed line) is multiplied by the likelihood of observing a sure bet (depicted in Figure <a href="computational-modeling-concepts.html#fig:sbg-utilities-to-choice">7.2</a>) to generate a new posterior distribution (blue-purple, solid line). This trend continues for each additional panel of Figure <a href="computational-modeling-concepts.html#fig:sbg-nine-choices">7.3</a>: our model observes a new choice and multiplies the likelihood of observing that choice by the previous posterior plausibility of <span class="math inline">\(\gamma\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sbg-nine-choices"></span>
<img src="figures/sbg_demo_nine_choices_figure.png" alt="How a Bayesian model updates parameter estimates with new observations. Each panel shows a new choice simulated according to CPUT with $\gamma = 0.25$. The model's estimate of $\gamma$ depicts the relative plausibility of each value. In each panel, most recent plausiblity (dashed line) is multiplied by the likelihood of observing the latest choice to produce the posterior plausibility (solid line)." width="95%"><p class="caption">
Figure 7.3: How a Bayesian model updates parameter estimates with new observations. Each panel shows a new choice simulated according to CPUT with <span class="math inline">\(\gamma = 0.25\)</span>. The model’s estimate of <span class="math inline">\(\gamma\)</span> depicts the relative plausibility of each value. In each panel, most recent plausiblity (dashed line) is multiplied by the likelihood of observing the latest choice to produce the posterior plausibility (solid line).
</p>
</div>
<p>Notice that each ‘sure bet’ choice shifts the range of plausible <span class="math inline">\(\gamma\)</span> rightwards and each gamble choice shifts it leftwards. With each observation, the variance of the curve decreases, and the height increases. This highlights increasing evidence for the plausibility of <span class="math inline">\(\gamma\)</span> values. As seen in the bottom right panel of Figure <a href="computational-modeling-concepts.html#fig:sbg-nine-choices">7.3</a>, we’re able to get an idea of the ‘true’ value of <span class="math inline">\(\gamma\)</span> with relatively little data!</p>
<p>For this visualization, I fixed <span class="math inline">\(\tau = 2.2\)</span>, which made it easier to estimate the posterior probability of <span class="math inline">\(\gamma\)</span>. Simultaneously estimating multiple parameters often leads to computationally intractable posterior distributions, however. In the next section, I discuss a family of methods for efficiently calculating these joint posterior distributions known as ‘Markov Chain Monte Carlo.’</p>
</div>
<div id="posterior-estimation-with-markov-chain-monte-carlo" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Posterior Estimation with Markov Chain Monte Carlo<a class="anchor" aria-label="anchor" href="#posterior-estimation-with-markov-chain-monte-carlo"><i class="fas fa-link"></i></a>
</h2>
<p>For my thesis, I used two Markov Chain Monte Carlo methods. For the first, I manually implemented method is the Metropolis-Hastings algorithm in R.<span class="citation"><sup>[<a href="references.html#ref-dogucu" role="doc-biblioref">37</a>,<a href="references.html#ref-haines2018" role="doc-biblioref">41</a>]</sup></span> At a high level, it can be boiled down into three steps repeated for <span class="math inline">\(n \in 1:N\)</span> iterations:</p>
<ol style="list-style-type: decimal">
<li>Propose a value, <span class="math inline">\(\theta_n^*\)</span> near the current estimate <span class="math inline">\(\theta_n\)</span>, propose a value <span class="math inline">\(\theta^*\)</span>
</li>
<li>Calculate the acceptance probability for proposal <span class="math inline">\(\theta_n^*\)</span> defined as the ratio between the posterior distribution evaluated at <span class="math inline">\(\theta_n^*\)</span> to that of <span class="math inline">\(\theta_n\)</span>
</li>
<li>Draw a random number between zero and one. If it is less than or equal to the acceptance probability, set <span class="math inline">\(\theta_{n+1} = \theta_n^*\)</span>, otherwise <span class="math inline">\(\theta_{n+1} = \theta_n\)</span>.</li>
</ol>
<p>I then validated my implementation by comparing it to posterior distributions computed with a hierarchical Bayesian approach. The Hierarchical Bayesian Analysis was implemented in the probabilistic programming language, Stan, which implements an efficient variant of Markov Chain Monte Carlo called the Hamiltonian Monte Carlo sampler.<span class="citation"><sup>[<a href="references.html#ref-standevelopmentteam2022" role="doc-biblioref">42</a>]</sup></span> Hierarchical Bayesian Analysis allows for simultaneous estimation of individual and group-level parameters in a mutually-constraining fashion. This has been shown to improve parameter estimates relative to other methods (e.g., maximum likelihood estimation), resulting in more stable and reliable estimates for individual-level parameters as they are informed by group trends.<span class="citation"><sup>[<a href="references.html#ref-ahn2011" role="doc-biblioref">43</a>]</sup></span></p>
<p>The specific implementation of hierarchical models I follow has been detailed elsewhere.<span class="citation"><sup>[<a href="references.html#ref-ahn2017" role="doc-biblioref">44</a>]</sup></span> At a high level, individual-participant parameters are assumed to be drawn from normally distributed group-level distributions. Bounded parameters, such as <span class="math inline">\(\gamma\)</span>, were estimated in an unconstrained space and transformed with the ‘Matt Trick,’<span class="citation"><sup>[<a href="references.html#ref-standevelopmentteam2022" role="doc-biblioref">42</a>]</sup></span> an inverse Probit transformation. This is to optimize the MCMC sampling.<span class="citation"><sup>[<a href="references.html#ref-ahn2017" role="doc-biblioref">44</a>]</sup></span> More formally,</p>
<span class="math display" id="eq:matt-trick">\[\begin{equation}
\begin{aligned}
\mu_\theta &amp;\sim \text{Normal}(0,1) \\
\sigma_\theta &amp;\sim \text{Half-Normal}(0,0.2) \\
\mathbf{\theta}^\prime &amp;\sim \text{Normal}(0,1) \\
\mathbf{\theta} &amp;= \text{Probit}^{-1}(\mu_\theta + \sigma_\theta \cdot \mathbf{\theta}^\prime) \times U.B.
\end{aligned}
\tag{7.5}
\end{equation}\]</span>
<p>where <span class="math inline">\(- \infty &lt; \mu_\theta &lt; + \infty\)</span> and <span class="math inline">\(- \infty &lt; \sigma_\theta &lt; + \infty\)</span> are the group-level mean and standard deviation, respectively; <span class="math inline">\(\theta^\prime\)</span> is the unconstrained parameter that gets transformed via the inverse Probit transformation and scaled to some upper bound, <span class="math inline">\(U.B\)</span>. As an example, for <span class="math inline">\(\gamma\)</span>, <span class="math inline">\(U.B. = 1\)</span>; for <span class="math inline">\(\tau\)</span>, <span class="math inline">\(U.B. = 30\)</span>. This non-centered reparameterization results in a uniform prior for individual participants’ parameters across the full range.<span class="citation"><sup>[<a href="references.html#ref-ahn2017" role="doc-biblioref">44</a>,<a href="references.html#ref-ahn2014" role="doc-biblioref">45</a>]</sup></span></p>
<hr>
<p>In this chapter, I hoped to provide an understanding of the computational modeling concepts used in my thesis. Specifically, I:</p>
<ul>
<li>Provided an overview of the sure bet or gamble task</li>
<li>Mathematically described how we can estimate parameters from binary choice data using Bayes’ Theorem</li>
<li>Visually depicted parameter estimation from choice data using Bayes’ Theorem for CPUT with simulated choices</li>
<li>Introduced the Markov Chain Monte Carlo methods I use in my thesis to sample from the joint posterior distributions</li>
</ul>
<p>With this foundation, it’s time to revisit the three computational modeling stages I introduced at the beginning of the chapter.<span class="citation"><sup>[<a href="references.html#ref-wilson2019" role="doc-biblioref">36</a>]</sup></span> Next, I outline my methods and results from simulating choice data according to counterfactual predicted utility theory, estimating parameters from observed data, and comparing evidence from three candidate models.</p>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="counterfactual-predicted-utility-theory.html"><span class="header-section-number">6</span> Counterfactual Predicted Utility Theory</a></div>
<div class="next"><a href="computational-modeling-methods-and-results.html"><span class="header-section-number">8</span> Computational Modeling Methods and Results</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#computational-modeling-concepts"><span class="header-section-number">7</span> Computational Modeling Concepts</a></li>
<li><a class="nav-link" href="#using-bayes-theorem-to-estimate-parameters-from-choice-behavior"><span class="header-section-number">7.1</span> Using Bayes’ Theorem to Estimate Parameters from Choice Behavior</a></li>
<li><a class="nav-link" href="#visualizing-bayes-theorem-with-choice-datamodeling-concepts-2"><span class="header-section-number">7.2</span> Visualizing Bayes’ Theorem with Choice Data9</a></li>
<li><a class="nav-link" href="#posterior-estimation-with-markov-chain-monte-carlo"><span class="header-section-number">7.3</span> Posterior Estimation with Markov Chain Monte Carlo</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/jdtrat/masters-thesis/blob/main/thesis-documents/04_modeling.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/jdtrat/masters-thesis/edit/main/thesis-documents/04_modeling.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Counterfactuals, Dopamine, and Risky Behavior</strong>: Deriving a neurobiological theory of decision-making under risk" was written by Jonathan D. Trattner. It was last built on 2022-05-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
