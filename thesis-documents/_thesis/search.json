[{"path":"index.html","id":"dedication-and-acknowledgements","chapter":"1 Dedication and Acknowledgements","heading":"1 Dedication and Acknowledgements","text":"dedicate thesis mom, Joanne Fink, grandpa, Dr. Gordon Fink. person without love, guidance, careful proof reading thesis. love .May 2022, graduate Master Science Degree Neuroscience Wake Forest School Medicine. website embodiment master’s thesis. None possible incredible support mentors, family, friends.First foremost, ’d like thank Ken Kishida. ’ve conducting research since February 2018 incredibly appreciative encouragement support. Dr. Kishida given space follow interests programming neuroscience especially, website embodiment . Within Kishida Lab, conversations L. Paul Sands greatly informed modeling techniques, appreciative. Emily DiMarco, Rachel Jones, Angela Jiang, Brittany Liebenow provided feedback guidance developed thesis.undergraduate, Lucy McGowan, S. Mason Garrison, Staci Hepler immeasurable impact understand, conduct, scientific programming, Bayesian inference, data analysis. Katy Lack, Melissa Maffeo, Wayne Pratt, Terry Blumenthal fostered interest Neuroscience. extremely grateful learned .’d next like thank committee members, Drs. Christian Waugh Todd McFall (Ken Kishida!) support guidance ’ve worked thesis. input made much better. Also, Nathaniel Haines’s publications greatly improved understanding underlying mathematics behind computational modeling provided invaluable feedback work.family, love support everything. Thank .","code":""},{"path":"abstract.html","id":"abstract","chapter":"2 Abstract","heading":"2 Abstract","text":"thesis, combine insights economics, pyschology, neuroscience develop ‘Counterfactual Predicted Utility Theory’ (CPUT) neurobiologically-plausible theory decision-making risk. CPUT inspired observation sub-second fluctuations levels neurotransmitter dopamine seemingly reflect factual counterfactual information. propose people incorporate anticipated counterfactual events making risky decisions. leads behavior considered ‘irrational’ classical economic perspective described Expected Utility Theory (EUT). assess predictive accuracy CPUT, compared variations CPUT EUT human choice data sure bet gamble task using hierarchical Bayesian modeling techniques. quantified model fit multiple methods. includes comparing marginal likelihood model evidence leave-one-cross validation predictive accuracy. found CPUT offers better explanation data collected part sure-bet gamble task EUT likely generalize (similar) datasets. results provide conclusive evidence favoring CPUT, suggest possible role integration counterfactual information risky decision-making warrants future investigation.","code":""},{"path":"introduction.html","id":"introduction","chapter":"3 Introduction","heading":"3 Introduction","text":"make choices every day. eat, whether take one route work, go sleep, just examples. Every decision associated consequences. Consequences inherently rewarding (appetitive), punishing (aversive), . understand processes involved human decision-making, use quantitative frameworks study choice behavior. analytic approaches primarily formalized three disciplines: economics, psychology, neuroscience.experimental literature, two types decision contexts described. “decisions risk,” decision-maker knows precision probability distribution possible outcomes. “decisions uncertainty,” decision-maker must infer probabilities potential outcomes. thesis, combine insights economics, psychology, neuroscience propose neurobiologically-plausible theory decision-making risk.next chapters, outline evolution decision-theory classical economic models behavioral economic ones. describe influences behavioral economic theories neuroscience research discuss potential neural mechanisms decision-making. neurobiological inspiration, propose new theory decision-making risk called ‘Counterfactual Predicted Utility Theory.’ Next, detail concepts, methods, computational modeling results estimate theory’s validity human choice data sure-bet gamble task. Lastly, discuss results propose next steps continuing work.","code":""},{"path":"evolution-of-decision-theory.html","id":"evolution-of-decision-theory","chapter":"4 Evolution of Decision Theory","heading":"4 Evolution of Decision Theory","text":"Imagine casino. asked play new type roulette. time , cost participating. rules simple: pick red option black option. choose red option, dealer give three-thousand dollars. pick black option, dealer spin wheel release ball. wheel weighted 80% chance getting four-thousand dollars 20% chance getting zero dollars. option choose? ?economic theorist, bet choose black option higher expected value. Expected values, \\(EV\\), calculated multiplying magnitude, \\(x\\), outcome probability, \\(p\\), occur. example, red option leads three-thousand dollars certainty. black option leads four-thousand dollars 80% chance (probability 0.8).Looking expected values option calculated (4.1), see \\(\\text{EV}(\\text{Black}) > \\text{EV(Red)}\\). Therefore, rational choice according classical economist black option.new type roulette presented prototypical example prospect – choice two options explicit probabilities outcomes – used investigate decision-making risk. normative measure monetary reinforcements allows decision-researchers probe mechanisms underlying choice behavior. participants similar reference point, choosing option higher expected monetary payout straightforward (least mathematically speaking). However, decision accept risky gamble like one described may change ask someone annual income one-million dollars compared someone income fifty-thousand dollars.introduces idea diminishing marginal returns. value millionaire places certain three-thousand dollars (option 1 ) may enough dissuade probable four-thousand dollars. person, assured three-thousand dollars, though, much valuable gamble. idea formalized term ‘utility,’ coined Swiss mathematician Daniel Bernoulli. Utiity refers subjective “moral value” decision’s outcome. Bernoulli wrote:[1]price item dependent thing equal everyone; utility, however, dependent particular circumstances person making estimate.Bernoulli’s concept formed basis von Neumman Morgenstern’s Expected Utility Theory (EUT).[2] EUT suggest people – – choose manner maximizes expected utility. EUT axiomatized, validity called question. Notably, Allais paradox suggests rationality defined maximizing expected utility neglects specific element psychology risk: variance individuals’ psychological values.[3]1979, Daniel Kahneman Amos Tversky published Prospect Theory: Analysis Decision Risk.[4] Prospect theory critiqued descriptive validity EUT. Kahneman Tversky highlighted systematic ways people violated EUT. , initiated field behavioral economics – wedding insights psychology quantitative models economics – better understand human choice behavior.Kahneman Tversky describe multiple deviations EUT. Notably, discuss certainty reflection effects. certainty effect describes people overweight outcomes considered certain relative probable ones. reflection effect – commonly known ‘loss aversion’ – accounts peoples tendency risk averse positive prospects risk seeking negative ones. addition effects, one key takeaway prospect theory value function corresponds changes wealth welfare, rather final states. value function, concave gains convex losses, losses steeper gains (goes hand--hand reflection effect).application behavioral insights theories human decision-making necessitate emotional component. discussed Graham Loomes Robert Sugden 1982 paper, Regret Theory: Alternative Rational Choice Uncertainty, anticipatory feelings regret used inform decisions.[5]1 Loomes Sugden’s describe idea choosing one option preference cost forgoing opportunities.2 theory introduces concept counterfactual thinking, explicit comparison present state world alternative states.[7,8]revisit casino example, feel chose black option (gambling four-thousand dollars) lost? chosen red option three-thousand dollars certain, forewent opportunity chance something . comparison “” vs. “might ” captures idea counterfactual information.summarize material chapter:recounted high-level overview choice theory, described expected values calculated, introduced importance subjective measures (utility) studying choice behavior.introduced EUT classical economist’s theory decision-making risk.Next, covered origin behavioral economics Kahneman Tversky’s prospect theory improve descriptive models choice behavior.concludes chapter covering regret theory necessity accounting subjective emotions choice models.next chapter, outline recent work looking neurobiological basis decision-making show evidence specific neural systems track counterfactual signals.","code":""},{"path":"neurobiology-of-decision-making.html","id":"neurobiology-of-decision-making","chapter":"5 Neurobiology of Decision-Making","heading":"5 Neurobiology of Decision-Making","text":"previous chapter, used term prospect describe problem two options stated probabilities outcomes. experimental literature, prospects called ‘description-based.’ Researchers use description-based prospects experiments ask participants select one available options presented along complete description non-trivial problem.[9]looking towards neuroscientific literature decision-making, different type experimental paradigm perhaps common: ‘experiential’ ‘feedback-based’ decisions.[9]. interacting environment, humans (animals) associate consequences different actions adapt behavior accordingly. words, learn. learn time want eat sushi dinner, ’s faster take highway work, ’re better go sleep midnight.3Looking towards animal learning field, see many accounts experiential learning. list :Thorndike’s Law Effect states animal’s behavior can modified consequences action.[10]Thorndike’s Law Effect states animal’s behavior can modified consequences action.[10]Classical (Pavlovian) conditioning details learning predict rewards punishments stimulus independent action-taken.[11]Classical (Pavlovian) conditioning details learning predict rewards punishments stimulus independent action-taken.[11]Operant (instrumental) conditioning involves learning rewards punishments contingent upon one’s actions.[12]Operant (instrumental) conditioning involves learning rewards punishments contingent upon one’s actions.[12]behavior (action decision) predicated upon prior experiences allows us formalize relationship states. , use state reference representation stimuli. example, state \\(s \\S\\) time \\(t\\) (\\(s_t\\)) may comprised internal states (hunger, thirst, fatigue) external ones (light, music, temperature).Consider Pavlov’s experiment showed repeatedly giving dog food ringing bell condition dog salivate bell rung.[11] means , time, behavior elicited stimulus (food) can evoked previously neutral stimulus (bell). one first attempts empirically describe process, Bush Mosteller suggest probability Pavlov’s dog salivating, \\(P(\\text{sal})\\), next presentation food bell (next trial, \\(tr+1\\)) function happened last presentation (last trial, \\(tr-1\\)) discounted experienced presentation (food reward trial, \\(R_{tr}\\).[13,14]Equation (5.1) computes average previously experienced rewards. \\(0 \\leq \\alpha \\leq 1\\) learning rate, modulates influence recent rewards. Bush Mosteller’s work forms basis modern approaches problem reinforcement learning.[15]4 discretizing learning trials logical first step modeling behavior experimental settings, ’s easily applied biological systems continuously interact environments.1988 paper, Learning Predict Methods Temporal Differences, Richard Sutton introduces antecedent temporal-difference reinforcement learning (TDRL) algorithms.[16] TDRL algorithm provides computational framework optimally learning experience actions associated stimuli lead rewards.[17]‘goal’ TDRL algorithms estimate value state use information maximize rewards. achieved ‘teaching signal,’ called temporal-difference reward prediction error (TD-RPE), relates value state time \\(t\\) expected previously.concept perhaps best illustrated example. Imagine order food favorite restaurant. ’ve tried every item menu, order favorite dish.5 ’ve ordered much, certain expectation item smells like, tastes, state contentedness feel eating .represent intrinsic value eating food time \\(t\\) \\(V(S_t)\\). describe economic terms, expected value eating favorite dish. Fortunately, time come food ready! open container notice something quite smell right. , experience, \\(\\text{outcome}_t\\), negative. expected fragrant odor faced something else. words, expected something better experienced. time, expectation future enjoyment, \\(V(S_{t+1})\\) still high. Maybe, think, odd smell comes container food . , remain hopeful enjoyable meal.idea presented preceding paragraph encapsulated Equation (5.2) defines TD-RPE, \\(\\delta_t\\), difference current value state time \\(t\\) expected. summarize notation:value state sum experience (e.g., displeasing odor, \\(\\text{outcome}_t\\)) expectation future values, \\(V(S_{t+1})\\). value future states modulated temporal-discounting parameter \\(0 \\leq \\gamma \\leq 1\\) preferentially weights immediate outcomes relative future ones.6The expectation state, \\(V(S_t)\\), (e.g., incredible culinary experience) based prior experiences.time step, \\(\\delta_t\\) used update estimated value current state formulated (5.3).Whereas Equation (5.1), learning rate \\(0 \\leq \\alpha \\leq 1\\) ascribed weight recent rewards recently relative experienced distant past. contrast, TDRL learning rate (also \\(0 \\leq \\alpha \\leq 1\\)) controls much weight individual places estimated value current state light TD-RPE. Put another way, controls much update future expectation given recent experience.1990s, Read Montague, Peter Dayan, colleagues showed evidence suggesting TD-RPEs encoded fluctuations activity mesencephalic dopaminergic neurons.[21,22] implication dopaminergic system might encode TD-RPEs became known TD-RPE hypothesis dopamine neurons consistent behavioral neural results rodents,[23] non-human primates,[24–27] humans.[28–31] biologically conserved mechanism experiential learning, can investigate neural basis choice behavior empirically TDRL algorithms. 2011, experiments saw exciting development Ken Kishida colleagues used fast-scan cyclic voltammetry measure dopamine fluctuations human striatum sub-second temporal resolution.[29]combination 2016 paper, Kishida colleagues studied dopamine levels humans undergoing elective surgery part deep-brain stimulation treatment.[29,32] Participants viewed graphical depiction (fictitous) stock market’s price history (Figure 5.1; B) asked choose much portfolio (initially valued $100) invest. six ‘markets,’ twenty-decisions, participants used handheld button boxes (Figure 5.1; ) increase decrease investment ten-percent increments. Decisions made light three pieces information sub-second changes dopamine concentrations recorded striatum:history market price (Figure 5.1; red-trace panel B)current portfolio value (Figure 5.1; bottom left box, 126, panel B)recent fractional change portfolio value (Figure 5.1; bottom right box, 15.2%, panel B).\nFigure 5.1: Participants played sequential-choice game surgery using button boxes (; Left) visual display (; Right). patient, bet size adjustments (e.g., increase bet decrease bet) decision submit one’s answer performed button boxes. (B) Graphical depiction market price history (red trace), current portfolio value (bottom left box), recent outcome (bottom right box) sequential investment task (C) Timeline events single round investment game. Reprinted permission Kishida et al., 2016.\n2011 paper, asked one person, MH, complete sequential investment task. line prior work relating dopamine unexpected financial outcomes,[28] Kishida colleagues observed strong correlation MH’s dopamine levels market value investment task.[29] 2016, Kishida colleagues published results seventeen humans. , explicitly tested hypothesis fluctuations dopamine released human striatum encode TD-RPEs.[32] sequential investment task, RPEs calculated difference investment’s return given trial relative expectation defined average return preceding trials.Contrary hypothesis dopamine fluctuations striatum track TD-RPEs,[21,23,33–36] authors found dopamine fluctuations encode integration RPEs counterfactual prediction errors (CPEs). discussed last chapter, counterfactual signals explicit comparison present state alternative ones.[7,8] sequential investment task, CPEs defined difference participant’s actual return trial invested less. means dopamine release result integration RPEs CPEs given trial. Formally:\\(b_{tr}\\) individual’s factional investment trial \\(tr\\) \\(r_{tr}\\) relative change market price. Kishida colleagues note, intuition Equation (5.4) better--expected outcomes (positive RPEs, increased dopamine release), even better (positive CPEs) reduced value. Similarly, worse--expected outcomes (negative RPEs, decreased dopamine release), even worse (negative CPEs) increased value. Importantly, empirical terms consistent subjective feelings (e.g., regret relief), one experiences light given outcome.\nFigure 5.2: RPE encoding dopamine transients invert function bet size. Dopamine responses equal absolute magnitude positive negative RPEs bets high (Left), medium (Center), low (Right). three plots, mean normalized dopamine responses standard errors shown positive RPEs (green traces) negative RPEs (red traces). Reprinted permission Kishida et al., 2016.\nFigure 5.2 depicts changes dopamine levels function bet size. Consider ‘higher bets’ panel (left) individuals bet close maximum amount possible. rewarded positive change portfolio value, dopamine concentrations increased (green; positive RPEs). Similarly, portfolio value decreased, dopamine levels dipped (red; negative RPEs). high bets (left panel, bets \\(90\\%-100\\%\\) portfolio value), difference earned earned bet minimal, CPE. medium bets (middle panel, \\(60\\%-80\\%\\)), however, difference individuals experienced experienced bet increases. means absolute magnitude CPE goes subtracts dopamine release predicted positive negative RPEs. CPEs maximal (small bets, \\(10\\% - 50\\%\\); right panel), observe inversion dopamine release response positive negative RPEs.‘superposed error signals actual counterfactual reward’ described Kishida colleagues’ paper[32] directly inspired thesis work. provide empirical, neurobiologically plausible framework investigating decision-making risk. theoretical quantitative underpinnings classical behavioral economic theories decision-making align well computational reinforcement learning literature described chapter. explicit probability outcome structure risky prospects afford opportunity internalize future states (potentially) incorporate anticipated counterfactual events decision-making process. next chapter, derive ‘Counterfactual Predicted Utility Theory’ new theory decision-making risk.","code":""},{"path":"counterfactual-predicted-utility-theory.html","id":"counterfactual-predicted-utility-theory","chapter":"6 Counterfactual Predicted Utility Theory","heading":"6 Counterfactual Predicted Utility Theory","text":"discussed neurobiology decision-making chapter, neurotransmitter dopamine seemingly encodes information actual counterfactual rewards,[32] integration may play guiding role decision-making. neural evidence, combined behavioral economic theories offering descriptive models people making risky decisions,[4,5] propose ‘Counterfactual Predicted Utility Theory’ (CPUT) neurobiologically-plausible theory decision-making risk.impetus behind CPUT idea people account counterfactual outcomes faced prospect integration factual counterfactual signals brain may discount invert preference choosing one option another. hypothesize preference-reversal modulated counterfactual weighting term, \\(\\gamma\\), may vary across people.formally derive CPUT, can revisit prospect introduced first chapter hypothetical casino game. two options: choosing one certainly three-thousand dollars; choosing another give 80% chance four-thousand dollars nothing. prospect commonly denoted follows first option leads outcome \\(x_1\\) probability \\(p_1\\) second option leads outcomes \\(x_2\\) probability \\(p_2\\).Unless otherwise stated, alternative outcomes option assumed zero. , choosing Option 1 choice receiving \\(x_1\\) probability \\(p_1\\) nothing probability \\((1 - p_1)\\). explicit, generalizable, representation prospect can seen Figure 6.1. , Option 1 choice receiving \\(x_{1a}\\) probability \\(p_1\\) \\(x_{1b}\\) probability \\((1 - p_1)\\). Similarly, Option 2 choice receiving \\(x_{2a}\\) probability \\(p_2\\) \\(x_{2b}\\) probability \\((1 - p_2)\\).\nFigure 6.1: Explicit representation prospect two options. Choosing option 1 may lead outcome \\(x_{1a}\\) probability \\(p_1\\) outcome \\(x_{1b}\\) probability \\((1 - p_1)\\). Choosing option 2 may lead outcome \\(x_{2a}\\) probability \\(p_2\\) outcome \\(x_{2b}\\) probability \\((1 - p_2)\\).\nrepresentation, can begin formally define option’s counterfactual utility, \\(U_C\\), follows:contrast, Expected Utility Theory, option’s expected value exponentiated risk-aversion parameter, \\(\\rho\\). expected utility definition Equation (6.3) represents weighting probabilities outcomes Equation (6.2).represent equations similarly, define \\(V_E\\) estimated expected utility value (really just stated outcome). CPUT, however, formally define transformation stated outcome face value minus weighted sum option’s alternative outcome option’s expected value. notation expressed Equation (6.4), shows prospect form depicted Figure 6.1 represented.Unlike estimated expected utility value, \\(V_E\\), estimated counterfactual utility value, \\(V_C\\) one--one mapping stated outcomes. provide better intuition within- -option dependency, helpful consider concrete example. adapting Figure 6.1 include values casino example initially described, can better see possible outcome may integrate evaluating given prospect.\nFigure 6.2: Example prospect diagram visualize counterfactual integration. Choosing option 1 may lead outcome \\(\\$3000\\) probability \\(1.0\\) outcome \\(\\$0\\) probability \\((1 - 1.0)\\). Choosing option 2 may lead outcome \\(\\$4000\\) probability \\(0.8\\) outcome \\(\\$0\\) probability \\((1 - 0.8)\\). Estimating counterfactual utility value possible outcomes dependent one-another.\nillustrate CPUT walking-Figure 6.2, let’s assume counterfactual-weighting term \\(\\gamma = 0.1\\). means stated outcomes transformed given available counterfactual information potential outcome follows:values combined Equation (6.2), see \\(U_C(\\text{Option 2}) > U_C(\\text{Option 1})\\):maximize utility, choose Option 2 progress diagram first node right-hand side. , forwent opportunity Option 1. chose differently, reached node left, expected value $3000, didn’t. current position, 80% chance find red node, $4000. proverbial coin-flip goes , however, find cyan node nothing show . walking-example, hoped convey possible outcomes relate one-another factual counterfactual information may integrated inform one’s decision.Importantly, equations suggest \\(\\gamma = 0\\), one places weight counterfactual events, counterfactual utility equivalent expected value. words, \\(\\gamma = 0\\), \\(U_C(\\text{Option 1}) = EV(\\text{Option 1})\\) \\(U_C(\\text{Option 2}) = EV(\\text{Option 2})\\). people don’t place weight counterfactual information, might expect choice behavior consistent maximizing expected value (, better compare theories decision-making, maximizing expected utility). provide evidence support CPUT generative theory decision-making, test hypothesis \\(\\gamma > 0\\) means people consider counterfactual outcomes faced risky prospect. summarize discussed chapter:addressed first thesis aim developing counterfactual predicted utility theory (CPUT) alternative expected utility theory explain decision-making risk.showed information potential outcome (terminal node Figure 6.1) integrates counterfactual weighting parameter, \\(\\gamma\\), adjust utility one option another.walked-example calculation assuming \\(\\gamma = 0.1\\) (diagrammed Figure 6.1).next chapter, begin address second thesis aim assessing predictive accuracy CPUT using human choice data ‘Sure Bet Gamble’ task.[37]","code":""},{"path":"computational-modeling-concepts.html","id":"computational-modeling-concepts","chapter":"7 Computational Modeling Concepts","heading":"7 Computational Modeling Concepts","text":"attempt robustly, transparently, fit CPUT behavioral data, follow general guidelines presented Robert Wilson Anne Collins’s paper Ten simple rules computational modeling behavioral data.[38]high level, state computational modeling allows us make better sense behavioral data mathematical models may provide insight mechanisms underlying behavior. Although exact form models differ, basic steps assess model’s descriptive predictive efficacy similar.first two steps Wilson Collins discuss designing experiment developing model. thesis, fit CPUT data collected ongoing study Brittany Liebenow colleagues[37] forty-five healthy adults (ages 18-65) recruited complete sure-bet gamble task (Figure 7.1).\nFigure 7.1: Schematic trial Sure Bet Gamble task subjective rating prompt. prospect presented random duration based Poisson distribution \\((\\lambda = 6\\text{s})\\). Assuming timely response, choice screen shown two seconds followed outcome screen one second. Trials separated fixation cross whose inter-trial interval random duration Poisson distribution \\(\\lambda = 3\\text{s}\\).\nthirty minutes, participants indicated preference sure bet (values $1-$6 $1 increments) fifty-fifty gamble two non-identical values ($0 - $6 $1 increments). lateral presentation sure bet gambles randomized, prospect presented random duration based Poisson distribution \\((\\lambda = 6\\text{s})\\). participant answered within alloted time, choice displayed two seconds shown outcome one second. answer time, shown late screen one second. Rounds separated fixation cross whose inter-trial interval Poisson distribution \\((\\lambda = 6\\text{s}\\), zeros removed\\()\\). one-third rounds choices made, respondents asked “feel last outcome?” adjusted slider ranging ‘bad’ ‘good.’ Participants paid $20 per hour told receive winnings randomly selected round bonus compensation.Using data task, can group remaining computational modeling steps three stages:[38]Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Parameter Estimation: Find set parameters best account experimental data given candidate model.Parameter Estimation: Find set parameters best account experimental data given candidate model.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.detailing methods results stage analysis, important understand mathematics behind model-fitting. general case, estimating model’s parameters decision-making task, want know parameter(s) best explain observed choices. tasks two outcomes, can represented binary choice vector choice option indicated 1 chosen 0 .Consider prospect depicted Figure 7.1. Given stated outcomes probabilities, can calculate counterfactual utilities option \\(\\gamma\\) value according Equations (6.2) (6.4). \\(0 \\leq \\gamma \\leq 0.5\\), can see utilities sure bet option ($3) gamble (50% chance $2 $5) Figure 7.2). , might assume people place low weight counterfactual information often choose gamble. point (\\(\\gamma \\approx 0.16\\)), individual equally likely choose either option. people place weight counterfactual information, likely choose sure bet prospect.\nFigure 7.2: Counterfactual utilities sample prospect sure bet gamble task simulated \\(0 \\leq \\gamma \\leq 0.5\\). Blue line represents counterfactual utility choosing ‘Sure Bet’ receiving three dollars; red line represents counterfactual utility choosing ‘Gamble’ 50 percent chance receiving two dollars five dollars. ‘indifference’ point choosing one option occurs \\(\\gamma \\approx 0.16\\).\nAlthough can determine utility option, peoples’ choice behavior fit model. means need determine likely parameter value give us observed data. help answer question, looked towards Bayesian statistics, offers way incorporate prior information parameters statistical model observed data define posterior probability distribution representing plausible parameter values.7The first step performing Bayesian inference construct prior probability model parameters interest. end fitting multiple models (e.g., perform model comparison), outline procedure general case using \\(\\theta\\) represent given model’s parameters. prior probability model, \\(\\pi(\\theta)\\) contains available information parameter’s distribution observing data. information come , example, previous experiments. information available, might assume uniform prior distribution, assigns equal probability values within defined range.next step Bayesian inference involves calculating likelihood observing data given set parameters, \\(\\theta\\). analysis, focused likelihood individual chose Option 1 (sure bet), represent follows:translate binary choice behavior likelihood, need way relating option’s utilities probability. can done softmax choice rule, logistic transformation difference utilities option:[41]\\(U_1, U_2\\) utilities (according proposed model CPUT EUT), \\(\\tau > 0\\) sensitivity parameter relates sensitive one’s choice difference utilities. complement Figure 7.2, can see probability choosing sure bet changes \\(\\gamma\\) (subsequently utility Option 1) increases:\nFigure 7.3: Probability choosing Option 1 (‘Sure Bet’) calculated logistic transformation difference utilities counterfactual utilities option shown Figure 7.2 across \\(0 \\leq \\gamma \\leq 0.5\\). \\(\\tau\\) increases, individuals likely maximize utility. Note ‘indifference’ point choosing one option occurs \\(\\gamma \\approx 0.16\\), regardless \\(\\tau\\).\nthird step Bayesian inference generate posterior distribution, \\(Pr(\\theta|\\text{Choices})\\), represents range likely range parameter values given observed choices. terms analysis, posterior distribution defined follows:probability \\(\\theta\\) value given observed choice data, posterior distribution \\(Pr(\\theta|\\text{Choices})\\), proportional to8 likelihood observing data given parameter value, \\(L(\\text{Chose Option 1}|\\theta)\\), times prior plausibility parameter value, \\(\\pi(\\theta)\\).estimate posterior distribution, used two ‘Markov Chain Monte Carlo’ methods. first attempt, manually implemented Metropolis-Hastings algorithm.[40,42] high level, Metropolis-Hastings algorithm involves following steps:iteration \\(n \\1:N\\) following:Propose value, \\(\\theta_n^*\\) near current estimate \\(\\theta_n\\), propose value \\(\\theta^*\\)Calculate acceptance probability proposal \\(\\theta_n^*\\) defined ratio posterior distribution evaluated \\(\\theta_n^*\\) \\(\\theta_n\\)Draw random number zero one. less equal acceptance probability, set \\(\\theta_{n+1} = \\theta_n^*\\), otherwise \\(\\theta_{n+1} = \\theta_n\\).validated implementation comparing posterior distributions computed hierarchical Bayesian approach. Hierarchical Bayesian Analysis implemented probabilistic programming language, Stan, implements efficient variant Markov Chain Monte Carlo called Hamiltonian Monte Carlo sampler.[43] Hierarchical Bayesian Analysis allows simultaneous estimation individual group-level parameters mutually-constraining fashion. shown improve parameter estimates relative methods (e.g., maximum likelihood estimation), resulting stable reliable estimates individual-level parameters informed group trends.[44]specific implementation hierarchical models follow detailed elsewhere.[45] high level, individual-participant parameters assumed drawn normally distributed group-level distributions. Bounded parameters, \\(\\gamma\\), estimated unconstrained space transformed ‘Matt Trick,’[43] inverse Probit transformation. optimize MCMC sampling.[45] formally,\\(- \\infty < \\mu_\\theta < + \\infty\\) \\(- \\infty < \\sigma_\\theta < + \\infty\\) group-level mean standard deviation, respectively; \\(\\theta^\\prime\\) unconstrained parameter gets transformed via inverse Probit transformation scaled upper bound, \\(U.B\\). example, \\(\\gamma\\), \\(U.B. = 1\\); \\(\\tau\\), \\(U.B. = 30\\). non-centered reparameterization results uniform prior individual participants’ parameters across full range.[45,46]better grasp concepts employed thesis, ’s time revisit three stages computational modeling introduced chapter introduction.[38] next chapter, outline methods results simulating choice data according counterfactual predicted utility theory, estimating parameters observed data, comparing evidence seven candidate models.","code":""},{"path":"modeling-methods-and-results.html","id":"modeling-methods-and-results","chapter":"8 Modeling Methods and Results","heading":"8 Modeling Methods and Results","text":"Using computational modeling techniques introduced previous chapter, examined ability counterfactual predicted utility theory explain human choice behavior sure bet gamble task[37]. chapter, describe implemented three stages Wilson Collins previously described.[38] first step: simulating choice behavior generated counterfactual predicted utility theory confirm experimental design elicits behaviors assumed model.","code":""},{"path":"modeling-methods-and-results.html","id":"simulating-choice-data","chapter":"8 Modeling Methods and Results","heading":"8.1 Simulating Choice Data","text":"first step simulate choice data sure-bet gamble task, looked results Kahneman Tversky’s prospect theory[4] paper search information inform prior distribution. Although record subject’s response specific prospects, Kahneman Tversky report proportion people chose option. nine prospects follow form depicted Figures 6.1 6.2, used reported proportions simulate choice behavior one-hundred subjects.assumed \\(\\gamma\\) uniformly distributed zero one fixed softmax sensitivity parameter, \\(\\tau = 1\\). ran ten-thousand iterations using Metropolis-Hastings algorithm described previous chapter. posterior distribution, depicted Figure 8.1, approximates \\(\\text{Beta}(1.1,1.1)\\) distribution. means , estimating \\(\\gamma\\) choice proportion data Kahneman Tversky, ’s plausible \\(\\gamma\\) value zero one, though little less likely towards tails.\nFigure 8.1: Posterior distribution \\(\\gamma\\) estimated ten-thousand iterations Metropolis-Hastings algorithm assuming uniform prior choice proportion data Kahneman Tversyk’s prospect theory[4]. posterior distribution (orange-red line) approximated \\(\\text{Beta}(1.1,1.1)\\) distribution (blue-gray), indicating slightly less plausibility \\(\\gamma\\) values near bounds zero--one interval relative central values.\nGiven task design, participants saw random subset 252 prospects. posterior distribution \\(\\gamma\\) recovered Kahneman Tversky’s choice proportion data used generate \\(\\gamma\\) values fifty subjects. simulated choices 252 prospects, fixing softmax sensitivity parameter \\(\\tau = 1\\). five-thousand iterations Metropolis-Hastings algorithm, sampled posterior distribution simulated subject.9 simulated choice data, also fit hierarchical Bayesian model Stan non-centered reparameterization described computational modeling concepts chapter. ran Hamiltonian Monte Carlo (Stan) sampler 5000 iterations across four parallel sampling chains total 20,000 samples posterior.10 Figure 8.2 shows 95% highest density interval recovered sampler’s posterior distribution.\nFigure 8.2: 95 percent highest density interval posterior distribution \\(\\gamma\\) estimated five-thousand iterations Metropolis-Hastings algorithm five-thousand iterations across four parallel chains Hamiltonian Monte Carlo Sampler (estimated using Stan). simulated gamma values subject represented sky-blue dots fall within highest density interval red dots fall outside .\nsubjects, simulated \\(\\gamma\\) values within highest-density interval. suggests sure-bet gamble task able elicit behaviors interest way measurable counterfactual predicted utility theory.","code":""},{"path":"modeling-methods-and-results.html","id":"parameter-estimation","chapter":"8 Modeling Methods and Results","heading":"8.2 Parameter Estimation","text":"confirmation able accurately recover simulated parameters sure-bet gamble task, move next stage computational modeling, parameter estimation. Specifically, compare counterfactual predicted utility theory explains human choice data sure-bet gamble task relative expected utility theory. primarily two reasons:Counterfactual predicted utility theory suggests , \\(\\gamma = 0\\), counterfactual utility option equivalent expected value. expected value special case expected utility theory risk aversion parameter, \\(\\rho = 1\\).sure-bet gamble task include losses, prohibits comparing counterfactual predicted utility theory prospect theory.total, estimated parameters seven variants expected utility theory counterfactual utility theory human choice data (Table 8.3).\nFigure 8.3: Parameters , description , different models fit human choice data sure-bet gamble task. models sampled Stan 5000 iterations across four parallel chains using hierarchical implementation. Individual parameters drawn normally distributed group-level distribution bounded inverse Probit transformation resulting uniform prior spanning zero one \\((\\gamma)\\), two \\((\\rho)\\), thirty \\((\\tau)\\).\nmodels sampled 5000 iterations across four parallel chains hierarchical Bayesian model formulation previously described.[45] model, chain convergence group-level transformed individual-level parameters checked Gelman-Rubin statistics, \\(\\hat{R} \\leq 1.1\\), suggesting -chain variance lower within chain variance.[47] group-level posterior distributions parameters fit model shown Figure 8.4.\nFigure 8.4: Posterior distribution group-level parameter estimates model. Distributions \\(\\gamma\\) green, \\(\\rho\\) blue, \\(\\tau\\) orange.\n","code":""},{"path":"modeling-methods-and-results.html","id":"model-comparison","chapter":"8 Modeling Methods and Results","heading":"8.3 Model Comparison","text":"estimated posterior distributions model type, sought determine model best explains choice behavior. , used three different methods compare models, results summarized Table 8.5:Posterior predictive checks , model, simulated choices given (joint) posterior distribution participants’ estimated model parameter(s). included Stan’s generated quantities block, executed posterior sample generated.[43] compared percentage predicted choices matches observed data summarized mean standard deviation model.Posterior predictive checks , model, simulated choices given (joint) posterior distribution participants’ estimated model parameter(s). included Stan’s generated quantities block, executed posterior sample generated.[43] compared percentage predicted choices matches observed data summarized mean standard deviation model.Comparing marginal likelihoods model. probability observing choice behavior given model, \\(M\\), \\(P(\\text{Choices}|M)\\). marginal likelihood model estimated using bridge sampling.[48] Marginal likelihoods often included calculations Bayes factors, describes relative evidence favor one model another quantifying ratio probability observing data given two models. marginal likelihoods computed log-scaled computational efficiency, means positive, less negative, marginal likelihood indicates better fit.Comparing marginal likelihoods model. probability observing choice behavior given model, \\(M\\), \\(P(\\text{Choices}|M)\\). marginal likelihood model estimated using bridge sampling.[48] Marginal likelihoods often included calculations Bayes factors, describes relative evidence favor one model another quantifying ratio probability observing data given two models. marginal likelihoods computed log-scaled computational efficiency, means positive, less negative, marginal likelihood indicates better fit.Assessing penalized model fit model’s leave-one-cross validation predictive accuracy.[49] approximated importance sampling posterior distribution calculate expected log pointwise predictive density (ELPD), logged sum pointwise posterior predictive distribution held data. multiplying ELPD negative two, get leave-one-information criterion, LOOIC. transformation makes easier compare information criterion (e.g., AIC, DIC), highlighting penalization model complexity.[50] include ELPD LOOIC easy comparison. Note less negative ELPD smaller (closer zero) LOOIC indicative better model fits.Assessing penalized model fit model’s leave-one-cross validation predictive accuracy.[49] approximated importance sampling posterior distribution calculate expected log pointwise predictive density (ELPD), logged sum pointwise posterior predictive distribution held data. multiplying ELPD negative two, get leave-one-information criterion, LOOIC. transformation makes easier compare information criterion (e.g., AIC, DIC), highlighting penalization model complexity.[50] include ELPD LOOIC easy comparison. Note less negative ELPD smaller (closer zero) LOOIC indicative better model fits.\nFigure 8.5: Parameters , description , different models fit human choice data sure-bet gamble task along model comparison metrics. Posterior predictive choice accuracy represents mean standard deviation correctly predicted choices individual participants given simulations (joint) posterior distribution. ELPD Predictive Density LOOIC details well models perform unobserved data (leave-one-cross validation). Parantheses ELPD LOOIC indicate Monte Carlo sampling error. Marginal likelihood model evidence indicates plausibility data given model parantheses representing interquartile range likeihood estimations. general, better models smaller LOOIC higher posterior predictive choice accuracy, ELPD predictive accuracy (less negative), marginal likelihood model evidence (less negative). CPUT + Softmax Sensitivity EUT + Softmax Sensitivity highlighted easy reference discussed.\ntwo rows highlighted Table 8.5, represent direct comparison contractual predicted utility theory expected utility theory. metrics presented pose interesting problem blanket statement ‘better model’ smaller LOOIC higher (less negative) posterior predictive choice accuracy, ELPD, marginal likelihood model evidence, model fit metrics pose interesting problem.average, — fact, models — accurately predict 80% observed choices using posterior predictive distribution. look either ELPD LOOIC, see expected utility model performs better. Looking marginal likelihood, however, counterfactual predicted utility model seems better. seemingly disparate indicators make sense considering metric represents. next chapter, conclude thesis discussion results outline next steps contribute towards better understanding neurobiological basis decision-making risk.","code":""},{"path":"discussion-next-steps.html","id":"discussion-next-steps","chapter":"9 Discussion & Next Steps","heading":"9 Discussion & Next Steps","text":"modeling results described last chapter highlight nuances model comparison terms predicting choice behavior sure-bet gamble task. ‘CPUT + Softmax Sensitivity’ estimated joint posterior distribution \\(\\gamma\\) \\(\\tau\\) ‘EUT + Softmax Sensitivity’ model fit joint posterior distribution \\(\\rho\\) \\(\\tau\\). CPUT model seemingly offers better explanation observed data. Indeed, log Bayes Factor 48.6, provides fair amount evidence favor CPUT EUT. , examining hypothesis \\(\\gamma > 0\\) evidence favor CPUT, can look average posterior distributions (depicted Figure 8.4 see don’t contain zero.11 time, ELPD LOOIC suggest expected utility theory better approximation unobserved choice data. means asked new person complete sure bet gamble task, expected utility theory may better predict data.culmination goal develop neurobiologically plausible theory decision-making risk counterfactual predicted utility theory, CPUT. acknowledge evidence presented insufficient conclude CPUT better theory decision-making risk EUT, seem offer better explanation data collected part sure-bet gamble task. fact able provide evidence supporting CPUT generative theory decision-making exciting!concluding future directions investigating CPUT, want highlight things:complex models necessarily better. Referring back Table 8.5, please note model best fits observed choice data according marginal likelihood one estimated joint posterior distribution \\(\\gamma, \\tau,\\) \\(\\rho\\), ‘CPUT + Risk Aversion + Softmax Sensitivity.’ inclusion additional parameter improve overall posterior predictive choice accuracy impaired ELPD predictive density LOOIC. reason, avoid drawing conclusions (relatively, least) overfit model, pay considerable attention .complex models necessarily better. Referring back Table 8.5, please note model best fits observed choice data according marginal likelihood one estimated joint posterior distribution \\(\\gamma, \\tau,\\) \\(\\rho\\), ‘CPUT + Risk Aversion + Softmax Sensitivity.’ inclusion additional parameter improve overall posterior predictive choice accuracy impaired ELPD predictive density LOOIC. reason, avoid drawing conclusions (relatively, least) overfit model, pay considerable attention .consensus neural correlates risk-aversion still debatable. 2009, Christopoulous colleagues reported activity interior frontal gyrus, located near dorsolateral prefrontal cortex, reflected subjective perception option’s riskiness objective evaluation risk. , describe signals inferior frontal gyrus integrate areas, striatum found sensitive changes magnitude, inform choice behavior.[51] hand, Niv colleagues find behavioral neural evidence risk sensitivity involving nonlinear utility functions.[52] One possibility mention referencing Matthew Rabin Richard Thaler’s 2001 paper risk aversion[53] general incompatability nonlinear utility functions small magnitudes.[[52];] However, Rabin Thaler assume strict expected utility maximizer, observed data (e.g., softmax sensitivity parameter reflect deterministic choices).consensus neural correlates risk-aversion still debatable. 2009, Christopoulous colleagues reported activity interior frontal gyrus, located near dorsolateral prefrontal cortex, reflected subjective perception option’s riskiness objective evaluation risk. , describe signals inferior frontal gyrus integrate areas, striatum found sensitive changes magnitude, inform choice behavior.[51] hand, Niv colleagues find behavioral neural evidence risk sensitivity involving nonlinear utility functions.[52] One possibility mention referencing Matthew Rabin Richard Thaler’s 2001 paper risk aversion[53] general incompatability nonlinear utility functions small magnitudes.[[52];] However, Rabin Thaler assume strict expected utility maximizer, observed data (e.g., softmax sensitivity parameter reflect deterministic choices).posterior distributions model show relatively small shifts. example, posterior density \\(\\tau\\) similar, aggregating around 1.2 ‘Expected Value + Softmax Sensitivity,’ ‘CPUT + Softmax Sensitivity,’ ‘CPUT + Risk Aversion + Softmax Sensitivity’ models. suggests random choice behavior compared ‘EUT + Softmax Sensitivity’ model clusters around two. suspect trend arises association deterministic choice behavior (utility maximization; higher \\(\\tau\\)) risk-averse behavior (smaller \\(\\rho\\)) potential area future research.12The posterior distributions model show relatively small shifts. example, posterior density \\(\\tau\\) similar, aggregating around 1.2 ‘Expected Value + Softmax Sensitivity,’ ‘CPUT + Softmax Sensitivity,’ ‘CPUT + Risk Aversion + Softmax Sensitivity’ models. suggests random choice behavior compared ‘EUT + Softmax Sensitivity’ model clusters around two. suspect trend arises association deterministic choice behavior (utility maximization; higher \\(\\tau\\)) risk-averse behavior (smaller \\(\\rho\\)) potential area future research.12To now entertain possibility CPUT provides mechanistic explanation choice behavior, discussing EUT, want focus outstanding questions involving potential neurobiological mechanisms. Specifically, hitherto unanswered question Kishida colleagues 2016 paper[32] surrounds mechanism counterfactual prediction errors reward prediction errors integrated. One possibility proposed Montague, Kishida, colleagues serotonin system.[54] describe ‘opponent-processing framework’ reward prediction errors counterfactual prediction errors independently encoded distinct neural systems integrated exchange dopamine predominantly serotonergic neurons vice versa (e.g., cross-loading).[54,55]2021, Kishida Sands proposed valence-partitioned reinforcement learning framework part ‘Dynamic Affective Core’ makes explicit predictions dopaminergic system interact opponent one inform choice behavior situations multi-valenced outcomes also associated subjective experiences feelings.[56] valence-partitioned framework provides another basis investigating asymmetric choice behavior decisions involving gains losses.[4,41] Although neural correlates behavior still investigation, hypothesized involve striatum[57] amygdala, area brain often associated anxiety fear.[58,59]extend work presented , hope incorporate ideas valence-partitioned reinforcement learning counterfactual signaling literature. Working towards goal developing neurobiological theory decision-making risk, next look CPUT predicts choices involving losses. CPUT’s predictions generalize gain loss domain, hope conduct neuroimaging study identify neural correlates CPUT. Fortunately, pretty good idea look.","code":""},{"path":"references.html","id":"references","chapter":"10 References","heading":"10 References","text":"","code":""}]
