[{"path":"index.html","id":"dedication-and-acknowledgements","chapter":"1 Dedication and Acknowledgements","heading":"1 Dedication and Acknowledgements","text":"dedicate thesis mom, Joanne Fink, grandpa, Dr. Gordon Fink. person without love guidance. Plus, excellent proof-readers, always appreciate! love .May 2022, graduate Master Science Degree Neuroscience Wake Forest School Medicine. website embodiment master’s thesis. None possible incredible support mentors, family, friends.First foremost, ’d like thank Ken Kishida. ’ve conducting research since February 2018 incredibly appreciative encouragement support. Dr. Kishida given space follow interests programming neuroscience especially, website embodiment . Within Kishida Lab, conversations L. Paul Sands greatly informed modeling techniques, appreciative. Emily DiMarco, Rachel Jones, Angela Jiang, Brittany Liebenow provided feedback guidance developed thesis.undergraduate, Lucy McGowan, S. Mason Garrison, Staci Hepler immeasurable impact understand, conduct, scientific programming, Bayesian inference, data analysis. Katy Lack, Melissa Maffeo, Wayne Pratt, Terry Blumenthal fostered interest Neuroscience. extremely grateful learned .’d next like thank committee members, Drs. Christian Waugh Todd McFall (Ken Kishida!) support guidance ’ve worked thesis. input made much better. Also, Nathaniel Haines’s publications greatly improved understanding underlying mathematics behind computational modeling provided invaluable feedback work.family, love support everything. Thank .","code":""},{"path":"abstract.html","id":"abstract","chapter":"2 Abstract","heading":"2 Abstract","text":"thesis, combine insights economics, pyschology, neuroscience develop ‘Counterfactual Predicted Utility Theory’ (CPUT) neurobiologically-plausible theory decision-making risk. CPUT inspired observation sub-second fluctuations levels neurotransmitter dopamine seemingly reflect factual counterfactual information. propose people incorporate anticipated counterfactual events making risky decisions. leads behavior considered ‘irrational’ classical economic perspective described Expected Utility Theory (EUT). assess counterfactual predicted utility theory’s validity theory decision-making risk, compared variations CPUT EUT human choice data sure-bet gamble task using hierarchical Bayesian modeling techniques. quantified model fit multiple methods. includes comparing marginal likelihood model evidence leave-one-cross validation predictive accuracy. Compared EUT, found CPUT offer better explanation data collected, generalize well. However, sure-bet gamble task limits analysis gain domain, decreasing range counterfactual information available. research neurobiological mechanisms processing factual counterfactual information downstream behavioral consequences warranted.","code":""},{"path":"introduction.html","id":"introduction","chapter":"3 Introduction","heading":"3 Introduction","text":"make choices every day. eat, whether take one route work, go sleep, just examples. Every decision associated consequences. Consequences inherently rewarding (appetitive), punishing (aversive), . understand processes involved human decision-making, use quantitative frameworks study choice behavior. analytic approaches primarily formalized three disciplines: economics, psychology, neuroscience.experimental literature, two types decision contexts described. “decisions risk,” decision-maker knows precision probability distribution possible outcomes. “decisions uncertainty,” decision-maker must infer probabilities potential outcomes. thesis, combine insights economics, psychology, neuroscience propose neurobiologically-plausible theory decision-making risk.next chapters, outline evolution decision-theory classical economic models behavioral economic ones. describe influences behavioral economic theories neuroscience research discuss potential neural mechanisms decision-making. neurobiological inspiration, propose new theory decision-making risk called ‘Counterfactual Predicted Utility Theory.’ Next, detail concepts, methods, computational modeling results estimate theory’s validity human choice data sure-bet gamble task. Lastly, discuss results propose next steps continuing work.","code":""},{"path":"evolution-of-decision-theory.html","id":"evolution-of-decision-theory","chapter":"4 Evolution of Decision Theory","heading":"4 Evolution of Decision Theory","text":"Imagine casino. asked play new type roulette. time , cost participating. rules simple: pick red option black option. choose red option, dealer give three-thousand dollars. pick black option, dealer spin wheel release ball. wheel weighted 80% chance getting four-thousand dollars 20% chance getting zero dollars. option choose? ?economic theorist, bet choose black option higher expected value. Expected values, \\(EV\\), calculated multiplying magnitude, \\(x\\), outcome probability, \\(p\\), occur. example, red option leads three-thousand dollars certainty. black option leads four-thousand dollars 80% chance (probability 0.8).Looking expected values option calculated (4.1), see \\(\\text{EV}(\\text{Black}) > \\text{EV(Red)}\\). Therefore, rational choice according classical economist black option.new type roulette presented prototypical example prospect – choice two options explicit probabilities outcomes – used investigate decision-making risk. normative measure monetary reinforcements allows decision-researchers probe mechanisms underlying choice behavior. participants similar reference point, choosing option higher expected monetary payout straightforward (least mathematically speaking). However, decision accept risky gamble like one described may change ask someone annual income one-million dollars compared someone income fifty-thousand dollars.introduces idea diminishing marginal returns. value millionaire places certain three-thousand dollars (option 1 ) may enough dissuade probable four-thousand dollars. person, assured three-thousand dollars, though, much valuable gamble. idea formalized term ‘utility,’ coined Swiss mathematician Daniel Bernoulli. Utiity refers subjective “moral value” decision’s outcome. Bernoulli wrote:[1]price item dependent thing equal everyone; utility, however, dependent particular circumstances person making estimate.Bernoulli’s concept formed basis von Neumman Morgenstern’s Expected Utility Theory (EUT).[2] EUT suggest people – – choose manner maximizes expected utility. EUT axiomatized, validity called question. Notably, Allais paradox suggests rationality defined maximizing expected utility neglects specific element psychology risk: variance individuals’ psychological values.[3]1979, Daniel Kahneman Amos Tversky published Prospect Theory: Analysis Decision Risk.[4] Prospect theory critiqued descriptive validity EUT. Kahneman Tversky highlighted systematic ways people violated EUT. , initiated field behavioral economics – wedding insights psychology quantitative models economics – better understand human choice behavior.Kahneman Tversky describe multiple deviations EUT. Notably, discuss certainty reflection effects. certainty effect describes people overweight outcomes considered certain relative probable ones. reflection effect – commonly known ‘loss aversion’ – accounts peoples tendency risk averse positive prospects risk seeking negative ones. addition effects, one key takeaway prospect theory value function corresponds changes wealth welfare, rather final states. value function, concave gains convex losses, losses steeper gains (goes hand--hand reflection effect).application behavioral insights theories human decision-making necessitate emotional component. discussed Graham Loomes Robert Sugden 1982 paper, Regret Theory: Alternative Rational Choice Uncertainty, anticipatory feelings regret used inform decisions.[5]1 Loomes Sugden’s describe idea choosing one option preference cost forgoing opportunities.2 theory introduces concept counterfactual thinking, explicit comparison present state world alternative states.[7,8]revisit casino example, feel chose black option (gambling four-thousand dollars) lost? chosen red option three-thousand dollars certain, forewent opportunity chance something . comparison “” vs. “might ” captures idea counterfactual information.summarize material chapter:recounted high-level overview choice theory, described expected values calculated, introduced importance subjective measures (utility) studying choice behavior.introduced EUT classical economist’s theory decision-making risk.Next, covered origin behavioral economics Kahneman Tversky’s prospect theory improve descriptive models choice behavior.concludes chapter covering regret theory necessity accounting subjective emotions choice models.next chapter, outline recent work looking neurobiological basis decision-making show evidence specific neural systems track counterfactual signals.","code":""},{"path":"neurobiology-of-decision-making.html","id":"neurobiology-of-decision-making","chapter":"5 Neurobiology of Decision-Making","heading":"5 Neurobiology of Decision-Making","text":"previous chapter, used term prospect describe problem two options stated probabilities outcomes. experimental literature, prospects called ‘description-based.’ Researchers use description-based prospects experiments ask participants select one available options presented along complete description non-trivial problem.[9]looking towards neuroscientific literature decision-making, different type experimental paradigm perhaps common: ‘experiential’ ‘feedback-based’ decisions.[9]. interacting environment, humans (animals) associate consequences different actions adapt behavior accordingly. words, learn. learn time want eat sushi dinner, ’s faster take highway work, ’re better go sleep midnight.3That behavior (action decision) predicated upon prior experiences allows us formalize relationship states. , use state reference representation stimuli. example, state \\(s \\S\\) time \\(t\\) (\\(s_t\\)) may comprised internal states (hunger, thirst, fatigue) external ones (light, music, temperature).Consider Pavlov’s experiment showed repeatedly giving dog food ringing bell condition dog salivate bell rung.[10] means , time, behavior elicited stimulus (food) can evoked previously neutral stimulus (bell). one first attempts empirically describe process, Bush Mosteller suggest probability Pavlov’s dog salivating, \\(P(\\text{sal})\\), next presentation food bell (next trial, \\(tr+1\\)) function happened last presentation (last trial, \\(tr-1\\)) discounted experienced presentation (food reward trial, \\(R_{tr}\\).[11,12]Equation (5.1) computes average previously experienced rewards. \\(0 \\leq \\alpha \\leq 1\\) learning rate, modulates influence recent rewards. Bush Mosteller’s work forms basis modern approaches problem reinforcement learning.[13]4 discretizing learning trials logical first step modeling behavior experimental settings, ’s easily applied biological systems continuously interact environments.1988 paper, Learning Predict Methods Temporal Differences, Richard Sutton introduces antecedent temporal-difference reinforcement learning (TDRL) algorithms.[14] TDRL algorithm provides computational framework optimally learning experience actions associated stimuli lead rewards.[15]‘goal’ TDRL algorithms estimate value state use information maximize rewards. achieved ‘teaching signal,’ called temporal-difference reward prediction error (TD-RPE), relates value state time \\(t\\) expected previously.concept perhaps best illustrated example. Imagine order food favorite restaurant. ’ve tried every item menu, order favorite dish.5 ’ve ordered much, certain expectation item smells like, tastes, state contentedness feel eating .represent intrinsic value eating food time \\(t\\) \\(V(S_t)\\). describe economic terms, expected value eating favorite dish. Fortunately, time come food ready! open container notice something quite smell right. , experience, \\(\\text{outcome}_t\\), negative. expected fragrant odor faced something else. words, expected something better experienced. time, expectation future enjoyment, \\(V(S_{t+1})\\) still high. Maybe, think, odd smell comes container food . , remain hopeful enjoyable meal.idea presented preceding paragraph encapsulated Equation (5.2) defines TD-RPE, \\(\\delta_t\\), difference current value state time \\(t\\) expected. summarize notation:value state sum experience (e.g., displeasing odor, \\(\\text{outcome}_t\\)) expectation future values, \\(V(S_{t+1})\\). value future states modulated temporal-discounting parameter \\(0 \\leq \\gamma \\leq 1\\) preferentially weights immediate outcomes relative future ones.6The expectation state, \\(V(S_t)\\), (e.g., incredible culinary experience) based prior experiences.time step, \\(\\delta_t\\) used update estimated value current state formulated (5.3).Whereas Equation (5.1), learning rate \\(0 \\leq \\alpha \\leq 1\\) ascribed weight recent rewards recently relative experienced distant past. contrast, TDRL learning rate (also \\(0 \\leq \\alpha \\leq 1\\)) controls much weight individual places estimated value current state light TD-RPE. Put another way, controls much update future expectation given recent experience.1990s, Read Montague, Peter Dayan, colleagues showed evidence suggesting TD-RPEs encoded fluctuations activity mesencephalic dopaminergic neurons.[19,20] implication dopaminergic system might encode TD-RPEs became known TD-RPE hypothesis dopamine neurons consistent behavioral neural results rodents,[21] non-human primates,[22–25] humans.[26–29] biologically conserved mechanism experiential learning, can investigate neural basis choice behavior empirically TDRL algorithms. 2011, experiments saw exciting development Ken Kishida colleagues used fast-scan cyclic voltammetry measure dopamine fluctuations human striatum sub-second temporal resolution.[27]combination 2016 paper, Kishida colleagues studied dopamine levels humans undergoing elective surgery part deep-brain stimulation treatment.[27,30] Participants viewed graphical depiction (fictitous) stock market’s price history (Figure 5.1; B) asked choose much portfolio (initially valued $100) invest. six ‘markets,’ twenty-decisions, participants used handheld button boxes (Figure 5.1; ) increase decrease investment ten-percent increments. Decisions made light three pieces information sub-second changes dopamine concentrations recorded striatum:history market price (Figure 5.1; red-trace panel B)current portfolio value (Figure 5.1; bottom left box, 126, panel B)recent fractional change portfolio value (Figure 5.1; bottom right box, 15.2%, panel B).\nFigure 5.1: Participants played sequential-choice game surgery using button boxes (; Left) visual display (; Right). patient, bet size adjustments (e.g., increase bet decrease bet) decision submit one’s answer performed button boxes. (B) Graphical depiction market price history (red trace), current portfolio value (bottom left box), recent outcome (bottom right box) sequential investment task (C) Timeline events single round investment game. Reprinted permission Kishida et al., 2016.\n2011 paper, asked one person, MH, complete sequential investment task. line prior work relating dopamine unexpected financial outcomes,[26] Kishida colleagues observed strong correlation MH’s dopamine levels market value investment task.[27] 2016, Kishida colleagues published results seventeen humans. , explicitly tested hypothesis fluctuations dopamine released human striatum encode TD-RPEs.[30] sequential investment task, RPEs calculated difference investment’s return given trial relative expectation defined average return preceding trials.Contrary hypothesis dopamine fluctuations striatum track TD-RPEs,[19,21,31–34] authors found dopamine fluctuations encode integration RPEs counterfactual prediction errors (CPEs). discussed last chapter, counterfactual signals explicit comparison present state alternative ones.[7,8] sequential investment task, CPEs defined difference participant’s actual return trial invested less. means dopamine release result integration RPEs CPEs given trial. Formally:\\(b_{tr}\\) individual’s factional investment trial \\(tr\\) \\(r_{tr}\\) relative change market price. Kishida colleagues note, intuition Equation (5.4) better--expected outcomes (positive RPEs, increased dopamine release), even better (positive CPEs) reduced value. Similarly, worse--expected outcomes (negative RPEs, decreased dopamine release), even worse (negative CPEs) increased value. Importantly, empirical terms consistent subjective feelings (e.g., regret relief), one experiences light given outcome.\nFigure 5.2: RPE encoding dopamine transients invert function bet size. Dopamine responses equal absolute magnitude positive negative RPEs bets high (Left), medium (Center), low (Right). three plots, mean normalized dopamine responses standard errors shown positive RPEs (green traces) negative RPEs (red traces). Reprinted permission Kishida et al., 2016.\nFigure 5.2 depicts changes dopamine levels function bet size. Consider ‘higher bets’ panel (left) individuals bet close maximum amount possible. rewarded positive change portfolio value, dopamine concentrations increased (green; positive RPEs). Similarly, portfolio value decreased, dopamine levels dipped (red; negative RPEs). high bets (left panel, bets \\(90\\%-100\\%\\) portfolio value), difference earned earned bet minimal, CPE. medium bets (middle panel, \\(60\\%-80\\%\\)), however, difference individuals experienced experienced bet increases. means absolute magnitude CPE goes subtracts dopamine release predicted positive negative RPEs. CPEs maximal (small bets, \\(10\\% - 50\\%\\); right panel), observe inversion dopamine release response positive negative RPEs.‘superposed error signals actual counterfactual reward’ described Kishida colleagues’ paper[30] directly inspired thesis work. provide empirical, neurobiologically plausible framework investigating decision-making risk. theoretical quantitative underpinnings classical behavioral economic theories decision-making align well computational reinforcement learning literature described chapter. explicit probability outcome structure risky prospects afford opportunity internalize future states (potentially) incorporate anticipated counterfactual events decision-making process. next chapter, derive ‘Counterfactual Predicted Utility Theory’ new theory decision-making risk.","code":""},{"path":"counterfactual-predicted-utility-theory.html","id":"counterfactual-predicted-utility-theory","chapter":"6 Counterfactual Predicted Utility Theory","heading":"6 Counterfactual Predicted Utility Theory","text":"discussed neurobiology decision-making chapter, neurotransmitter dopamine seemingly encodes information actual counterfactual rewards,[30] integration may play guiding role decision-making. neural evidence, combined behavioral economic theories offering descriptive models people making risky decisions,[4,5] propose ‘Counterfactual Predicted Utility Theory’ (CPUT) neurobiologically-plausible theory decision-making risk.impetus behind CPUT idea people account counterfactual outcomes faced prospect integration factual counterfactual signals brain may discount invert preference choosing one option another. hypothesize preference-reversal modulated counterfactual weighting term, \\(\\gamma\\), may vary across people.formally derive CPUT, can revisit prospect introduced first chapter hypothetical casino game. two options: choosing one certainly three-thousand dollars; choosing another give 80% chance four-thousand dollars nothing. prospect commonly denoted follows first option leads outcome \\(x_1\\) probability \\(p_1\\) second option leads outcomes \\(x_2\\) probability \\(p_2\\).Following conventional notation, alternative outcomes option assumed zero. , choosing Option 1 choice receiving \\(x_1\\) probability \\(p_1\\) nothing probability \\((1 - p_1)\\). true, however, CPUT formulated generalizable representation prospect depicted Figure 6.1. , Option 1 choice receiving \\(x_{1a}\\) probability \\(p_1\\) \\(x_{1b}\\) probability \\((1 - p_1)\\). Similarly, Option 2 choice receiving \\(x_{2a}\\) probability \\(p_2\\) \\(x_{2b}\\) probability \\((1 - p_2)\\).\nFigure 6.1: Explicit representation prospect two options. Choosing option 1 may lead outcome \\(x_{1a}\\) probability \\(p_1\\) outcome \\(x_{1b}\\) probability \\((1 - p_1)\\). Choosing option 2 may lead outcome \\(x_{2a}\\) probability \\(p_2\\) outcome \\(x_{2b}\\) probability \\((1 - p_2)\\).\nrepresentation, can begin formally define option’s counterfactual utility, \\(U_C\\), follows:Similarly, define Expected Utility follows Equation (6.3) represents weighting probabilities outcomes Equation (6.2).difference equations value estimates outcome. Expected Utility Theory exponentiates stated outcome magnitude risk sensitivity parameter, \\(\\rho\\).7 CPUT, define transformation stated outcome face value minus weighted sum option’s alternative outcome option’s expected value. notation expressed Equation (6.4), shows prospect form depicted Figure 6.1 represented.Unlike value estimate Expected Utility Theory, \\(V_E\\), estimated counterfactual utility value, \\(V_C\\) one--one mapping stated outcomes. provide better intuition within- -option dependency, helpful consider concrete example. adapting Figure 6.1 include values casino example initially described, can better see possible outcome may integrate evaluating given prospect.\nFigure 6.2: Example prospect diagram visualize counterfactual integration. Choosing option 1 may lead outcome \\(\\$3000\\) probability \\(1.0\\) outcome \\(\\$0\\) probability \\((1 - 1.0)\\). Choosing option 2 may lead outcome \\(\\$4000\\) probability \\(0.8\\) outcome \\(\\$0\\) probability \\((1 - 0.8)\\). Estimating counterfactual utility value possible outcomes dependent one-another.\nillustrate CPUT walking-Figure 6.2, let’s assume counterfactual-weighting term \\(\\gamma = 0.35\\). means stated outcomes transformed given available counterfactual information potential outcome follows:values combined Equation (6.2), see \\(U_C(\\text{Option 1}) > U_C(\\text{Option 2})\\):maximize utility, choose Option 1 progress diagram first node left-hand side. , forwent opportunity Option 2. chose differently, reached node right, expected value $3200, didn’t. , nodes right-hand side diagram counterfactual events. walking-example, hoped convey possible outcomes relate one-another factual counterfactual information may integrated inform one’s decision.Importantly, equations suggest \\(\\gamma = 0\\), one places weight counterfactual events, counterfactual utility equivalent expected value. words, \\(\\gamma = 0\\), \\(U_C(\\text{Option 1}) = EV(\\text{Option 1})\\) \\(U_C(\\text{Option 2}) = EV(\\text{Option 2})\\). people don’t place weight counterfactual information, might expect choice behavior consistent maximizing expected value (, better compare theories decision-making, maximizing expected utility). provide evidence support CPUT generative theory decision-making, test hypothesis \\(\\gamma > 0\\) means people consider counterfactual outcomes faced risky prospect.summarize discussed chapter:addressed first thesis aim developing counterfactual predicted utility theory (CPUT) alternative expected utility theory explain decision-making risk.showed information potential outcome (terminal node Figure 6.1) integrates counterfactual weighting parameter, \\(\\gamma\\), adjust utility one option another.walked-example calculation assuming \\(\\gamma = 0.35\\) (diagrammed Figure 6.1).next chapter, begin address second thesis aim assessing descriptive predictive validity CPUT using human choice data ‘Sure Bet Gamble’ task.[35]","code":""},{"path":"computational-modeling-concepts.html","id":"computational-modeling-concepts","chapter":"7 Computational Modeling Concepts","heading":"7 Computational Modeling Concepts","text":"attempt robustly, transparently, fit CPUT behavioral data, follow general guidelines presented Robert Wilson Anne Collins’s paper Ten simple rules computational modeling behavioral data.[36]high level, state computational modeling allows us make better sense behavioral data mathematical models may provide insight mechanisms underlying behavior. Although exact form models may differ, basic process assessing model’s descriptive predictive efficacy similar.first two steps Wilson Collins discuss designing experiment developing model. thesis, fit CPUT data collected ongoing study Brittany Liebenow colleagues[35] forty-five healthy adults (ages 18-65) recruited complete sure-bet gamble task (Figure 7.1).\nFigure 7.1: Schematic trial Sure Bet Gamble task subjective rating prompt. prospect presented random duration based Poisson distribution \\((\\lambda = 6\\text{s})\\). Assuming timely response, choice screen shown two seconds followed outcome screen one second. Trials separated fixation cross whose inter-trial interval random duration Poisson distribution \\(\\lambda = 3\\text{s}\\).\nthirty minutes, participants indicated preference sure bet (values $1-$6 $1 increments) fifty-fifty gamble two non-identical values ($0 - $6 $1 increments). lateral presentation sure bet gambles randomized, prospect presented random duration based Poisson distribution \\((\\lambda = 6\\text{s})\\). participant answered within allotted time, choice displayed two seconds shown outcome one second. answer time, shown late screen one second. Rounds separated fixation cross whose inter-trial interval Poisson distribution \\((\\lambda = 6\\text{s}\\), zeros removed\\()\\). one-third rounds choices made, respondents asked “feel last outcome?” adjusted slider ranging ‘bad’ ‘good.’ Participants paid $20 per hour told receive winnings randomly selected round bonus compensation.Using data task, can group remaining computational modeling steps three stages:[36]Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Parameter Estimation: Find set parameters best account experimental data given candidate model.Parameter Estimation: Find set parameters best account experimental data given candidate model.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.detailing methods results stage analysis, important understand mathematics behind model-fitting. remaining sections chapter, discuss Bayesian inference can help us infer choice data plausible parameter values model.","code":""},{"path":"computational-modeling-concepts.html","id":"using-bayes-theorem-to-estimate-parameters-from-choice-behavior","chapter":"7 Computational Modeling Concepts","heading":"7.1 Using Bayes’ Theorem to Estimate Parameters from Choice Behavior","text":"Data sure bet gamble task represented binary variable. , prospect, someone chose option one (sure bet), denote 1. Otherwise, ’s 0. zero otherwise. example, someone’s choice behavior six prospects may look like :Given binary choice behavior, question becomes can estimate parameter(s) interest. answer Bayes’ Theorem! general case, Bayes’ Theorem states probability parameter interest, \\(\\theta\\), value given observed data proportional likelihood observing data given parameter value times prior plausibility parameter said value (Equation (7.1)).8We can rewrite Bayes’ Theorem context estimating counterfactual weighting term, \\(\\gamma\\) human choice data. , probability \\(\\gamma\\) value given observed choices proportional likelihood observing choice given \\(\\gamma\\) value times prior plausibility \\(\\gamma\\) value (Equation (7.2)).Bayesian inference, unknown parameters (e.g., \\(\\gamma\\)) considered random variables can relate observed data “likelihood function.[38] parameter interest assessing descriptive predictive validity CPUT using human choice data \\(\\gamma\\). defining prior plausibility \\(\\gamma\\), able incorporate existing information modeling.Prior information may influenced previous experiments. , make assumptions distribution \\(\\gamma\\) light potential data-generating model, CPUT. Specifically, idea people account counterfactual information making decisions, assume \\(\\gamma \\ge 0\\). assume people place weight counterfactual outcomes relative factual ones. constrains \\(\\gamma \\le 1\\). Together, prior information incorporate models suggests values \\(0 \\leq \\gamma \\leq 1\\) equally plausible. , \\(\\gamma\\) distributed uniform distribution zero one.refine estimate \\(\\gamma\\) using Bayes’ Theorem, need way defining likelihood observing binary choice specific \\(\\gamma\\) value. likelihood describes statistical model assumed generate choice behavior, relating possible values \\(\\gamma\\) observed choices.[38]CPUT offers way determining utilities prospect’s options. order generate data, need likelihood function can transform utilities valid statistical model. number ‘action-selection’ methods[15]. One common psychological literature reinforcement learning field ‘soft-max’ choice rule: logistic transformation difference utilities option (Equation (7.3)).[39] introduces additional parameter, \\(\\tau > 0\\), relates sensitive one’s choice difference utilities. limit, \\(\\tau \\rightarrow \\infty\\), probability choosing option higher utility approaches 1.analysis, used softmax transformation likelihood function relate probability choosing option one, sure bet, \\(\\gamma\\). , mathematical description model used assess CPUT’s veracity, represented Equation (7.4), says:individual choice option 1 made probability \\(p\\), \\(p\\) determined softmax transformation counterfactual utilities option, \\(U_{C1}(\\gamma), U_{C2}(\\gamma)\\), sensitivity parameter, \\(\\tau\\), \\(\\tau\\) assumed uniform zero thirty, \\(\\gamma\\) assumed uniform zero one.","code":""},{"path":"computational-modeling-concepts.html","id":"visualizing-bayes-theorem-with-choice-datamodeling-concepts-2","chapter":"7 Computational Modeling Concepts","heading":"7.2 Visualizing Bayes’ Theorem with Choice Data9","text":"build intuition can estimate model’s parameters interest, can begin ‘Simulation & Parameter Recovery’ step described chapter introduction. Figure 7.2 depicts process simulating choice prospect included top Figure 7.1. first calculate counterfactual utilities prospect. Next, apply softmax choice rule translate utilities probability choosing either option. Lastly, ‘make’ choice flipping weighted coin.\nFigure 7.2: Depiction data generating process modeling choice behavior CPUT sure bet gamble task. left panel highlights first step counterfactual utilities calculated. middle panel shows softmax transformation utilities probability choosing either option; opacity logistic function increases softmax sensitivity parameter, \\(\\tau\\), signaling utility maximizing tendency. right panel conveys choice made ‘flipping weighted coin.’\nfitting model behavioral data, assume statistical model represents data generated. can therefore work backwards observing choices infer parameter values plausible given data. Bayes’ Theorem provides way update plausible parameter values choice observed.visualize concrete example , simulated nine choices sure bet three dollars fifty-fifty gamble two five dollars (top panel Figure 7.1) agent \\(\\gamma = 0.25\\) \\(\\tau = 2.2\\). given \\(\\tau\\), likelihood function assigns probability observing choice \\(\\gamma\\) value.Consider top left panel Figure 7.3. observing data, specified Equation (7.4), prior (black, dashed line) uniformly distributed zero one. first choice agent makes gamble. Multiplying prior likelihood choosing gamble gives us posterior plausibility \\(\\gamma\\) (purple, solid line). may notice posterior distribution panel resembles likelihood choosing gamble depicted Figure 7.2. prior distribution \\(\\gamma\\) initially uniform, one choice observed, posterior plausibility becomes likelihood.distribution becomes starting point future inference. next panel, model observes sure bet choice. recent plausibility (purple, dashed line) multiplied likelihood observing sure bet (depicted Figure 7.2) generate new posterior distribution (blue-purple, solid line). trend continues additional panel Figure 7.3: model observes new choice multiplies likelihood observing choice previous posterior plausibility \\(\\gamma\\).\nFigure 7.3: Bayesian model updates parameter estimates new observations. panel shows new choice simulated according CPUT \\(\\gamma = 0.25\\). model’s estimate \\(\\gamma\\) depicts relative plausibility value. panel, recent plausiblity (dashed line) multiplied likelihood observing latest choice produce posterior plausibility (solid line).\nNotice ‘sure bet’ choice shifts range plausible \\(\\gamma\\) rightwards gamble choice shifts leftwards. observation, variance curve decreases, height increases. highlights increasing evidence plausibility \\(\\gamma\\) values. seen bottom right panel Figure 7.3, ’re able get idea ‘true’ value \\(\\gamma\\) relatively little data!visualization, fixed \\(\\tau = 2.2\\), made easier estimate posterior probability \\(\\gamma\\). Simultaneously estimating multiple parameters often leads computationally intractable posterior distributions, however. next section, discuss family methods efficiently calculating joint posterior distributions known ‘Markov Chain Monte Carlo.’","code":""},{"path":"computational-modeling-concepts.html","id":"posterior-estimation-with-markov-chain-monte-carlo","chapter":"7 Computational Modeling Concepts","heading":"7.3 Posterior Estimation with Markov Chain Monte Carlo","text":"thesis, used two Markov Chain Monte Carlo methods. first, manually implemented method Metropolis-Hastings algorithm R.[37,41] high level, can boiled three steps repeated \\(n \\1:N\\) iterations:Propose value, \\(\\theta_n^*\\) near current estimate \\(\\theta_n\\), propose value \\(\\theta^*\\)Calculate acceptance probability proposal \\(\\theta_n^*\\) defined ratio posterior distribution evaluated \\(\\theta_n^*\\) \\(\\theta_n\\)Draw random number zero one. less equal acceptance probability, set \\(\\theta_{n+1} = \\theta_n^*\\), otherwise \\(\\theta_{n+1} = \\theta_n\\).validated implementation comparing posterior distributions computed hierarchical Bayesian approach. Hierarchical Bayesian Analysis implemented probabilistic programming language, Stan, implements efficient variant Markov Chain Monte Carlo called Hamiltonian Monte Carlo sampler.[42] Hierarchical Bayesian Analysis allows simultaneous estimation individual group-level parameters mutually-constraining fashion. shown improve parameter estimates relative methods (e.g., maximum likelihood estimation), resulting stable reliable estimates individual-level parameters informed group trends.[43]specific implementation hierarchical models follow detailed elsewhere.[44] high level, individual-participant parameters assumed drawn normally distributed group-level distributions. Bounded parameters, \\(\\gamma\\), estimated unconstrained space transformed ‘Matt Trick,’[42] inverse Probit transformation. optimize MCMC sampling.[44] formally,\\(- \\infty < \\mu_\\theta < + \\infty\\) \\(- \\infty < \\sigma_\\theta < + \\infty\\) group-level mean standard deviation, respectively; \\(\\theta^\\prime\\) unconstrained parameter gets transformed via inverse Probit transformation scaled upper bound, \\(U.B\\). example, \\(\\gamma\\), \\(U.B. = 1\\); \\(\\tau\\), \\(U.B. = 30\\). non-centered reparameterization results uniform prior individual participants’ parameters across full range.[44,45]chapter, hoped provide understanding computational modeling concepts used thesis. Specifically, :Provided overview sure bet gamble taskMathematically described can estimate parameters binary choice data using Bayes’ TheoremVisually depicted parameter estimation choice data using Bayes’ Theorem CPUT simulated choicesIntroduced Markov Chain Monte Carlo methods use thesis sample joint posterior distributionsWith foundation, ’s time revisit three computational modeling stages introduced beginning chapter.[36] Next, outline methods results simulating choice data according counterfactual predicted utility theory, estimating parameters observed data, comparing evidence three candidate models.","code":""},{"path":"computational-modeling-methods-and-results.html","id":"computational-modeling-methods-and-results","chapter":"8 Computational Modeling Methods and Results","heading":"8 Computational Modeling Methods and Results","text":"Using computational modeling techniques introduced previous chapter, examined ability counterfactual predicted utility theory explain human choice behavior sure bet gamble task[35]. chapter, present methods results concurrently following three stages adapted Wilson Collins discussed Section 7.[36] start simulating choice behavior generated counterfactual predicted utility theory confirm experimental design elicits behaviors assumed model. find estimate individual- group-level parameters three candidate models. Lastly, quantify model fit model comparison techniques.","code":""},{"path":"computational-modeling-methods-and-results.html","id":"simulating-choice-data","chapter":"8 Computational Modeling Methods and Results","heading":"8.1 Simulating Choice Data","text":"first step simulate choice data sure-bet gamble task, looked results Kahneman Tversky’s prospect theory[4] paper search information inform prior distribution. Although record subject’s response specific prospects, Kahneman Tversky report proportion people chose option. nine prospects follow form depicted Figures 6.1 6.2, used reported proportions simulate choice behavior one-hundred subjects.assumed \\(\\gamma\\) uniformly distributed zero one fixed softmax sensitivity parameter, \\(\\tau = 2.2\\) following conceptual visualizations Section 7.2 consistent literature.[39] ran ten-thousand iterations using Metropolis-Hastings algorithm described previous chapter. posterior distribution, depicted Figure 8.1, approximates \\(\\text{Beta}(1.1,1.1)\\) distribution. means , estimating \\(\\gamma\\) choice proportion data Kahneman Tversky, ’s plausible \\(\\gamma\\) value zero one, though little less likely towards tails.\nFigure 8.1: Posterior distribution \\(\\gamma\\) estimated ten-thousand iterations Metropolis-Hastings algorithm assuming uniform prior choice proportion data Kahneman Tversky’s prospect theory. posterior distribution (orange-red line) approximated \\(\\text{Beta}(1.1,1.1)\\) distribution (blue-gray), indicating slightly less plausibility \\(\\gamma\\) values near bounds zero--one interval relative central values.\nGiven sure bet gamble task design, participants saw random subset 252 prospects. posterior distribution \\(\\gamma\\) recovered Kahneman Tversky’s choice proportion data used generate \\(\\gamma\\) values fifty subjects. simulated choices 252 prospects, fixing softmax sensitivity parameter \\(\\tau = 2.2\\). five-thousand iterations Metropolis-Hastings algorithm, sampled posterior distribution simulated subject.10 simulated data, fit hierarchical Bayesian model Stan non-centered reparameterization described computational modeling concepts chapter. ran Hamiltonian Monte Carlo (Stan) sampler 5000 iterations across four parallel sampling chains total 20,000 samples posterior.11I chose estimate posterior distribution Metropolis-Hastings Hamiltonian Monte Carlo algorithms highlight similarity posterior parameter estimation techniques discussed Chapter 7. Figure 8.2 shows 95% highest density interval recovered sampler’s posterior distribution. subjects, simulated \\(\\gamma\\) values within highest-density interval. suggests sure-bet gamble task able elicit behaviors interest way measurable counterfactual predicted utility theory.confirmation able accurately recover simulated parameters sure-bet gamble task, move next stage computational modeling, parameter estimation. , use hierarchical Bayesian model Stan stable reliable estimates computational efficiency.\nFigure 8.2: 95 percent highest density interval posterior distribution \\(\\gamma\\) estimated five-thousand iterations Metropolis-Hastings algorithm five-thousand iterations across four parallel chains Hamiltonian Monte Carlo Sampler (estimated using Stan). simulated gamma values subject represented sky-blue dots fall within highest density interval red dots fall outside .\n","code":""},{"path":"computational-modeling-methods-and-results.html","id":"parameter-estimation","chapter":"8 Computational Modeling Methods and Results","heading":"8.2 Parameter Estimation","text":"assess counterfactual predicted utility theory’s validity theory decision-making risk, estimate parameters comparison expected utility theory. primarily two reasons:Counterfactual predicted utility theory suggests , \\(\\gamma = 0\\), counterfactual utility option equivalent expected value. expected value special case expected utility theory risk sensitivity parameter, \\(\\rho = 1\\).sure-bet gamble task include losses, prohibits comparing counterfactual predicted utility theory prospect theory.addition directly comparing CPUT EUT, wanted see different risk preferences might affect interact counterfactual information inform choice behavior. total, fit three models:CPUT + Softmax Sensitivity: model looks counterfactual information informs choice behavior. estimated parameters counterfactual weighting term, \\(\\gamma\\), sensitivity differences choice utilities, \\(\\tau\\).CPUT + Risk Sensitivity + Softmax Sensitivity: model looks differences risk sensitivity may interact counterfactual information inform choice behavior. estimated parameters counterfactual weighting term, \\(\\gamma\\), risk sensitivity term, \\(\\rho\\), sensitivity differences choice utilities, \\(\\tau\\).EUT + Softmax Sensitivity: model looks differences risk sensitivity informs choice behavior. estimated parameters risk sensitivity term, \\(\\rho\\), sensitivity differences choice utilities, \\(\\tau\\).models sampled 5000 iterations across four parallel chains hierarchical Bayesian model formulation described Section 7.3.[44] model, chain convergence group-level transformed individual-level parameters checked Gelman-Rubin statistics, \\(\\hat{R} \\leq 1.1\\), suggesting -chain variance lower within chain variance.[46] group-level posterior distributions parameters fit model shown Figure 8.3.\nFigure 8.3: Posterior distribution group-level parameter estimates model. Relative distributions \\(\\gamma\\) (left), \\(\\rho\\) (middle), \\(\\tau\\) (right) underlined 95 percent highest density intervals model median indicated. ‘CPUT + Softmax Sensitivity’ model shown blue estimated parameters \\(\\gamma, \\tau\\); ‘EUT + Softmax Sensitivity’ shown red estimated parameters \\(\\rho, \\tau\\); ‘CPUT + Risk Sensitivity + Softmax Sensitivity’ shown yellow estimated parameters \\(\\gamma, \\rho, \\tau\\).\n","code":""},{"path":"computational-modeling-methods-and-results.html","id":"model-comparison","chapter":"8 Computational Modeling Methods and Results","heading":"8.3 Model Comparison","text":"estimated posterior distributions model type, sought determine model best explains choice behavior. , used three different methods compare models, results summarized Table 8.4:Posterior predictive checks , model, simulated choices given (joint) posterior distribution participants’ estimated model parameter(s). included Stan’s generated quantities block, executed posterior sample generated.[42] compared percentage predicted choices matches observed data summarized mean standard deviation model.Posterior predictive checks , model, simulated choices given (joint) posterior distribution participants’ estimated model parameter(s). included Stan’s generated quantities block, executed posterior sample generated.[42] compared percentage predicted choices matches observed data summarized mean standard deviation model.Comparing marginal likelihoods model. probability observing choice behavior given model, \\(M\\), \\(P(\\text{Choices}|M)\\). marginal likelihood model estimated using bridge sampling.[47] Marginal likelihoods often included calculations Bayes factors, describes relative evidence favor one model another quantifying ratio probability observing data given two models. marginal likelihoods computed log-scaled computational efficiency, means positive, less negative, marginal likelihood indicates better fit.Comparing marginal likelihoods model. probability observing choice behavior given model, \\(M\\), \\(P(\\text{Choices}|M)\\). marginal likelihood model estimated using bridge sampling.[47] Marginal likelihoods often included calculations Bayes factors, describes relative evidence favor one model another quantifying ratio probability observing data given two models. marginal likelihoods computed log-scaled computational efficiency, means positive, less negative, marginal likelihood indicates better fit.Assessing penalized model fit model’s leave-one-cross validation predictive accuracy.[48] approximated importance sampling posterior distribution calculate expected log pointwise predictive density (ELPD), logged sum pointwise posterior predictive distribution held data. multiplying ELPD negative two, get leave-one-information criterion, LOOIC. transformation makes easier compare information criterion (e.g., AIC, DIC), highlighting penalization model complexity.[49] include ELPD LOOIC easy comparison. Note less negative ELPD smaller (closer zero) LOOIC indicative better model fits.Assessing penalized model fit model’s leave-one-cross validation predictive accuracy.[48] approximated importance sampling posterior distribution calculate expected log pointwise predictive density (ELPD), logged sum pointwise posterior predictive distribution held data. multiplying ELPD negative two, get leave-one-information criterion, LOOIC. transformation makes easier compare information criterion (e.g., AIC, DIC), highlighting penalization model complexity.[49] include ELPD LOOIC easy comparison. Note less negative ELPD smaller (closer zero) LOOIC indicative better model fits.\nFigure 8.4: Parameters , description , different models fit human choice data sure-bet gamble task along model comparison metrics. Posterior predictive choice accuracy represents mean standard deviation correctly predicted choices individual participants given simulations (joint) posterior distribution. ELPD Predictive Density LOOIC details well models perform unobserved data (leave-one-cross validation). Parantheses ELPD LOOIC indicate Monte Carlo sampling error. Marginal likelihood model evidence indicates plausibility data given model parantheses representing interquartile range likeihood estimations. general, better models smaller LOOIC higher posterior predictive choice accuracy, ELPD predictive accuracy (less negative), marginal likelihood model evidence (less negative). CPUT + Softmax Sensitivity EUT + Softmax Sensitivity highlighted easy reference discussed.\n","code":""},{"path":"computational-modeling-methods-and-results.html","id":"eut-versus-cput","chapter":"8 Computational Modeling Methods and Results","heading":"8.3.1 EUT versus CPUT","text":"EUT provides better explanation observed data sure bet gamble task (\\(BF_{\\frac{\\rho, \\tau}{\\gamma, \\tau}}\\) = 48.07) generalizes better CPUT (\\(\\text{LOOIC}_{\\rho, \\tau} - \\text{LOOIC}_{\\gamma, \\tau}\\) = -381.34). posterior predictive choice accuracy – percentage choices simulated posterior estimate subject’s parameters – similar, though better EUT (83.8%) compared CPUT (82.3%)., group-level posterior parameter distribution \\(\\tau\\), common variable two models, higher EUT CPUT (95% HDI EUT [1.51, 2.62] median 2.05; CPUT = [0.97, 1.31] median 1.13). suggests utility maximizing decisions EUT relative random choice behavior CPUT.","code":""},{"path":"computational-modeling-methods-and-results.html","id":"cput-risk-sensitivity-versus-eut","chapter":"8 Computational Modeling Methods and Results","heading":"8.3.2 CPUT + Risk Sensitivity versus EUT","text":"Adding risk sensitivity term, \\(\\rho\\), EUT CPUT offers best explanation observed human choice data (\\(BF_{\\frac{\\rho, \\tau, \\gamma}{\\rho, \\tau}}\\) = 109.89). come cost decreased generalizability (\\(\\text{LOOIC}_{\\rho, \\tau} - \\text{LOOIC}_{\\rho,\\tau,\\gamma}\\) = -158.18) increased posterior predictive choice accuracy (83.9% relative EUT’s 83.8%)., group-level posterior parameter distribution \\(\\tau\\) depict similar sensitivities utility differences (95% HDI ‘CPUT + Softmax + Risk Sensitivity’ = [1.45, 2.57] median 1.98; ‘EUT + Softmax = [1.51, 2.62] median 2.05) risk sensitivity (95% HDI ’CPUT + Softmax + Risk Sensitivity’ = [0.68, 0.94] median 0.8; ‘EUT + Softmax’ = [0.66, 0.93] median 0.79).","code":""},{"path":"computational-modeling-methods-and-results.html","id":"cput-risk-sensitivity-versus-cput","chapter":"8 Computational Modeling Methods and Results","heading":"8.3.3 CPUT + Risk Sensitivity versus CPUT","text":"Incorporating risk sensitivity CPUT results better explanation observed data (\\(BF_{\\frac{\\rho, \\gamma, \\tau}{\\gamma, \\tau}}\\) = 157.95), generalizable, (\\(\\text{LOOIC}_{\\rho, \\gamma, \\tau} - \\text{LOOIC}_{\\gamma, \\tau}\\) = -223.16), higher posterior predictive choice accuracy (83.9%) relative CPUT’s (82.3%).Interestingly, group-level posterior parameter distribution \\(\\tau\\) CPUT + Risk Sensitivity closely reflects EUT. time, group-level posterior parameter distribution \\(\\gamma\\) much tightly concentrated towards zero CPUT (95% HDI CPUT + Risk Sensitivity [<0.001, 0.006] median 0.002; CPUT = [<0.001, 0.015] median 0.006). suggests lower weighting counterfactual information accounting risk preferences.measures, seems Expected Utility Theory provides generalizable explanation human choice data sure bet gamble task. next chapter, discuss results outline next steps contribute towards better understanding neurobiological basis decision-making risk.","code":""},{"path":"discussion-next-steps.html","id":"discussion-next-steps","chapter":"9 Discussion & Next Steps","heading":"9 Discussion & Next Steps","text":"","code":""},{"path":"references.html","id":"references","chapter":"10 References","heading":"10 References","text":"","code":""}]
