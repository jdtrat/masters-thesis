[{"path":"index.html","id":"hello-world","chapter":"Hello, World","heading":"Hello, World","text":"name Jonathan Trattner. May 2022, graduate Master’s Science Degree Neuroscience Wake Forest School Medicine. website embodiment master’s thesis.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"make choices every day. eat, whether take one route work, go sleep, just examples. Every decision associated consequences. Consequences inherently rewarding (appetitive), punishing (aversive), . understand processes involved human decision-making, use quantitative frameworks study choice behavior. analytic approaches primarily formalized three disciplines: economics, psychology, neuroscience.experimental literature, two types decision contexts described. “decisions risk,” decision-maker knows precision probability distribution possible outcomes. “decisions uncertainty,” decision-maker must infer probabilities potential outcomes. thesis, combine insights economics, psychology, neuroscience propose neurobiologically-plausible theory decision-making risk.first chapter, introduce notation used throughout thesis. outline evolution decision-theory classical economic models behavioral economic ones. second chapter, describe influences behavioral economic theories neuroscience research. cover relation (neuro)biology behavior. third chapter, propose new theory decision-making risk called ‘Counterfactual Predicted Utility Theory’ builds upon foundational work chapters one two. fourth chapter, assess predictive accuracy Counterfactual Predicted Utility Theory human choice data sure-bet gamble task. chapter five, conclude thesis discussions next steps.","code":""},{"path":"evolution-of-decision-theory.html","id":"evolution-of-decision-theory","chapter":"2 Evolution of Decision Theory","heading":"2 Evolution of Decision Theory","text":"Imagine casino. asked play new type roulette. time , cost participating. rules simple: pick red option black option. choose red option, dealer give three-thousand dollars. pick black option, dealer spin wheel release ball. wheel weighted 80% chance getting four-thousand dollars 20% chance getting zero dollars. option choose? ?economic theorist, bet choose black option higher expected value. Expected values, \\(EV\\), calculated multiplying magnitude, \\(x\\), outcome probability, \\(p\\), occur. example, red option leads three-thousand dollars certainty. black option leads four-thousand dollars 80% chance (probability 0.8).Looking expected values option calculated (2.1), see \\(\\text{EV}(\\text{Red}) > \\text{EV(Black)}\\). Therefore, rational choice according classical economist black option.new type roulette presented prototypical example prospect – choice two options explicit probabilities outcomes – used investigate decision-making risk. normative measure monetary reinforcements allows decision-researchers probe mechanisms underlying choice behavior. participants similar reference point, choosing option higher expected monetary payout straightforward (least mathematically speaking). However, decision accept risky gamble like may change ask someone annual income one-million dollars compared someone income fifty-thousand dollars.introduces idea diminishing marginal returns. value millionaire places certain three-thousand dollars (option 1 ) may enough dissuade probable four-thousand dollars. person, assured three-thousand dollars, though, much valuable gamble. idea formalized term ‘utility,’ coined Swiss mathematician Daniel Bernoulli. Utiity refers subjective “moral value” decision’s outcome. Bernoulli wrote: (Daniel Bernoulli 1954)price item dependent thing equal everyone; utility, however, dependent particular circumstances person making estimate.Bernoulli’s concept formed basis von Neumman Morgenstern’s Expected Utility Theory (EUT). (Neumann Morgenstern, O. 1947) EUT suggest people – – choose manner maximizes expected utility. EUT axiomatized, validity called question. Notably, Allais paradox suggests rationality defined maximizing expected utility neglects specific element psychology risk: variance individuals’ psychological values.(Allais 1953)1979, Daniel Kahneman Amos Tversky published Prospect Theory: Analysis Decision Risk.(Kahneman Tversky 1979) Prospect theory critiqued descriptive validity EUT. Kahneman Tversky highlighted systematic ways people violated EUT. , instantiated field behavioral economics – wedding insights psychology quantitative models economics – better understand human choice behavior.Kahneman Tversky describe multiple deviations EUT. Notably, discuss certainty reflection effects. certainty effect describes people overweight outcomes considered certain relative probable ones. reflection effect – commonly known ‘loss aversion’ – accounts peoples tendency risk averse positive prospects risk seeking negative ones. addition effects, one key takeaway prospect theory value function corresponds changes wealth welfare, rather final states. value function, concave gains convex losses, losses steeper gains (goes hand--hand reflection effect).application behavioral insights theories human decision-making necessitate emotional component. discussed Graham Loomes Robert Sugden 1982 paper, Regret Theory: Alternative Rational Choice Uncertainty, anticipatory feelings regret used inform decisions. (Loomes Sugden 1982)1 Loomes Sugden’s describe idea choosing one option preference cost forgoing opportunities.2 theory introduces concept counterfactual thinking, explicit comparison present state world alternative states.(Neal J. Roese 1997; Liu et al. 2016)revisit casino example, feel chose black option (gambling four-thousand dollars) lost? chosen red option three-thousand dollars certain, forewent opportunity chance something . comparison “” vs. “might ” captures idea counterfactual information.chapter, recounted high-level overview choice theory. example prospect, described expected values calculated importance subjective measures (utility) studying choice behavior. introduced EUT classical economist’s theory decision-making risk. Next, covered origin behavioral economics Kahneman Tversky’s prospect theory improve descriptive models choice behavior. concluded chapter covering regret theory necessity accounting subjective emotions choice models. next chapter, outline recent work looking neurobiological basis decision-making show evidence specific neural systems track counterfactual signals.","code":""},{"path":"neurobiology-of-decision-making.html","id":"neurobiology-of-decision-making","chapter":"3 Neurobiology of Decision-Making","heading":"3 Neurobiology of Decision-Making","text":"last chapter, used term prospect describe problem two options stated probabilities outcomes. experimental literature, prospects ‘description-based.’ Formally, researchers use description-based prospects experiments ask participants select one available options presented along complete description non-trivial problem.(Barron Erev 2003)looking towards neuroscientific literature decision-making, different type experimental paradigm perhaps common: ‘experiential’ ‘feedback-based’ decisions.(Barron Erev 2003). interacting environment, humans (animals) associate consequences different actions adapt behavior accordingly. words, learn. learn time want eat sushi dinner, ’s faster take highway work, ’re better go sleep midnight.3Looking towards animal learning field, see many accounts experiential learning. list :Thorndike’s Law Effect states animal’s behavior can modified consequences action.(Thorndike 1911)Thorndike’s Law Effect states animal’s behavior can modified consequences action.(Thorndike 1911)Classical (Pavlovian) conditioning details learning predict rewards punishments stimuli independent action-taken.(Pavlov 2010)Classical (Pavlovian) conditioning details learning predict rewards punishments stimuli independent action-taken.(Pavlov 2010)Operant (instrumental) conditioning involves learning rewards punishments contingent upon one’s actions.(B. F. Skinner 1938)Operant (instrumental) conditioning involves learning rewards punishments contingent upon one’s actions.(B. F. Skinner 1938)behavior (action decision) predicated upon prior experiences allows us formalize relationship states. , use state reference representation stimuli. example, state \\(s \\S\\) time \\(t\\) (\\(s_t\\)) may comprised internal states (hunger, thirst, fatigue) external ones (light, music, temperature).Consider Pavlov’s experiment showed repeatedly giving dog food ringing bell condition dog salivate bell rung.(Pavlov 2010) means , time, behavior elicited stimulus (food) can evoked – previously – neutral stimulus (bell). one first attempts empirically describe process, Bush Mosteller suggest probability Pavlov’s dog salivating, \\(P(\\text{sal})\\), next presentation food bell (next trial, \\(tr+1\\)) function happened last presentation (last trial, \\(tr-1\\)) discounted experienced presentation (food reward trial, \\(R_{tr}\\).(Bush Mosteller 1951a, 1951b)Equation (3.1) computes average previously experienced rewards. \\(0 \\leq \\alpha \\leq 1\\) learning rate, modulates influence recent rewards. Bush Mosteller’s work forms basis modern approaches problem reinforcement learning.(Glimcher 2011)4 discretizing learning trials logical first step modeling behavior experimental settings, ’s easily applied biological systems continuously interact environments.1988 paper, Learning Predict Methods Temporal Differences, Richard Sutton introduces antecedent temporal-difference reinforcement learning (TDRL) algorithms.(Sutton 1988) TDRL algorithm provides computational framework optimally learning experience actions associated stimuli lead rewards. (Richard S. Sutton; Andrew G. Barto 2018)‘goal’ TDRL algorithms estimate value state use information maximize rewards. achieved ‘teaching signal,’ called temporal-difference reward prediction error (TD-RPE), relates value state time \\(t\\) expected previously.current value state sum outcome experienced time \\(t\\) plus expectation future outcomes said state. expectation future values, \\(V(S_{t+1})\\) modulated temporal-discounting parameter \\(0 \\leq \\gamma \\leq 1\\) can preferentially weight immediate outcomes relative future ones.total, Equation (3.2) shows TD-RPE, \\(\\delta_t\\), difference current value state recent expectation state’s value, \\(V(S_t)\\). time step, \\(\\delta_t\\) used update estimated value current state formulated (3.3). , \\(0 \\leq \\alpha \\leq 1\\) learning rate controls much weight individual places estimated value current state light TD-RPE.1990s, Read Montague, Peter Dayan, colleagues show evidence suggesting TD-RPEs reflected fluctuations activity mesencephalic dopaminergic neurons.(P. Montague, Dayan, Sejnowski 1996; W. Schultz, Dayan, Montague 1997a) TD-RPE hypothesis dopamine neurons consistent behavioral neural results rodents, (Hart et al. 2014) non-human primates, (Tomas Ljunberg, Paul Apicella, Wolfram Schultz 1992; W. Schultz, Apicella, Ljungberg 1993; W. Schultz, Tremblay, Hollerman 1998; Bayer Glimcher 2005a) humans.(Zaghloul et al. 2009; Kishida et al. 2011; Moran et al. 2018; Bang et al. 2020) biologically conserved mechanism experiential learning, can investigate neural basis choice behavior empirically TDRL algorithms. 2011, experiments saw exciting development Ken Kishida colleagues used fast-scan cyclic voltammetry measure dopamine fluctuations human striatum sub-second temporal resolution. (Kishida et al. 2011)combination 2016 paper, Kishida colleagues studied dopamine levels humans undergoing elective surgery part deep-brain stimulation treatment.(Kishida et al. 2011, 2016) Participants viewed graphical depiction (fictitous) stock market’s price history (Figure 3.1; B) asked choose much portfolio (initially valued $100) invest. six ‘markets,’ twenty-decisions, participants used handheld button boxes (Figure 3.1; ) increase decrease investment ten-percent increments. Decision made dopamine recorded striatum light three pieces information:history market price (Figure 3.1; red-trace panel B)current portfolio value (Figure 3.1; bottom left box, 126, panel B)recent fractional change portfolio value (Figure 3.1; bottom right box, 15.2%, panel B).\nFigure 3.1: Participants played sequential-choice game surgery using button boxes (; Left) visual display (; Right). patient, bet size adjustments (e.g., increase bet decrease bet) decision submit one’s answer performed button boxes. (B) Graphical depiction market price history (red trace), current portfolio value (bottom left box), recent outcome (bottom right box) sequential investment task (C) Timeline events single round investment game. Reprinted permission Kishida et al., 2016.\n2011 paper, asked one person, MH, complete sequential investment task. line prior work relating dopamine unexpected financial outcomes (Zaghloul et al. 2009), Kishida colleagues observed strong correlation MH’s dopamine levels market value investment task.(Kishida et al. 2011) 2016, Kishida colleagues published results seventeen humans. , explicitly tested hypothesis fluctuations dopamine released human striatum encode TD-RPEs.(Kishida et al. 2016) sequential investment task, RPEs calculated difference investment’s return given trial relative expectation defined average return preceding trials.Contrary hypothesis dopamine fluctuations striatum track TD-RPEs,(P. Read Montague, Hyman, Cohen 2004; P. Montague, Dayan, Sejnowski 1996; W. Schultz, Dayan, Montague 1997b; Bayer Glimcher 2005b; Hart et al. 2014; Roesch, Calu, Schoenbaum 2007) authors found dopamine fluctuations encode integration RPEs counterfactual prediction errors (CPEs). discussed last chapter, counterfactual signals explicit comparison present state alternative ones.(Neal J. Roese 1997; Liu et al. 2016) sequential investment task, CPEs defined difference participant’s actual return trial invested less. means dopamine release result integration RPEs CPEs given trial. Formally:\\(b_{tr}\\) individual’s factional investment trial \\(tr\\) \\(r_{tr}\\) relative change market price. Kishida colleagues note, intuition Equation (3.4) better--expected outcomes (positive RPEs, increased dopamine release), even better (positive CPEs) reduced value. Similarly, worse--expected outcomes (negative RPEs, decreased dopamine release), even worse (negative CPEs) increased value. Importantly, empirical terms consistent subjective feelings (e.g., regret relief), one experiences light given outcome.Figure 3.2 depicts changes dopamine levels function bet size. Consider ‘higher bets’ panel (left) individuals bet close maximum amount possible. rewarded positive change portfolio value, dopamine concentrations increased (green; positive RPEs). Similarly, portfolio value decreased, dopamine levels dipped (red; negative RPEs). high bets (left panel, bets \\(90\\%-100\\%\\) portfolio value), difference earned earned bet minimal, CPE. medium bets (middle panel, \\(60\\%-80\\%\\)), however, difference individuals experienced experienced bet increases. means absolute magnitude CPE goes subtracts dopamine release predicted positive negative RPEs. CPEs maximal (small bets, \\(10\\% - 50\\%\\); right panel), observe inversion dopamine release response positive negative RPEs.\nFigure 3.2: RPE encoding dopamine transients invert function bet size. Dopamine responses equal absolute magnitude positive negative RPEs bets high (Left), medium (Center), low (Right). three plots, mean normalized dopamine responses standard errors shown positive RPEs (green traces) negative RPEs (red traces). Reprinted permission Kishida et al., 2016.\n‘superposed error signals actual counterfactual reward’ described Kishida colleagues’ paper(Kishida et al. 2016) directly inspired thesis work. provide empirical, neurobiologically plausible framework investigating decision-making risk. theoretical quantitative underpinnings classical behavioral economic theories decision-making align well computational reinforcement learning literature described chapter. explicit probability outcome structure risky prospects afford opportunity internalize future states (potentially) incorporate anticipated counterfactual events decision-making process. next chapter, derive ‘Counterfactual Predicted Utility Theory’ new theory decision-making risk.","code":""},{"path":"counterfactual-predicted-utility-theory.html","id":"counterfactual-predicted-utility-theory","chapter":"4 Counterfactual Predicted Utility Theory","heading":"4 Counterfactual Predicted Utility Theory","text":"discussed last chapter, neurotransmitter dopamine seemingly encodes information actual counterfactual rewards,(Kishida et al. 2016) integration may play guiding role decision-making. neural evidence, combined behavioral economic theories offering descriptive models people making risky decisions,(Kahneman Tversky 1979; Loomes Sugden 1982) propose ‘Counterfactual Predicted Utility Theory’ (CPUT) neurobiologically-plausible theory decision-making risk.intuition behind CPUT idea people account counterfactual outcomes faced prospect integration factual counterfactual signals brain may discount invert preference choosing one option another. hypothesize preference-reversal modulated counterfactual weighting term, \\(\\gamma\\), may vary across people.formally derive CPUT, can revisit prospect introduced first chapter hypothetical casino game. two options: choosing one certainly three-thousand dollars; choosing another give 80% chance four-thousand dollars nothing. prospect commonly denoted follows first option leads outcome \\(x_1\\) probability \\(p_1\\) second option leads outcomes \\(x_2\\) probability \\(p_2\\).Unless otherwise stated, alternative outcomes option assumed zero. , choosing Option 1 choice receiving \\(x_1\\) probability \\(p_1\\) nothing probability \\((1 - p_1)\\). explicit, generalizable, representation prospect can seen Figure 4.1. , Option 1 choice receiving \\(x_{1a}\\) probability \\(p_1\\) \\(x_{1b}\\) probability \\((1 - p_1)\\). Similarly, Option 2 choice receiving \\(x_{2a}\\) probability \\(p_2\\) \\(x_{2b}\\) probability \\((1 - p_2)\\).\nFigure 4.1: Explicit representation prospect two options. Choosing option 1 may lead outcome \\(x_{1a}\\) probability \\(p_1\\) outcome \\(x_{1b}\\) probability \\((1 - p_1)\\). Choosing option 2 may lead outcome \\(x_{2a}\\) probability \\(p_2\\) outcome \\(x_{2b}\\) probability \\((1 - p_2)\\).\nrepresentation, can begin formally define option’s counterfactual utility, \\(U_C\\), follows:contrast, Expected Utility Theory, option’s expected value exponentiated risk-aversion parameter, \\(\\rho\\). expected utility definition Equation (4.3) represents weighting probabilities outcomes Equation (4.2).represent equations similarly, define \\(V_E\\) estimated expected utility value (really just stated outcome). CPUT, however, formally define transformation stated outcome face value minus weighted sum option’s alternative outcome option’s expected value. notation expressed Equation (4.4), shows prospect form depicted Figure 4.1 represented.Unlike estimated expected utility value, \\(V_E\\), estimated counterfactual utility value, \\(V_C\\) one--one mapping stated outcomes. provide better intuition within- -option dependency, helpful consider concrete example. adapting Figure 4.1 include values casino example initially described, can better see possible outcome may integrate evaluating given prospect.\nFigure 4.2: Example prospect diagram visualize counterfactual integration. Choosing option 1 may lead outcome \\(\\$3000\\) probability \\(1.0\\) outcome \\(\\$0\\) probability \\((1 - 1.0)\\). Choosing option 2 may lead outcome \\(\\$4000\\) probability \\(0.8\\) outcome \\(\\$0\\) probability \\((1 - 0.8)\\). Estimating counterfactual utility value possible outcomes dependent one-another.\nillustrate CPUT walking-Figure 4.2, let’s assume counterfactual-weighting term \\(\\gamma = 0.1\\). means stated outcomes transformed given available counterfactual information potential outcome follows:values combined Equation (4.2), see \\(U_C(\\text{Option 2}) > U_C(\\text{Option 1})\\):maximize utility, choose Option 2 progress diagram first node right-hand side. , forwent opportunity Option 1. chose differently, reached node left, expected value $3000, didn’t. current position, 80% chance find red node, $4000. proverbial coin-flip goes , however, find cyan node nothing show . walking-example, hoped convey possible outcomes relate one-another factual counterfactual information may integrated inform one’s decision.Importantly, equations suggest \\(\\gamma = 0\\), one places weight counterfactual events, counterfactual utility equivalent expected value. words, \\(\\gamma = 0\\), \\(U_C(\\text{Option 1}) = EV(\\text{Option 1})\\) \\(U_C(\\text{Option 2}) = EV(\\text{Option 2})\\). people don’t place weight counterfactual information, might expect choice behavior consistent maximizing expected value (, better compare theories decision-making, maximizing expected utility). provide evidence support CPUT generative theory decision-making, test hypothesis \\(\\gamma > 0\\) means people consider counterfactual outcomes faced risky prospect. , use choice data ‘Sure Bet Gamble’ task.","code":""},{"path":"computational-modeling-concepts.html","id":"computational-modeling-concepts","chapter":"5 Computational Modeling Concepts","heading":"5 Computational Modeling Concepts","text":"last chapter, addressed first thesis aim developing counterfactual predicted utility theory (CPUT) alternative expected utility theory explain decision-making risk. showed information potential outcome (terminal node Figure 4.1) integrates counterfactual weighting parameter, \\(\\gamma\\), adjust utility one option another. walked-example calculation assuming \\(\\gamma = 0.1\\) (diagrammed Figure 4.1). chapter, begin address second thesis aim assessing predictive accuracy CPUT using human choice data ‘Sure Bet Gamble’ task.(B. Liebenow et al. 2021)attempt robustly, transparently, fit CPUT behavioral data, follow general guidelines presented Robert Wilson Anne Collins’s paper Ten simple rules computational modeling behavioral data.(Wilson Collins 2019)high level, state computational modeling allows us make better sense behavioral data mathematical models may provide insight mechanisms underlying behavior. Although exact form models differ, basic steps assess model’s descriptive predictive efficacy similar.first two steps Wilson Collins discuss designing experiment developing model. thesis, fit CPUT, formulated last chapter, data collected ongoing study Brittany Liebenow colleagues(B. Liebenow et al. 2021) forty-five healthy adults (ages 18-65) recruited complete sure-bet gamble task (Figure 5.1).\nFigure 5.1: Schematic trial Sure Bet Gamble task subjective rating prompt. prospecti s presented random duration based Poisson distribution \\((\\lambda = 6\\text{s})\\). Assuming timely response, choice screen shown two seconds followed outcome screen one second. Trials separated fixation cross whose inter-trial interval random duration Poisson distribution \\(\\lambda = 3\\text{s}\\).\nthirty minutes, participants indicated preference sure bet (values $1-$6 $1 increments) fifty-fifty gamble two non-identical values ($0 - $6 $1 increments). lateral presentation sure bet gambles randomized, prospect presented random duration based Poisson distribution \\((\\lambda = 6\\text{s})\\). participant answered within alloted time, choice displayed two seconds shown outcome one second. answer time, shown late screen one second. Rounds separated fixation cross whose inter-trial interval Poisson distribution \\((\\lambda = 6\\text{s}\\), zeros removed\\()\\). -third rounds choices made, respondents asked “feel last outcome?” adjusted slider ranging ‘bad’ ‘good.’ Participants paid $20 per hour told receive winnings randomly selected round bonus compensation.Using data task, can group remaining computational modeling steps three stages:(Wilson Collins 2019)Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Parameter Estimation: Find set parameters best account experimental data given candidate model.Parameter Estimation: Find set parameters best account experimental data given candidate model.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.detailing methods results stage analysis, important understand mathematics behind model-fitting. general case, estimating model’s parameters decision-making task, want know parameter(s) best explain observed choices. tasks two outcomes, can represented binary choice vector choice option indicated 1 chosen 0 .Consider prospect depicted Figure 5.1. Given stated outcomes probabilities, can calculate counterfactual utilities option \\(\\gamma\\) value according Equations (4.2) (4.4). \\(0 \\leq \\gamma \\leq 0.5\\), can see utilities sure bet option ($3) gamble (50% chance $2 $5) Figure 5.2). , might assume people place low weight counterfactual information often choose gamble. point (\\(\\gamma \\approx 0.16\\)), individual equally likely choose either option. people place weight counterfactual information, likely choose sure bet prospect.\nFigure 5.2: Counterfactual utilities sample prospect sure bet gamble task simulated \\(0 \\leq \\gamma \\leq 0.5\\). Blue line represents counterfactual utility choosing ‘Sure Bet’ receiving three dollars; red line represents counterfactual utility choosing ‘Gamble’ 50 percent chance receiving two dollars five dollars. ‘indifference’ point choosing one option occurs \\(\\gamma \\approx 0.16\\).\nAlthough can determine utility option, peoples’ choice behavior fit model. means need determine likely parameter value give us observed data. help answer question, looked towards Bayesian statistics, offers way incorporate prior information parameters statistical model observed data define posterior probability distribution representing plausible parameter values.5The first step performing Bayesian inference construct prior probability model parameters interest. end fitting multiple models (e.g., perform model comparison), outline procedure general case using \\(\\theta\\) represent given model’s parameters. prior probability model, \\(\\pi(\\theta)\\) contains available information parameter’s distribution observing data. information come , example, previous experiments. information available, might assume uniform prior distribution, assigns equal probability values within defined range.next step Bayesian inference involves calculating likelihood observing data given set parameters, \\(\\theta\\). analysis, focused likelihood individual chose Option 1 (sure bet), represent follows:translate binary choice behavior likelihood, need way relating option’s utilities probability. can done softmax choice rule, logistic transformation difference utilities option:(P. Sokol-Hessner et al. 2009)\\(U_1, U_2\\) utilities (according proposed model CPUT EUT), \\(\\tau > 0\\) sensitivity parameter relates sensitive one’s choice difference utilities. complement Figure 5.2, can see probability choosing sure bet changes \\(\\gamma\\) (subsequently utility Option 1) increases:\nFigure 5.3: Probability choosing Option 1 (‘Sure Bet’) calculated logistic transformation difference utilities counterfactual utilities option shown Figure 5.2 across \\(0 \\leq \\gamma \\leq 0.5\\). \\(\\tau\\) increases, individuals likely maximize utility. Note ‘indifference’ point choosing one option occurs \\(\\gamma \\approx 0.16\\), regardless \\(\\tau\\).\nthird step Bayesian inference generate posterior distribution, \\(Pr(\\theta|\\text{Choices})\\), represents range likely range parameter values given observed choices. terms analysis, posterior distribution defined follows:probability \\(\\theta\\) value given observed choice data, posterior distribution \\(Pr(\\theta|\\text{Choices})\\), proportional to6 likelihood observing data given parameter value, \\(L(\\text{Chose Option 1}|\\theta)\\), times prior plausibility parameter value, \\(\\pi(\\theta)\\).estimate posterior distribution, used two ‘Markov Chain Monte Carlo’ methods. first attempt, manually implemented Metropolis-Hastings algorithm.(Haines 2018; Dogucu 2022) high level, Metropolis-Hastings algorithm involves following steps:iteration \\(n \\1:N\\) following:Propose value, \\(\\theta_n^*\\) near current estimate \\(\\theta_n\\), propose value \\(\\theta^*\\)Calculate acceptance probability proposal \\(\\theta_n^*\\) defined ratio posterior distribution evaluated \\(\\theta_n^*\\) \\(\\theta_n\\)Draw random number zero one. less equal acceptance probability, set \\(\\theta_{n+1} = \\theta_n^*\\), otherwise \\(\\theta_{n+1} = \\theta_n\\).validated implementation comparing posterior distributions computed hierarchical Bayesian approach. Hierarchical Bayesian Analysis implemented probabilistic programming language, Stan, implements efficient variant Markov Chain Monte Carlo called Hamiltonian Monte Carlo sampler.(Stan Development Team 2022) Hierarchical Bayesian Analysis allows simultaneous estimation individual group-level parameters mutually-constraining fashion. shown improve parameter estimates relative methods (e.g., maximum likelihood estimation), resulting stable reliable estimates individual-level parameters informed group trends.(Ahn et al. 2011)specific implementation hierarchical models follow detailed elsewhere.(Ahn, Haines, Zhang 2017) high level, individual-participant parameters assumed drawn normally distributed group-level distributions. Bounded parameters, \\(\\gamma\\), estimated unconstrained space transformed ‘Matt Trick,’(Stan Development Team 2022) inverse Probit transformation. optimize MCMC sampling.(Ahn, Haines, Zhang 2017) formally,\\(- \\infty < \\mu_\\theta < + \\infty\\) \\(- \\infty < \\sigma_\\theta < + \\infty\\) group-level mean standard deviation, respectively; \\(\\theta^\\prime\\) unconstrained parameter gets transformed via inverse Probit transformation scaled upper bound, \\(U.B\\). example, \\(\\gamma\\), \\(U.B. = 1\\); \\(\\tau\\), \\(U.B. = 30\\). non-centered reparameterization results uniform prior individual participants’ parameters across full range.(Ahn et al. 2014; Ahn, Haines, Zhang 2017)better grasp concepts employed thesis, ’s time revisit three stages computational modeling introduced chapter introduction. (Wilson Collins 2019) next chapter, outline methods results simulating choice data according counterfactual predicted utility theory, estimating parameters observed data, comparing evidence seven candidate models.","code":""},{"path":"modeling-methods-and-results.html","id":"modeling-methods-and-results","chapter":"6 Modeling Methods and Results","heading":"6 Modeling Methods and Results","text":"Using computational modeling techniques introduced last chapter, examined ability counterfactual predicted utility theory explain human choice behavior sure bet gamble task(B. Liebenow et al. 2021). chapter, describe implemented three stages outlined last chapter.(Wilson Collins 2019) first step: simulating choice behavior generated counterfactual predicted utility theory confirm experimental design elicits behaviors assumed model.","code":""},{"path":"modeling-methods-and-results.html","id":"simulating-choice-data","chapter":"6 Modeling Methods and Results","heading":"6.1 Simulating Choice Data","text":"first step simulate choice data sure-bet gamble task, looked results Kahneman Tversky’s prospect theory(Kahneman Tversky 1979) paper search information inform prior distribution. Although record subject’s response specific prospects, Kahneman Tversky report proportion people chose option. nine prospects follow form depicted Figures 4.1 4.2, used reported proportions simulate choice behavior one-hundred subjects.assumed \\(\\gamma\\) uniformly distributed zero one fixed softmax sensitivity parameter, \\(\\tau = 1\\). ran ten-thousand iterations using Metropolis-Hastings algorithm described previous chapter. posterior distribution, depicted Figure 6.1, approximates \\(\\text{Beta}(1.1,1.1)\\) distribution. means , estimating \\(\\gamma\\) choice proportion data Kahneman Tversky, ’s plausible \\(\\gamma\\) value zero one, though little less likely towards tails.\nFigure 6.1: Posterior distribution \\(\\gamma\\) estimated ten-thousand iterations Metropolis-Hastings algorithm assuming uniform prior choice proportion data Kahneman Tversyk’s prospect theory(Kahneman Tversky 1979). posterior distribution (orange-red line) approximated \\(\\text{Beta}(1.1,1.1)\\) distribution (blue-gray), indicating slightly less plausibility \\(\\gamma\\) values near bounds zero--one interval relative central values.\nGiven task design, participants saw random subset 252 prospects. posterior distribution \\(\\gamma\\) recovered Kahneman Tversky’s choice proportion data used generate \\(\\gamma\\) values fifty subjects. simulated choices 252 prospects, fixing softmax sensitivity parameter \\(\\tau = 1\\). five-thousand iterations Metropolis-Hastings algorithm, sampled posterior distribution simulated subject.7 simulated choice data, also fit hierarchical Bayesian model Stan non-centered reparameterization described last chapter. ran Hamiltonian Monte Carlo (Stan) sampler 5000 iterations across four parallel sampling chains total 20,000 samples posterior.8 Figure 6.2 shows 95% highest density interval recovered sampler’s posterior distribution.\nFigure 6.2: 95 percent highest density interval posterior distribution \\(\\gamma\\) estimated five-thousand iterations Metropolis-Hastings algorithm five-thousand iterations across four parallel chains Hamiltonian Monte Carlo Sampler (estimated using Stan). simulated gamma values subject represented sky-blue dots fall within highest density interval red dots fall outside .\nsubjects, simulated \\(\\gamma\\) values within highest-density interval. suggests sure-bet gamble task able elicit behaviors interest way measurable counterfactual predicted utility theory.","code":""},{"path":"modeling-methods-and-results.html","id":"parameter-estimation","chapter":"6 Modeling Methods and Results","heading":"6.2 Parameter Estimation","text":"confirmation able accurately recover simulated parameters sure-bet gamble task, move next stage computational modeling, parameter estimation. Specifically, compare counterfactual predicted utility theory explains human choice data sure-bet gamble task relative expected utility theory. primarily two reasons:Counterfactual predicted utility theory suggests , \\(\\gamma = 0\\), counterfactual utility option equivalent expected value. expected value special case expected utility theory risk aversion parameter, \\(\\rho = 1\\).sure-bet gamble task include losses, prohibits comparing counterfactual predicted utility theory prospect theory.total, estimated parameters seven variants expected utility theory counterfactual utility theory human choice data (Table 6.3).\nFigure 6.3: Parameters , description , different models fit human choice data sure-bet gamble task. models sampled Stan 5000 iterations across four parallel chains using hierarchical implementation. Individual parameters drawn normally distributed group-level distribution bounded inverse Probit transformation resulting uniform prior spanning zero one \\((\\gamma)\\), two \\((\\rho)\\), thirty \\((\\tau)\\).\nmodels sampled 5000 iterations across four parallel chains hierarchical Bayesian model formulation previously described.(Ahn, Haines, Zhang 2017) model, chain convergence group-level transformed individual-level parameters checked Gelman-Rubin statistics, \\(\\hat{R} \\leq 1.1\\), suggesting -chain variance lower within chain variance.(Gelman Rubin 1992) histogram representing samples population level posterior distribution parameter per model shown Figure 6.4.\nFigure 6.4: Placeholder caption.\n","code":""},{"path":"modeling-methods-and-results.html","id":"model-comparison","chapter":"6 Modeling Methods and Results","heading":"6.3 Model Comparison","text":"estimated posterior distributions model type, sought determine model best explains choice behavior. , used three different methods compare models, results summarized Table 6.5:Posterior predictive checks , model, simulated choices given (joint) posterior distribution participants’ estimated model parameter(s). included Stan’s generated quantities block, executed posterior sample generated. (Stan Development Team 2022) compared percentage predicted choices matches observed data summarized mean standard deviation model.Posterior predictive checks , model, simulated choices given (joint) posterior distribution participants’ estimated model parameter(s). included Stan’s generated quantities block, executed posterior sample generated. (Stan Development Team 2022) compared percentage predicted choices matches observed data summarized mean standard deviation model.Comparing marginal likelihoods model. probability observing choice behavior given model, \\(M\\), \\(P(\\text{Choices}|M)\\). marginal likelihood model estimated using bridge sampling.(Gronau, Singmann, Wagenmakers 2020) Marginal likelihoods often included calculations Bayes factors, describes relative evidence favor one model another quantifying ratio probability observing data given two models. marginal likelihoods computed log-scaled computational efficiency, means positive, less negative, marginal likelihood indicates better fit.Comparing marginal likelihoods model. probability observing choice behavior given model, \\(M\\), \\(P(\\text{Choices}|M)\\). marginal likelihood model estimated using bridge sampling.(Gronau, Singmann, Wagenmakers 2020) Marginal likelihoods often included calculations Bayes factors, describes relative evidence favor one model another quantifying ratio probability observing data given two models. marginal likelihoods computed log-scaled computational efficiency, means positive, less negative, marginal likelihood indicates better fit.Assessing penalized model fit model’s leave-one-cross validation predictive accuracy.(Vehtari, Gelman, Gabry 2017) approximated importance sampling posterior distribution calculate expected log pointwise predictive density (ELPD), logged sum pointwise posterior predictive distribution held data. multiplying ELPD negative two, get leave-one-information criterion, LOOIC. transformation makes easier compare information criterion (e.g., AIC, DIC), highlighting penalization model complexity.(Plummer 2008) include ELPD LOOIC easy comparison. Note less negative ELPD smaller (closer zero) LOOIC indicative better model fits.Assessing penalized model fit model’s leave-one-cross validation predictive accuracy.(Vehtari, Gelman, Gabry 2017) approximated importance sampling posterior distribution calculate expected log pointwise predictive density (ELPD), logged sum pointwise posterior predictive distribution held data. multiplying ELPD negative two, get leave-one-information criterion, LOOIC. transformation makes easier compare information criterion (e.g., AIC, DIC), highlighting penalization model complexity.(Plummer 2008) include ELPD LOOIC easy comparison. Note less negative ELPD smaller (closer zero) LOOIC indicative better model fits.\nFigure 6.5: Parameters , description , different models fit human choice data sure-bet gamble task along model comparison metrics. Posterior predictive choice accuracy represents mean standard deviation correctly predicted choices individual participants given simulations (joint) posterior distribution. ELPD Predictive Density LOOIC details well models perform unobserved data (leave-one-cross validation). Parantheses ELPD LOOIC indicate Monte Carlo sampling error. Marginal likelihood model evidence indicates plausibility data given model parantheses representing interquartile range likeihood estimations. general, better models smaller LOOIC higher posterior predictive choice accuracy, ELPD predictive accuracy (less negative), marginal likelihood model evidence (less negative). CPUT + Softmax Sensitivity EUT + Softmax Sensitivity highlighted easy reference discussed.\ntwo rows highlighted Table 6.5, represent direct comparison contractual predicted utility theory expected utility theory. metrics presented pose interesting problem blanket statement ‘better model’ smaller LOOIC higher (less negative) posterior predictive choice accuracy, ELPD, marginal likelihood model evidence, model fit metrics pose interesting problem.average, — fact, models — accurately predict 80% observed choices using posterior predictive distribution. look either ELPD LOOIC, see expected utility model performs better. Looking marginal likelihood, however, counterfactual predicted utility model seems better. seemingly disparate indicators make sense considering metric represents. next chapter, conclude thesis discussion results allude next steps contribute towards better understanding neurobiological basis decision-making risk.","code":""},{"path":"discussion-next-steps.html","id":"discussion-next-steps","chapter":"7 Discussion & Next Steps","heading":"7 Discussion & Next Steps","text":"modeling results described last chapter highlight nuances model comparison. predict choice behavior sure-bet gamble task, model ‘CPUT + Softmax Sensitivity’ estimated joint posterior distribution \\(\\gamma\\) \\(\\tau\\) ‘EUT + Softmax Sensitivity’ model fit joint posterior distribution \\(\\rho\\) \\(\\tau\\). CPUT model seemingly offers better explanation observed data. Indeed, log Bayes Factor 50.2, provides fair amount evidence favor CPUT EUT. time, ELPD LOOIC suggest expected utility theory better approximation unobserved choice data. means asked new person complete sure bet gamble task, expected utility theory may better predict data.thinking results, ’s important consider broader context work presented. mean goal develop neurobiologically plausible theory decision-making risk. culmination counterfactual predicted utility theory, CPUT. one hand, don’t think evidence presented sufficient conclude CPUT better theory decision-making risk EUT. However, seems offer better explanation data collected part sure-bet gamble task. think able provide evidence supporting CPUT generative theory decision-making, exciting!concluding future directions investigating CPUT, want highlight things. First, interesting case showing complex models necessarily better. Referring back Table 6.5, ’ll note model best fits observed choice data according marginal likelihood one estimated joint posterior distribution \\(\\gamma, \\tau,\\) \\(\\rho\\), ‘CPUT + Risk Aversion + Softmax Sensitivity.’ inclusion additional parameter improve overall posterior predictive choice accuracy impaired ELPD predictive density LOOIC. reason, avoid drawing conclusions (relatively, least) overfit model, pay considerable attention .Second, light evidence supporting EUT fair theory decision-making risk,9 want highlight potential neural correlates risk-aversion. 2009, Chsitopoulous colleagues reported activity interior frontal gyrus, located near dorsolateral prefrontal cortex, reflected subjective perception option’s riskiness objective evaluation risk. , describe signals inferior frontal gyrus integrate areas, striatum found sensitive changes magnitude, inform choice behavior.(Christopoulos et al. 2009)hand, Niv colleagues find behavioral neural evidence risk sensitivity involving nonlinear utility functions.(Niv et al. 2012) One possibility mention referencing Matthew Rabin Richard Thaler’s 2001 paper risk aversion(Matthew Rabin Richard H. Thaler 2001) general incompatability nonlinear utility functions small magnitudes.[Niv et al. (2012);] However, Rabin Thaler assume strict expected utility maximizer, observed data (e.g., softmax sensitivity parameter reflect deterministic choices).now entertain possibility CPUT provides mechanistic explanation choice behavior, discussing EUT, want focus outstanding questions involving potential neurobiological mechanisms. Specifically, hitherto unanswered question Kishida colleagues 2016 paper(Kishida et al. 2016) surrounds mechanism counterfactual prediction errors reward prediction errors integrated. One possibility proposed Montague, Kishida, colleagues serotonin system.(P. Read Montague et al. 2016) describe ‘opponent-processing framework’ reward prediction errors counterfactual prediction errors independently encoded distinct neural systems integrated , one possibility, exchange dopamine predominantly serotonergic neurons vice versa (e.g., cross-loading).(P. Read Montague et al. 2016; Zhou et al. 2005)2021, Kishida Sands proposed valence-partitioned reinforcement learning framework part ‘Dynamic Affective Core’ makes explicit predictions dopaminergic system interact opponent one inform choice behavior situations multi-valenced outcomes also associated subjective experiences feelings.(Kishida Sands 2021) valence-partitioned framework provides another basis investigating asymmetric choice behavior decisions involving gains losses.(Kahneman Tversky 1979; P. Sokol-Hessner et al. 2009) Although neural correlates behavior still investigation, hypothesized involve striatum(Tom et al. 2007) amygdala, area brain often associated anxiety fear.(P. Sokol-Hessner, Camerer, Phelps 2013; Peter Sokol-Hessner Rutledge 2019)extend work presented , hope incorporate ideas valence-partitioned reinforcement learning counterfactual signaling literature. Working towards goal developing neurobiological theory decision-making risk, next look CPUT predicts choices involving losses. CPUT’s predictions generalize gain loss domain, hope conduct neuroimaging study identify neural correlates CPUT. Fortunately, pretty good idea look.","code":""},{"path":"references.html","id":"references","chapter":"8 References","heading":"8 References","text":"","code":""}]
