<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>3 Neurobiology of Decision-Making | Counterfactuals, Dopamine, and Risky Behavior</title>
<meta name="author" content="Jonathan D. Trattner">
<meta name="description" content="In the last chapter, I used the term prospect to describe a problem that has two options with stated probabilities and outcomes. In the experimental literature, these prospects are...">
<meta name="generator" content="bookdown 0.25 with bs4_book()">
<meta property="og:title" content="3 Neurobiology of Decision-Making | Counterfactuals, Dopamine, and Risky Behavior">
<meta property="og:type" content="book">
<meta property="og:url" content="https://masters-thesis.jdtrat.com/neurobiology-of-decision-making.html">
<meta property="og:description" content="In the last chapter, I used the term prospect to describe a problem that has two options with stated probabilities and outcomes. In the experimental literature, these prospects are...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="3 Neurobiology of Decision-Making | Counterfactuals, Dopamine, and Risky Behavior">
<meta name="twitter:site" content="@jdtrat">
<meta name="twitter:description" content="In the last chapter, I used the term prospect to describe a problem that has two options with stated probabilities and outcomes. In the experimental literature, these prospects are...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Deriving a neurobiological theory of decision-making under risk">Counterfactuals, Dopamine, and Risky Behavior</a>:
        <small class="text-muted">Deriving a neurobiological theory of decision-making under risk</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Hello, World</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="evolution-of-decision-theory.html"><span class="header-section-number">2</span> Evolution of Decision Theory</a></li>
<li><a class="active" href="neurobiology-of-decision-making.html"><span class="header-section-number">3</span> Neurobiology of Decision-Making</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/jdtrat/masters-thesis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="neurobiology-of-decision-making" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Neurobiology of Decision-Making<a class="anchor" aria-label="anchor" href="#neurobiology-of-decision-making"><i class="fas fa-link"></i></a>
</h1>
<p>In the last chapter, I used the term prospect to describe a problem that has two options with stated probabilities and outcomes. In the experimental literature, these prospects are ‘description-based.’ Formally, researchers who use description-based prospects in their experiments ask participants to select one of the available options that are presented along with a complete description of a non-trivial problem.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-barron2003a" role="doc-biblioref">Barron and Erev 2003</a>)</span></p>
<p>When looking towards the neuroscientific literature of decision-making, a different type of experimental paradigm is perhaps more common: ‘experiential’ or ‘feedback-based’ decisions.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-barron2003a" role="doc-biblioref">Barron and Erev 2003</a>)</span>. By interacting with the environment, humans (and other animals) associate the consequences of different actions and adapt their behavior accordingly. In other words, we learn. We learn over time that we want to eat sushi for dinner, it’s faster to take the highway to work, and we’re better off if we go to sleep before midnight.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;These learned experiences are in response to the choices posed in the thesis’s introduction.&lt;/p&gt;"><sup>3</sup></a></p>
<p>Looking towards the animal learning field, we see many accounts of experiential learning. To list a few:</p>
<ul>
<li><p>Thorndike’s Law of Effect states that an animal’s behavior can be modified by the consequences of an action.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-thorndike1911" role="doc-biblioref">Thorndike 1911</a>)</span></p></li>
<li><p>Classical (Pavlovian) conditioning details learning to predict rewards or punishments from a stimuli independent of any action-taken.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-pavlov2010" role="doc-biblioref">Pavlov 2010</a>)</span></p></li>
<li><p>Operant (instrumental) conditioning involves learning how rewards and punishments are contingent upon one’s actions.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-b.f.skinner1938" role="doc-biblioref">B. F. Skinner 1938</a>)</span></p></li>
</ul>
<p>That a behavior (an action or decision) is predicated upon prior experiences allows us to formalize the relationship between states. Here, I use state in reference to the representation of stimuli. For example, the state <span class="math inline">\(s \in S\)</span> at time <span class="math inline">\(t\)</span> (<span class="math inline">\(s_t\)</span>) may be comprised of internal states (hunger, thirst, fatigue) or external ones (light, music, temperature).</p>
<p>Consider Pavlov’s experiment which showed how repeatedly giving a dog food after ringing a bell will condition the dog to salivate after the bell is rung.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-pavlov2010" role="doc-biblioref">Pavlov 2010</a>)</span> This means that, over time, behavior elicited by a stimulus (food) can be evoked by a – previously – neutral stimulus (the bell). In one of the first attempts to empirically describe this process, Bush and Mosteller suggest the probability of Pavlov’s dog salivating, <span class="math inline">\(P(\text{sal})\)</span>, on the <em>next</em> presentation of food with the bell (next trial, <span class="math inline">\(tr+1\)</span>) is a function of what happened <em>last</em> presentation (last trial, <span class="math inline">\(tr-1\)</span>) discounted by what was experienced during <em>this</em> presentation (food reward this trial, <span class="math inline">\(R_tr\)</span>.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-bush1951" role="doc-biblioref">Bush and Mosteller 1951a</a>, <a href="neurobiology-of-decision-making.html#ref-bush1951a" role="doc-biblioref">1951b</a>)</span></p>
<span class="math display" id="eq:bush-mosteller">\[\begin{equation}
P(\text{sal})_{\text{tr}+1} = P(\text{sal})_{\text{tr}-1} + \alpha (R_{\text{tr}} - P(\text{sal})_{\text{tr}-1})
\tag{3.1}
\end{equation}\]</span>
<p>Bush and Mosteller’s equation computes an average of previously experienced rewards. <span class="math inline">\(0 \leq \alpha \leq 1\)</span> is a learning rate, which modulates the influence of more recent rewards. Bush and Mosteller’s work forms the basis for modern approaches to this problem of <strong><em>reinforcement learning</em></strong>.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-glimcher2011a" role="doc-biblioref">Glimcher 2011</a>)</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;For a more detailed explanation of Bush and Mosteller’s work, the development of reinforcement learning for applications to Neuroscience, and much of the material I cover in this chapter, please refer to Paul Glimcher’s &lt;em&gt;Understanding dopamine and reinforcement learning: The dopamine reward prediction error hypothesis&lt;/em&gt;.&lt;span class="citation"&gt;(&lt;a href="neurobiology-of-decision-making.html#ref-glimcher2011a" role="doc-biblioref"&gt;Glimcher 2011&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;'><sup>4</sup></a> While discretizing learning into trials is a logical first step to modeling behavior in experimental settings, it’s not easily applied to biological systems that continuously interact with their environments.</p>
<p>In his 1988 paper, <em>Learning to Predict by the Methods of Temporal Differences</em>, Richard Sutton introduces the antecedent for temporal-difference reinforcement learning (TDRL) algorithms.<span class="citation">(<a href="neurobiology-of-decision-making.html#ref-sutton1988" role="doc-biblioref">Sutton 1988</a>)</span> The TDRL algorithm provides a computational framework for optimally learning from experience how actions and their associated stimuli lead to rewards. <span class="citation">(<a href="neurobiology-of-decision-making.html#ref-sutton-barto-2018" role="doc-biblioref">Richard S. Sutton; Andrew G. Barto 2018</a>)</span></p>
<p>The ‘goal’ of TDRL algorithms are to estimate the value of a state and use that information to maximize rewards. This is achieved with a ‘teaching signal,’ called the temporal-difference reward prediction error (TD-RPE), which relates the current value of being in a state at time <span class="math inline">\(t\)</span> to what was expected.</p>
<span class="math display" id="eq:td-rpe">\[\begin{equation}
\delta_t = [\text{outcome}_t + \gamma V(S_{t+1})] - V(S_t)
\tag{3.2}
\end{equation}\]</span>
<p>The current value of a state is the sum of any outcome experienced at time <span class="math inline">\(t\)</span> plus the expectation of future outcomes from being in said state. This expectation of future values, <span class="math inline">\(V(S_{t+1})\)</span> is modulated by the temporal-discounting parameter <span class="math inline">\(0 \leq \gamma \leq 1\)</span>. The TD-RPE, <span class="math inline">\(\delta_t\)</span>, is the difference between the current value of a state and the most recent expectation for that state’s value, <span class="math inline">\(V(S_t)\)</span>. On each time step, the TD-RPE is used to update the estimated value of the current state following the learning rule where <span class="math inline">\(0 \leq \alpha \leq 1\)</span>, the learning rate, controls how much weight an individual places on the estimated value of the current state in light of the TD-RPE.</p>
<span class="math display" id="eq:td-value-update">\[\begin{equation}
\hat{V}(S_t) \leftarrow V(S_t) + (\alpha \cdot \delta_t)
\tag{3.3}
\end{equation}\]</span>

<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-allais1953" class="csl-entry">
Allais, M. 1953. <span>“Le Comportement de l’homme Rationnel Devant Le Risque: Critique Des Postulats Et Axiomes de l’ecole Americaine.”</span> <em>Econometrica</em> 21 (4): 503–46. <a href="https://doi.org/10.2307/1907921">https://doi.org/10.2307/1907921</a>.
</div>
<div id="ref-b.f.skinner1938" class="csl-entry">
B. F. Skinner. 1938. <em>The Behavior of Organisms: An Experimental Analysis</em>. New York: Appleton-Century.
</div>
<div id="ref-barron2003a" class="csl-entry">
Barron, Greg, and Ido Erev. 2003. <span>“Small Feedback-Based Decisions and Their Limited Correspondence to Description-Based Decisions.”</span> <em>Journal of Behavioral Decision Making</em> 16 (3): 215–33. <a href="https://doi.org/10.1002/bdm.443">https://doi.org/10.1002/bdm.443</a>.
</div>
<div id="ref-bush1951" class="csl-entry">
Bush, Robert R., and Frederick Mosteller. 1951a. <span>“A Mathematical Model for Simple Learning.”</span> <em>Psychological Review</em> 58 (5): 313–23. <a href="https://doi.org/10.1037/h0054388">https://doi.org/10.1037/h0054388</a>.
</div>
<div id="ref-bush1951a" class="csl-entry">
———. 1951b. <span>“A Model for Stimulus Generalization and Discrimination.”</span> <em>Psychological Review</em> 58 (6): 413–23. <a href="https://doi.org/10.1037/h0054576">https://doi.org/10.1037/h0054576</a>.
</div>
<div id="ref-danielbernoulli1954" class="csl-entry">
Daniel Bernoulli. 1954. <span>“Exposition of a New Theory on the Measurement of Risk.”</span> <em>Econometrica</em> 22 (1): 23–36.
</div>
<div id="ref-glimcher2011a" class="csl-entry">
Glimcher, P. W. 2011. <span>“Understanding Dopamine and Reinforcement Learning: The Dopamine Reward Prediction Error Hypothesis.”</span> <em>Proceedings of the National Academy of Sciences</em> 108 (Supplement<span>_</span>3): 15647–54. <a href="https://doi.org/10.1073/pnas.1014269108">https://doi.org/10.1073/pnas.1014269108</a>.
</div>
<div id="ref-kahneman1979" class="csl-entry">
Kahneman, Daniel, and Amos Tversky. 1979. <span>“Prospect Theory: An Analysis of Decision Under Risk.”</span> <em>Econometrica</em> 47 (2): 263. <a href="https://doi.org/10.2307/1914185">https://doi.org/10.2307/1914185</a>.
</div>
<div id="ref-liu2016a" class="csl-entry">
Liu, Zhiyuan, Lin Li, Li Zheng, Zengxi Hu, Ian D. Roberts, Xiuyan Guo, and Guang Yang. 2016. <span>“The Neural Basis of Regret and Relief During a Sequential Risk-Taking Task.”</span> <em>Neuroscience</em> 327 (July): 136–45. <a href="https://doi.org/10.1016/j.neuroscience.2016.04.018">https://doi.org/10.1016/j.neuroscience.2016.04.018</a>.
</div>
<div id="ref-loomes1982" class="csl-entry">
Loomes, Graham, and Robert Sugden. 1982. <span>“Regret Theory: An Alternative Theory of Rational Choice Under Uncertainty.”</span> <em>The Economic Journal</em> 92 (368): 805–24. <a href="https://doi.org/10.2307/2232669">https://doi.org/10.2307/2232669</a>.
</div>
<div id="ref-nealj.roese1997" class="csl-entry">
Neal J. Roese. 1997. <span>“Counterfactual Thinking.”</span> <em>Psychological Bulletin</em> 121.
</div>
<div id="ref-vonneumann1947" class="csl-entry">
Neumann, J. von, and Morgenstern, O. 1947. <em>Theory of Games and Economic Behavior, 2nd Edn.</em> Princeton University Press.
</div>
<div id="ref-pavlov2010" class="csl-entry">
Pavlov, Ivan P. 2010. <span>“Conditioned Reflexes: An Investigation of the Physiological Activity of the Cerebral Cortex.”</span> <em>Annals of Neurosciences</em> 17 (3). <a href="https://doi.org/10.5214/ans.0972-7531.1017309">https://doi.org/10.5214/ans.0972-7531.1017309</a>.
</div>
<div id="ref-sutton-barto-2018" class="csl-entry">
Richard S. Sutton; Andrew G. Barto. 2018. <em>Reinforcement Learning: An Introduction</em>. 2nd ed. MIT Press.
</div>
<div id="ref-sutton1988" class="csl-entry">
Sutton, Richard S. 1988. <span>“Learning to Predict by the Methods of Temporal Differences.”</span> <em>Machine Learning</em> 3 (1): 9–44. <a href="https://doi.org/10.1007/BF00115009">https://doi.org/10.1007/BF00115009</a>.
</div>
<div id="ref-thorndike1911" class="csl-entry">
Thorndike, Edward L. 1911. <em>Animal Intelligence : Experimental Studies</em>.
</div>
</div>
</div>










  <div class="chapter-nav">
<div class="prev"><a href="evolution-of-decision-theory.html"><span class="header-section-number">2</span> Evolution of Decision Theory</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#neurobiology-of-decision-making"><span class="header-section-number">3</span> Neurobiology of Decision-Making</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/jdtrat/masters-thesis/blob/main/thesis-documents/02_neurobiology-of-decision-making.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/jdtrat/masters-thesis/edit/main/thesis-documents/02_neurobiology-of-decision-making.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Counterfactuals, Dopamine, and Risky Behavior</strong>: Deriving a neurobiological theory of decision-making under risk" was written by Jonathan D. Trattner. It was last built on 2022-03-29.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
