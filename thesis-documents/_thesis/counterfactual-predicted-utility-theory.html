<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4 Counterfactual Predicted Utility Theory | Counterfactuals, Dopamine, and Risky Behavior</title>
<meta name="author" content="Jonathan D. Trattner">
<meta name="description" content="As discussed in the last chapter, the neurotransmitter dopamine seemingly encodes information about actual and counterfactual rewards,(Kishida et al. 2016) and their integration may play a guiding...">
<meta name="generator" content="bookdown 0.25 with bs4_book()">
<meta property="og:title" content="4 Counterfactual Predicted Utility Theory | Counterfactuals, Dopamine, and Risky Behavior">
<meta property="og:type" content="book">
<meta property="og:url" content="https://masters-thesis.jdtrat.com/counterfactual-predicted-utility-theory.html">
<meta property="og:description" content="As discussed in the last chapter, the neurotransmitter dopamine seemingly encodes information about actual and counterfactual rewards,(Kishida et al. 2016) and their integration may play a guiding...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="4 Counterfactual Predicted Utility Theory | Counterfactuals, Dopamine, and Risky Behavior">
<meta name="twitter:site" content="@jdtrat">
<meta name="twitter:description" content="As discussed in the last chapter, the neurotransmitter dopamine seemingly encodes information about actual and counterfactual rewards,(Kishida et al. 2016) and their integration may play a guiding...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Deriving a neurobiological theory of decision-making under risk">Counterfactuals, Dopamine, and Risky Behavior</a>:
        <small class="text-muted">Deriving a neurobiological theory of decision-making under risk</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Hello, World</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="evolution-of-decision-theory.html"><span class="header-section-number">2</span> Evolution of Decision Theory</a></li>
<li><a class="" href="neurobiology-of-decision-making.html"><span class="header-section-number">3</span> Neurobiology of Decision-Making</a></li>
<li><a class="active" href="counterfactual-predicted-utility-theory.html"><span class="header-section-number">4</span> Counterfactual Predicted Utility Theory</a></li>
<li><a class="" href="modeling-counterfactual-predicted-utility-theory.html"><span class="header-section-number">5</span> Modeling Counterfactual Predicted Utility Theory</a></li>
<li><a class="" href="references.html"><span class="header-section-number">6</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/jdtrat/masters-thesis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="counterfactual-predicted-utility-theory" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Counterfactual Predicted Utility Theory<a class="anchor" aria-label="anchor" href="#counterfactual-predicted-utility-theory"><i class="fas fa-link"></i></a>
</h1>
<p>As discussed in the last chapter, the neurotransmitter dopamine seemingly encodes information about actual and counterfactual rewards,<span class="citation">(<a href="references.html#ref-kishida2016" role="doc-biblioref">Kishida et al. 2016</a>)</span> and their integration may play a guiding role in decision-making. With this neural evidence, combined with behavioral economic theories offering descriptive models for people making risky decisions,<span class="citation">(<a href="references.html#ref-kahneman1979" role="doc-biblioref">Kahneman and Tversky 1979</a>; <a href="references.html#ref-loomes1982" role="doc-biblioref">Loomes and Sugden 1982</a>)</span> I propose ‘Counterfactual Predicted Utility Theory’ (CPUT) as a neurobiologically-plausible theory of decision-making under risk.</p>
<p>The intuition behind CPUT is the idea that people account for counterfactual outcomes when faced with a prospect and the integration of factual and counterfactual signals in the brain may discount or invert their preference for choosing one option over another. I hypothesize that this preference-reversal is modulated by a counterfactual weighting term, <span class="math inline">\(\gamma\)</span>, which may vary across people.</p>
<p>To formally derive CPUT, we can revisit the prospect I introduced in the first chapter with a hypothetical casino game. There are two options: choosing one will certainly three-thousand dollars; choosing another will give you an 80% chance of four-thousand dollars or nothing. Such a prospect is commonly denoted as follows where the first option leads to outcome <span class="math inline">\(x_1\)</span> with probability <span class="math inline">\(p_1\)</span> and the second option leads to outcomes <span class="math inline">\(x_2\)</span> with probability <span class="math inline">\(p_2\)</span>.</p>
<span class="math display" id="eq:prospect-notation">\[\begin{equation}
\begin{aligned}
\text{Option 1} &amp;= (x_1, p_1) \\ 
\text{Option 2} &amp;= (x_2, p_2)
\end{aligned}
\tag{4.1}
\end{equation}\]</span>
<p>Unless otherwise stated, the alternative outcomes of an option are assumed to be zero. That is, choosing Option 1 is a choice of receiving <span class="math inline">\(x_1\)</span> with probability <span class="math inline">\(p_1\)</span> or nothing with probability <span class="math inline">\((1 - p_1)\)</span>. A more explicit, and generalizable, representation of a prospect can be seen in Figure <a href="counterfactual-predicted-utility-theory.html#fig:prospect-diagram-general">4.1</a>. Here, Option 1 is a choice of receiving <span class="math inline">\(x_{1a}\)</span> with probability <span class="math inline">\(p_1\)</span> or <span class="math inline">\(x_{1b}\)</span> with probability <span class="math inline">\((1 - p_1)\)</span>. Similarly, Option 2 is a choice of receiving <span class="math inline">\(x_{2a}\)</span> with probability <span class="math inline">\(p_2\)</span> or <span class="math inline">\(x_{2b}\)</span> with probability <span class="math inline">\((1 - p_2)\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:prospect-diagram-general"></span>
<img src="figures/prospect_diagram_general.png" alt="Explicit representation of a prospect with two options. Choosing option 1 may lead to outcome $x_{1a}$ with probability $p_1$ or outcome $x_{1b}$ with probability $(1 - p_1)$. Choosing option 2 may lead to outcome $x_{2a}$ with probability $p_2$ or outcome $x_{2b}$ with probability $(1 - p_2)$." width="467"><p class="caption">
Figure 4.1: Explicit representation of a prospect with two options. Choosing option 1 may lead to outcome <span class="math inline">\(x_{1a}\)</span> with probability <span class="math inline">\(p_1\)</span> or outcome <span class="math inline">\(x_{1b}\)</span> with probability <span class="math inline">\((1 - p_1)\)</span>. Choosing option 2 may lead to outcome <span class="math inline">\(x_{2a}\)</span> with probability <span class="math inline">\(p_2\)</span> or outcome <span class="math inline">\(x_{2b}\)</span> with probability <span class="math inline">\((1 - p_2)\)</span>.
</p>
</div>
<p>With this representation, we can begin to formally define an option’s counterfactual utility, <span class="math inline">\(U_C\)</span>, as follows:</p>
<span class="math display" id="eq:calculating-uc">\[\begin{equation}
\begin{split}
U_{C}(\text{Option 1}) = p_{1} \cdot V_{C}(x_{1a}) + (1 - p_{1}) \cdot V_{C}(x_{1b}) \\ 
U_{C}(\text{Option 2}) = p_{2} \cdot V_{C}(x_{2a}) + (1 - p_{2}) \cdot V_{C}(x_{2b})
\end{split}
\tag{4.2} 
\end{equation}\]</span>
<p>As in Expected Utility Theory, an option’s utility is the expected value of its transformed value. The expected utility definition in Equation <a href="counterfactual-predicted-utility-theory.html#eq:calculating-ue">(4.3)</a> represents the same weighting as that from Equation <a href="counterfactual-predicted-utility-theory.html#eq:calculating-uc">(4.2)</a>. The difference stems from how the estimated counterfactual utility value, <span class="math inline">\(V_C\)</span> compares with the estimated expected utility value, <span class="math inline">\(V_E\)</span>.</p>
<span class="math display" id="eq:calculating-ue">\[\begin{equation}
\begin{split}
U_{E}(\text{Option 1}) = p_{1} \cdot V_{E}(x_{1}) + (1 - p_{1}) \cdot V_{E}(x_{2}) \\   
U_{E}(\text{Option 2}) = p_{2} \cdot V_{E}(x_{4}) + (1 - p_{2}) \cdot V_{E}(x_{3})
\end{split}
\tag{4.3}
\end{equation}\]</span>
<p>In EUT, as in prospect theory, the transformation of the stated outcome is exponentiated by a <em>risk-aversion</em> parameter, <span class="math inline">\(\rho\)</span>. Conversely, for CPUT, we define the transformation of the stated outcome as the face value minus a weighted sum of that option’s alternative outcome and the other option’s expected value. The transformations for each theory are presented in Equation <a href="counterfactual-predicted-utility-theory.html#eq:eut-cput-transformations">(4.4)</a>, which shows how a prospect of the form depicted in Figure <a href="counterfactual-predicted-utility-theory.html#fig:prospect-diagram-general">4.1</a> are represented.</p>
<span class="math display" id="eq:eut-cput-transformations">\[\begin{equation}
\begin{split}
\text{EUT:} \\
    V_{E}(x_{1a}) = x_{1a} \\
    V_{E}(x_{1b}) = x_{1b} \\
    V_{E}(x_{2a}) = x_{2a} \\
    V_{E}(x_{2b}) = x_{2b}
\end{split}
\hspace{3cm}
\begin{split}
\text{CPUT:} \\
    V_{C}(x_{1a}) = x_{1a} - \gamma[x_{1b} + EV(\text{Option 2})] \\
    V_{C}(x_{1b}) = x_{1b} - \gamma[x_{1a} + EV(\text{Option 2})] \\
    V_{C}(x_{2a}) = x_{2a} - \gamma[x_{2b} + EV(\text{Option 1})] \\
    V_{C}(x_{2b}) = x_{2b} - \gamma[x_{2a} + EV(\text{Option 1})]
\end{split}
\tag{4.4}
\end{equation}\]</span>
<p>Unlike the estimated expected utility value, <span class="math inline">\(V_E\)</span>, the estimated counterfactual utility value, <span class="math inline">\(V_C\)</span> is not a one-to-one mapping for the stated outcomes. To provide a better intuition for this within- and between-option dependency, it is helpful to consider a concrete example. By adapting Figure <a href="counterfactual-predicted-utility-theory.html#fig:prospect-diagram-general">4.1</a> to include the values from the casino example initially described, we can better see how each possible outcome may integrate when evaluating a given prospect.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:prospect-diagram-kt"></span>
<img src="figures/prospect_diagram_kt.png" alt="Example prospect diagram to visualize counterfactual integration. Choosing option 1 may lead to outcome $\$3000$ with probability $1.0$ or outcome $\$0$ with probability $(1 - 1.0)$. Choosing option 2 may lead to outcome $\$4000$ with probability $0.8$ or outcome $\$0$ with probability $(1 - 0.8)$. Estimating the counterfactual utility value of possible outcomes are dependent on one-another." width="488"><p class="caption">
Figure 4.2: Example prospect diagram to visualize counterfactual integration. Choosing option 1 may lead to outcome <span class="math inline">\(\$3000\)</span> with probability <span class="math inline">\(1.0\)</span> or outcome <span class="math inline">\(\$0\)</span> with probability <span class="math inline">\((1 - 1.0)\)</span>. Choosing option 2 may lead to outcome <span class="math inline">\(\$4000\)</span> with probability <span class="math inline">\(0.8\)</span> or outcome <span class="math inline">\(\$0\)</span> with probability <span class="math inline">\((1 - 0.8)\)</span>. Estimating the counterfactual utility value of possible outcomes are dependent on one-another.
</p>
</div>
<p>To illustrate CPUT by walking-through Figure <a href="counterfactual-predicted-utility-theory.html#fig:prospect-diagram-kt">4.2</a>, let’s assume that I have a counterfactual-weighting term of <span class="math inline">\(\gamma = 0.1\)</span>. This means that the stated outcomes are transformed given the available counterfactual information from each potential outcome as follows:</p>
<span class="math display" id="eq:cput-transformation-kt-demo">\[\begin{equation}
\begin{aligned}
V_{C}(\$3000) &amp;= 3000 - 0.1[0 + EV(\text{Option 2})] \\
&amp;= 3000 - 0.1[0 + 3200] \\
&amp;= 2680 \\
V_{C}(\$0) &amp;= 0 - 0.1[3000 + EV(\text{Option 2})] \\
&amp;= 0 - 0.1[3000 + 3200] \\
&amp;= -620 \\
V_{C}(\$4000) &amp;= 4000 - 0.1[0 + EV(\text{Option 1})] \\
&amp;= 0 - 0.1[4000 + 3000] \\
&amp;= -700 \\
V_{C}(\$0) &amp;= 0 - 0.1[4000 + EV(\text{Option 1})] \\
&amp;= 4000 - 0.1[0 + 3000] \\
&amp;= 3700 \\
\end{aligned}
\tag{4.5}
\end{equation}\]</span>
<p>When these values are combined by Equation <a href="counterfactual-predicted-utility-theory.html#eq:calculating-uc">(4.2)</a>, we see that <span class="math inline">\(U_C(\text{Option 2}) &gt; U_C(\text{Option 1})\)</span>:</p>
<span class="math display" id="eq:calculating-uc-kt-demo">\[\begin{equation}
\begin{aligned}
U_{C}(\text{Option 1}) &amp;= 1 \cdot 2680 + (1 - 1) \cdot -620) \\ 
&amp;= 2680 \\
U_{C}(\text{Option 2}) &amp;= 0.8 \cdot 3700 + (1 - 0.8) \cdot -700) \\
&amp;= 2820
\end{aligned}
\tag{4.6} 
\end{equation}\]</span>
<p>To maximize my utility, I would choose Option 2 and progress down the diagram to the first node on the right-hand side. In doing this, I forwent the opportunity to have Option 1. If I chose differently, I would have reached the node on the left, which has an expected value of $3000, but I didn’t. From my current position, there is an 80% chance that I will find myself in the red node, with $4000. If the proverbial coin-flip goes against me, however, I would find myself at the cyan node with nothing to show for it. By walking-through this example, I hoped to convey how the possible outcomes relate to one-another and how factual and counterfactual information may be integrated to inform one’s decision.</p>
<p>Importantly, these equations suggest that when <span class="math inline">\(\gamma = 0\)</span>, when one places no weight on counterfactual events, the counterfactual utility is equivalent to the expected value. In other words, when <span class="math inline">\(\gamma = 0\)</span>, <span class="math inline">\(U_C(\text{Option 1}) = EV(\text{Option 1})\)</span> and <span class="math inline">\(U_C(\text{Option 2}) = EV(\text{Option 2})\)</span>. If people don’t place weight on counterfactual information, we might expect choice behavior to be consistent with maximizing expected value (or, to better compare theories of decision-making, maximizing expected utility). To provide evidence in support of CPUT as a generative theory of decision-making, I test the hypothesis that <span class="math inline">\(\gamma &gt; 0\)</span> which means that people <em>do</em> consider counterfactual outcomes when faced with a risky prospect. To do this, I use choice data from a ‘Sure Bet or Gamble’ task.</p>

</div>
  <div class="chapter-nav">
<div class="prev"><a href="neurobiology-of-decision-making.html"><span class="header-section-number">3</span> Neurobiology of Decision-Making</a></div>
<div class="next"><a href="modeling-counterfactual-predicted-utility-theory.html"><span class="header-section-number">5</span> Modeling Counterfactual Predicted Utility Theory</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#counterfactual-predicted-utility-theory"><span class="header-section-number">4</span> Counterfactual Predicted Utility Theory</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/jdtrat/masters-thesis/blob/main/thesis-documents/03_cput.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/jdtrat/masters-thesis/edit/main/thesis-documents/03_cput.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Counterfactuals, Dopamine, and Risky Behavior</strong>: Deriving a neurobiological theory of decision-making under risk" was written by Jonathan D. Trattner. It was last built on 2022-04-01.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
