
@book{vonneumann1947,
	title = {Theory of Games and Economic Behavior, 2nd edn.},
	author = {von Neumann, J. and {Morgenstern, O.}, },
	year = {1947},
	date = {1947},
	publisher = {Princeton University Press}
}

@article{danielbernoulli1954,
	title = {Exposition of a New Theory on the Measurement of Risk},
	author = {Daniel Bernoulli, },
	year = {1954},
	date = {1954},
	journal = {Econometrica},
	pages = {23--36},
	volume = {22},
	number = {1}
}

@article{allais1953,
	title = {Le Comportement de l'Homme Rationnel devant le Risque: Critique des Postulats et Axiomes de l'Ecole Americaine},
	author = {Allais, M.},
	year = {1953},
	date = {1953},
	journal = {Econometrica},
	pages = {503--546},
	volume = {21},
	number = {4},
	doi = {10.2307/1907921},
	url = {https://www.jstor.org/stable/1907921}
}

@article{kahneman1979,
	title = {Prospect Theory: An Analysis of Decision under Risk},
	author = {Kahneman, Daniel and Tversky, Amos},
	year = {1979},
	month = {03},
	date = {1979-03},
	journal = {Econometrica},
	pages = {263},
	volume = {47},
	number = {2},
	doi = {10.2307/1914185},
	url = {https://www.jstor.org/stable/1914185?origin=crossref},
	langid = {en}
}

@article{loomes1982,
	title = {Regret Theory: An Alternative Theory of Rational Choice Under Uncertainty},
	author = {Loomes, Graham and Sugden, Robert},
	year = {1982},
	date = {1982},
	journal = {The Economic Journal},
	pages = {805--824},
	volume = {92},
	number = {368},
	doi = {10.2307/2232669},
	url = {https://www.jstor.org/stable/2232669},
	note = {Publisher: [Royal Economic Society, Wiley]}
}

@article{bell1982,
	title = {Regret in Decision Making under Uncertainty},
	author = {Bell, David E.},
	year = {1982},
	date = {1982},
	journal = {Operations Research},
	pages = {961--981},
	volume = {30},
	number = {5},
	url = {https://www.jstor.org/stable/170353},
	note = {Publisher: INFORMS}
}

@article{liu2016,
	title = {The neural basis of regret and relief during a sequential risk-taking task},
	author = {Liu, Zhiyuan and Li, Lin and Zheng, Li and Hu, Zengxi and Roberts, Ian D. and Guo, Xiuyan and Yang, Guang},
	year = {2016},
	month = {07},
	date = {2016-07-07},
	journal = {Neuroscience},
	pages = {136--145},
	volume = {327},
	doi = {10.1016/j.neuroscience.2016.04.018},
	url = {http://www.sciencedirect.com/science/article/pii/S0306452216300835},
	langid = {en}
}

@article{nealj.roese1997,
	title = {Counterfactual Thinking},
	author = {Neal J. Roese, },
	year = {1997},
	date = {1997},
	journal = {Psychological Bulletin},
	volume = {121}
}

@article{liu2016a,
	title = {The neural basis of regret and relief during a sequential risk-taking task},
	author = {Liu, Zhiyuan and Li, Lin and Zheng, Li and Hu, Zengxi and Roberts, Ian D. and Guo, Xiuyan and Yang, Guang},
	year = {2016},
	month = {07},
	date = {2016-07-07},
	journal = {Neuroscience},
	pages = {136--145},
	volume = {327},
	doi = {10.1016/j.neuroscience.2016.04.018},
	url = {http://www.sciencedirect.com/science/article/pii/S0306452216300835},
	langid = {en}
}

@article{wise2004,
	title = {Dopamine, learning and motivation},
	author = {Wise, R. A.},
	year = {2004},
	month = {06},
	date = {2004-06},
	journal = {Nat Rev Neurosci},
	pages = {483--94},
	volume = {5},
	number = {6},
	doi = {10.1038/nrn1406}
}

@article{montague2004,
	title = {Computational roles for dopamine in behavioural control},
	author = {Montague, P. Read and Hyman, Steven E. and Cohen, Jonathan D.},
	year = {2004},
	month = {10},
	date = {2004-10-14},
	journal = {Nature},
	pages = {760--767},
	volume = {431},
	number = {7010},
	doi = {10.1038/nature03015},
	note = {PMID: 15483596},
	langid = {eng}
}

@article{glimcher2011,
	title = {Understanding dopamine and reinforcement learning: The dopamine reward prediction error hypothesis},
	author = {Glimcher, P. W.},
	year = {2011},
	date = {2011},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {15647--15654},
	volume = {108},
	number = {Supplement{\_}3},
	doi = {10.1073/pnas.1014269108}
}

@article{barron2003a,
	title = {Small feedback-based decisions and their limited correspondence to description-based decisions},
	author = {Barron, Greg and Erev, Ido},
	year = {2003},
	date = {2003},
	journal = {Journal of Behavioral Decision Making},
	pages = {215--233},
	volume = {16},
	number = {3},
	doi = {10.1002/bdm.443}
}

@book{thorndike1911,
	title = {Animal intelligence : experimental studies},
	author = {Thorndike, Edward L.},
	year = {1911},
	date = {1911},
	langid = {English}
}

@article{pavlov_conditioned_1927,
	title = {Conditioned reflexes: {An} investigation of the physiological activity of the cerebral cortex},
	volume = {17},
	issn = {0972-7531},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4116985/},
	doi = {10.5214/ans.0972-7531.1017309},
	number = {3},
	journal = {Annals of Neurosciences},
	author = {Pavlov, Ivan P.},
	year = {1927},
	annote = {The following values have no corresponding Zotero field:publisher: SAGE Publications},
	file = {Pavlov-2010-Conditioned-reflexes-an-investigat:/Users/jt/Zotero/storage/K6GH47YL/Pavlov-2010-Conditioned-reflexes-an-investigat.pdf:application/pdf},
}
@book{b.f.skinner1938,
	title = {The Behavior of Organisms: An Experimental Analysis},
	author = {B. F. Skinner, },
	year = {1938},
	date = {1938},
	publisher = {Appleton-Century},
	address = {New York}
}

@article{bush1951,
	title = {A mathematical model for simple learning},
	author = {Bush, Robert R. and Mosteller, Frederick},
	year = {1951},
	date = {1951},
	journal = {Psychological Review},
	pages = {313--323},
	volume = {58},
	number = {5},
	doi = {10.1037/h0054388},
	note = {Place: US
Publisher: American Psychological Association}
}

@article{bush1951a,
	title = {A model for stimulus generalization and discrimination},
	author = {Bush, Robert R. and Mosteller, Frederick},
	year = {1951},
	date = {1951},
	journal = {Psychological Review},
	pages = {413--423},
	volume = {58},
	number = {6},
	doi = {10.1037/h0054576},
	note = {Place: US
Publisher: American Psychological Association}
}

@article{glimcher2011a,
	title = {Understanding dopamine and reinforcement learning: The dopamine reward prediction error hypothesis},
	author = {Glimcher, P. W.},
	year = {2011},
	date = {2011},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {15647--15654},
	volume = {108},
	number = {Supplement{\_}3},
	doi = {10.1073/pnas.1014269108}
}

@book{sutton-barto-2018,
	title = {Reinforcement Learning: An Introduction},
	author = {{Richard S. Sutton; Andrew G. Barto}, },
	year = {2018},
	date = {2018},
	publisher = {MIT Press},
	edition = {2}
}

@article{sutton1988,
	title = {Learning to predict by the methods of temporal differences},
	author = {Sutton, Richard S.},
	year = {1988},
	month = {08},
	date = {1988-08},
	journal = {Machine Learning},
	pages = {9--44},
	volume = {3},
	number = {1},
	doi = {10.1007/BF00115009},
	url = {http://link.springer.com/10.1007/BF00115009},
	langid = {en}
}

@article{montague1996,
	title = {A framework for mesencephalic dopamine systems based on predictive Hebbian learning},
	author = {Montague, Pr and Dayan, P and Sejnowski, Tj},
	year = {1996},
	month = {03},
	date = {1996-03-01},
	journal = {The Journal of Neuroscience},
	pages = {1936--1947},
	volume = {16},
	number = {5},
	doi = {10.1523/JNEUROSCI.16-05-01936.1996},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.16-05-01936.1996},
	langid = {en}
}

@article{schultz1997,
	title = {A neural substrate of prediction and reward},
	author = {Schultz, W. and Dayan, P. and Montague, P. R.},
	year = {1997},
	month = {03},
	date = {1997-03-14},
	journal = {Science (New York, N.Y.)},
	pages = {1593--1599},
	volume = {275},
	number = {5306},
	doi = {10.1126/science.275.5306.1593},
	note = {PMID: 9054347},
	langid = {eng}
}

@article{tomasljunberg1992,
	title = {Responses of Monkey Dopamine Neurons During Learning of Behavioral Reactions},
	author = {Tomas Ljunberg,  and Paul Apicella,  and Wolfram Schultz, },
	year = {1992},
	date = {1992},
	journal = {Journal of Neurophysiology},
	volume = {67}
}

@article{schultz1993,
	title = {Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task},
	author = {Schultz, W and Apicella, P and Ljungberg, T},
	year = {1993},
	month = {03},
	date = {1993-03-01},
	journal = {The Journal of Neuroscience},
	pages = {900--913},
	volume = {13},
	number = {3},
	doi = {10.1523/JNEUROSCI.13-03-00900.1993},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.13-03-00900.1993},
	langid = {en}
}

@article{bayer2005,
	title = {Midbrain dopamine neurons encode a quantitative reward prediction error signal},
	author = {Bayer, Hannah M. and Glimcher, Paul W.},
	year = {2005},
	month = {07},
	date = {2005-07-07},
	journal = {Neuron},
	pages = {129--141},
	volume = {47},
	number = {1},
	doi = {10.1016/j.neuron.2005.05.020},
	note = {PMID: 15996553
PMCID: PMC1564381},
	langid = {eng}
}

@article{hart2014,
	title = {Phasic dopamine release in the rat nucleus accumbens symmetrically encodes a reward prediction error term},
	author = {Hart, Andrew S. and Rutledge, Robb B. and Glimcher, Paul W. and Phillips, Paul E. M.},
	year = {2014},
	month = {01},
	date = {2014-01-15},
	journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	pages = {698--704},
	volume = {34},
	number = {3},
	doi = {10.1523/JNEUROSCI.2489-13.2014},
	note = {PMID: 24431428
PMCID: PMC3891951},
	langid = {eng}
}

@article{schultz1998,
	title = {Reward prediction in primate basal ganglia and frontal cortex},
	author = {Schultz, W. and Tremblay, L. and Hollerman, J. R.},
	year = {1998},
	month = {05},
	date = {1998-05},
	journal = {Neuropharmacology},
	pages = {421--429},
	volume = {37},
	number = {4-5},
	doi = {10.1016/s0028-3908(98)00071-9},
	note = {PMID: 9704983},
	langid = {eng}
}

@article{zaghloul2009,
	title = {Human Substantia Nigra Neurons Encode Unexpected Financial Rewards},
	author = {Zaghloul, K. A. and Blanco, J. A. and Weidemann, C. T. and McGill, K. and Jaggi, J. L. and Baltuch, G. H. and Kahana, M. J.},
	year = {2009},
	date = {2009},
	journal = {Science},
	pages = {1496--1499},
	volume = {323},
	number = {5920},
	doi = {10.1126/science.1167342}
}

@article{kishida2011,
	title = {Sub-Second Dopamine Detection in Human Striatum},
	author = {Kishida, Kenneth T. and Sandberg, Stefan G. and Lohrenz, Terry and Comair, Youssef G. and {Sáez}, Ignacio and Phillips, Paul E. M. and Montague, P. Read},
	year = {2011},
	month = {08},
	date = {2011-08-04},
	journal = {PLOS ONE},
	pages = {e23291},
	volume = {6},
	number = {8},
	doi = {10.1371/journal.pone.0023291},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0023291},
	langid = {en}
}

@article{moran2018,
	title = {The Protective Action Encoding of Serotonin Transients in the Human Brain},
	author = {Moran, Rosalyn J and Kishida, Kenneth T and Lohrenz, Terry and Saez, Ignacio and Laxton, Adrian W and Witcher, Mark R and Tatter, Stephen B and Ellis, Thomas L and Phillips, Paul EM and Dayan, Peter and Montague, P Read},
	year = {2018},
	month = {05},
	date = {2018-05},
	journal = {Neuropsychopharmacology},
	pages = {1425--1435},
	volume = {43},
	number = {6},
	doi = {10.1038/npp.2017.304},
	url = {http://www.nature.com/articles/npp2017304},
	langid = {en}
}

@article{bang2020,
	title = {Sub-second Dopamine and Serotonin Signaling in Human Striatum during Perceptual Decision-Making},
	author = {Bang, Dan and Kishida, Kenneth T. and Lohrenz, Terry and White, Jason P. and Laxton, Adrian W. and Tatter, Stephen B. and Fleming, Stephen M. and Montague, P. Read},
	year = {2020},
	month = {10},
	date = {2020-10-12},
	journal = {Neuron},
	doi = {10.1016/j.neuron.2020.09.015},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627320307157},
	langid = {en}
}

@article{kishida2016,
	title = {Subsecond dopamine fluctuations in human striatum encode superposed error signals about actual and counterfactual reward},
	author = {Kishida, Kenneth T. and Saez, Ignacio and Lohrenz, Terry and Witcher, Mark R. and Laxton, Adrian W. and Tatter, Stephen B. and White, Jason P. and Ellis, Thomas L. and Phillips, Paul E. M. and Montague, P. Read},
	year = {2016},
	month = {01},
	date = {2016-01-05},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {200--205},
	volume = {113},
	number = {1},
	doi = {10.1073/pnas.1513619112},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1513619112},
	langid = {en}
}

@article{schultz1997a,
	title = {A neural substrate of prediction and reward},
	author = {Schultz, W. and Dayan, P. and Montague, P. R.},
	year = {1997},
	month = {03},
	date = {1997-03-14},
	journal = {Science (New York, N.Y.)},
	pages = {1593--1599},
	volume = {275},
	number = {5306},
	doi = {10.1126/science.275.5306.1593},
	note = {PMID: 9054347},
	langid = {eng}
}

@article{bayer2005a,
	title = {Midbrain dopamine neurons encode a quantitative reward prediction error signal},
	author = {Bayer, Hannah M. and Glimcher, Paul W.},
	year = {2005},
	month = {07},
	date = {2005-07-07},
	journal = {Neuron},
	pages = {129--141},
	volume = {47},
	number = {1},
	doi = {10.1016/j.neuron.2005.05.020},
	note = {PMID: 15996553
PMCID: PMC1564381},
	langid = {eng}
}

@article{roesch2007,
	title = {Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards},
	author = {Roesch, Matthew R. and Calu, Donna J. and Schoenbaum, Geoffrey},
	year = {2007},
	month = {12},
	date = {2007-12},
	journal = {Nature Neuroscience},
	pages = {1615--1624},
	volume = {10},
	number = {12},
	doi = {10.1038/nn2013},
	note = {PMID: 18026098
PMCID: PMC2562672},
	langid = {eng}
}

@misc{liebenow2021,
	title = {The {\textquoteleft}Expected Value{\textquoteright} (not the surprising outcomes) of risky choices drives subjective pleasure of risky decision making in patients with Impulse Control Disorder},
	author = {B. Liebenow,  and A. Jiang,  and E. DiMarco,  and L. P. Sands,  and M. Moya-Mendez,  and M. S. Siddiqui,  and I. HAQ,  and K.T. Kishida, },
	year = {2021},
	month = {11},
	date = {2021-11-09},
	url = {https://www.abstractsonline.com/pp8/#!/10485/presentation/17371}
}

@article{wilson2019,
	title = {Ten simple rules for the computational modeling of behavioral data},
	author = {Wilson, Robert C and Collins, Anne GE},
	editor = {Behrens, Timothy E},
	year = {2019},
	month = {11},
	date = {2019-11-26},
	journal = {eLife},
	pages = {e49547},
	volume = {8},
	doi = {10.7554/eLife.49547},
	url = {https://doi.org/10.7554/eLife.49547},
	note = {Publisher: eLife Sciences Publications, Ltd}
}

@book{richardmcelreath2020,
	title = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan},
	author = {Richard McElreath, },
	year = {2020},
	date = {2020},
	publisher = {CRC Press}
}

@book{dogucu,
	title = {Bayes Rules! An Introduction to Applied Bayesian Modeling},
	author = {Dogucu, {Alicia A. Johnson, Miles Q. Ott, Mine}},
	url = {https://www.bayesrulesbook.com/},
	year = {2022},
	date = {2022},
	publisher = {CRC Press}
}

@article{sokol-hessner2009,
	title = {Thinking like a trader selectively reduces individuals' loss aversion},
	author = {Sokol-Hessner, P. and Hsu, M. and Curley, N. G. and Delgado, M. R. and Camerer, C. F. and Phelps, E. A.},
	year = {2009},
	month = {03},
	date = {2009-03-31},
	journal = {Proc Natl Acad Sci U S A},
	pages = {5035--40},
	volume = {106},
	number = {13},
	doi = {10.1073/pnas.0806761106},
	note = {PMCID: PMC2656558}
}

@misc{haines2018,
	title = {Human Choice and Reinforcement Learning (3)},
	author = {Haines, Nathaniel},
	year = {2018},
	month = {09},
	date = {2018-09-08},
	url = {http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3/2018-03-24-human-choice-and-reinforcement-learning-3/},
	langid = {en-us}
}

@book{standevelopmentteam2022,
	title = {Stan Modeling Language Users Guide and Reference Manual},
	author = {Stan Development Team, },
	year = {2022},
	date = {2022},
	url = {https://mc-stan.org}
}

@article{ahn2011,
	title = {A model-based fMRI analysis with hierarchical Bayesian parameter estimation.},
	author = {Ahn, Woo-Young and Krawitz, Adam and Kim, Woojae and Busemeyer, Jerome R. and Brown, Joshua W.},
	year = {2011},
	month = {05},
	date = {2011-05},
	journal = {Journal of Neuroscience, Psychology, and Economics},
	pages = {95--110},
	volume = {4},
	number = {2},
	doi = {10.1037/a0020684},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0020684},
	langid = {en}
}

@article{ahn2017,
	title = {Revealing Neurocomputational Mechanisms of Reinforcement Learning and Decision-Making With the hBayesDM Package},
	author = {Ahn, Woo-Young and Haines, Nathaniel and Zhang, Lei},
	year = {2017},
	month = {10},
	date = {2017-10-01},
	journal = {Computational Psychiatry},
	pages = {24--57},
	volume = {1},
	doi = {10.1162/CPSY_a_00002},
	url = {https://doi.org/10.1162/CPSY_a_00002}
}

@article{ahn2014,
	title = {Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users},
	author = {Ahn, Woo-Young and Vasilev, Georgi and Lee, Sung-Ha and Busemeyer, Jerome R. and Kruschke, John K. and Bechara, Antoine and Vassileva, Jasmin},
	year = {2014},
	month = {08},
	date = {2014-08-12},
	journal = {Frontiers in Psychology},
	pages = {849},
	volume = {5},
	doi = {10.3389/fpsyg.2014.00849},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4129374/},
	note = {PMID: 25161631
PMCID: PMC4129374}
}

@article{gelman1992,
	title = {Inference from Iterative Simulation Using Multiple Sequences},
	author = {Gelman, Andrew and Rubin, Donald B.},
	year = {1992},
	month = {11},
	date = {1992-11},
	journal = {Statistical Science},
	pages = {457--472},
	volume = {7},
	number = {4},
	doi = {10.1214/ss/1177011136},
	url = {https://projecteuclid.org/journals/statistical-science/volume-7/issue-4/Inference-from-Iterative-Simulation-Using-Multiple-Sequences/10.1214/ss/1177011136.full},
	note = {Publisher: Institute of Mathematical Statistics}
}

@article{gronau2020,
	title = {bridgesampling: An R Package for Estimating Normalizing Constants},
	author = {Gronau, Quentin F. and Singmann, Henrik and Wagenmakers, Eric-Jan},
	year = {2020},
	month = {02},
	date = {2020-02-27},
	journal = {Journal of Statistical Software},
	pages = {1--29},
	volume = {92},
	doi = {10.18637/jss.v092.i10},
	url = {https://doi.org/10.18637/jss.v092.i10},
	langid = {en}
}

@article{vehtari2017,
	title = {Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	year = {2017},
	month = {09},
	date = {2017-09-01},
	journal = {Statistics and Computing},
	pages = {1413--1432},
	volume = {27},
	number = {5},
	doi = {10.1007/s11222-016-9696-4},
	url = {https://doi.org/10.1007/s11222-016-9696-4},
	langid = {en}
}

@article{plummer2008,
	title = {Penalized loss functions for Bayesian model comparison},
	author = {Plummer, Martyn},
	year = {2008},
	month = {07},
	date = {2008-07},
	journal = {Biostatistics},
	pages = {523--539},
	volume = {9},
	number = {3},
	doi = {10.1093/biostatistics/kxm049},
	url = {https://academic.oup.com/biostatistics/article-lookup/doi/10.1093/biostatistics/kxm049},
	langid = {en}
}


@article{sokol-hessner_psychological_2019,
	title = {The {Psychological} and {Neural} {Basis} of {Loss} {Aversion}},
	volume = {28},
	issn = {0963-7214},
	url = {https://doi.org/10.1177/0963721418806510},
	doi = {10.1177/0963721418806510},
	abstract = {Loss aversion is a central element of prospect theory, the dominant theory of decision making under uncertainty for the past four decades, and refers to the overweighting of potential losses relative to equivalent gains, a critical determinant of risky decision making. Recent advances in affective and decision neuroscience have shed new light on the psychological and neurobiological mechanisms underlying loss aversion. Here, integrating disparate literatures from the level of neurotransmitters to subjective reports of emotion, we propose a novel neural and computational framework that links norepinephrine to loss aversion and identifies a distinct role for dopamine in risk taking for rewards. We also propose that loss aversion specifically relates to anticipated emotions and aspects of the immediate experience of realized gains and losses but not their long-term emotional consequences, highlighting an underappreciated temporal structure. Finally, we discuss challenges to loss aversion and the relevance of loss aversion to understanding psychiatric disorders. Refining models of loss aversion will have broad consequences for the science of decision making and for how we understand individual variation in economic preferences and psychological well-being across both healthy and psychiatric populations.},
	language = {en},
	number = {1},
	urldate = {2022-04-03},
	journal = {Current Directions in Psychological Science},
	author = {Sokol-Hessner, Peter and Rutledge, Robb B.},
	month = feb,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	keywords = {decision making, emotion, loss aversion, prospect theory, well-being},
	pages = {20--27},
	file = {SAGE PDF Full Text:/Users/jt/Zotero/storage/6EYVS6PT/Sokol-Hessner and Rutledge - 2019 - The Psychological and Neural Basis of Loss Aversio.pdf:application/pdf},
}

@article{sokol-hessner_emotion_2013,
	title = {Emotion regulation reduces loss aversion and decreases amygdala responses to losses},
	volume = {8},
	issn = {1749-5024 (Electronic) 1749-5016 (Linking)},
	doi = {10.1093/scan/nss002},
	abstract = {Emotion regulation strategies can alter behavioral and physiological responses to emotional stimuli and the neural correlates of those responses in regions such as the amygdala or striatum. The current study investigates the brain systems engaged when using an emotion regulation technique during financial decisions. In decision making, regulating emotion with reappraisal-focused strategies that encourage taking a different perspective has been shown to reduce loss aversion as observed both in choices and in the relative arousal responses to actual loss and gain outcomes. In the current study, we find using fMRI that behavioral loss aversion correlates with amygdala activity in response to losses relative to gains. Success in regulating loss aversion also correlates with the reduction in amygdala responses to losses but not to gains. Furthermore, across both decisions and outcomes, we find the reappraisal strategy increases baseline activity in dorsolateral and ventromedial prefrontal cortex and the striatum. The similarity of the neural circuitry observed to that seen in emotion regulation, despite divergent tasks, serves as further evidence for a role of emotion in decision making, and for the power of reappraisal to change assessments of value and thereby choices.},
	number = {3},
	journal = {Soc Cogn Affect Neurosci},
	author = {Sokol-Hessner, P. and Camerer, C. F. and Phelps, E. A.},
	month = mar,
	year = {2013},
	pmcid = {PMC3594725},
	keywords = {Adolescent, Female, Humans, Male, Young Adult, Magnetic Resonance Imaging, Image Processing, Computer-Assisted, Statistics as Topic, *Decision Making, Oxygen/blood, Emotions/*physiology, *Brain Mapping, Amygdala/blood supply/*physiology, Neural Inhibition/*physiology},
	pages = {341--50},
	annote = {Sokol-Hessner, PeterCamerer, Colin FPhelps, Elizabeth AengR01 AG039283/AG/NIA NIH HHS/R01 MH080756/MH/NIMH NIH HHS/AG039283/AG/NIA NIH HHS/MH080756/MH/NIMH NIH HHS/Research Support, N.I.H., ExtramuralResearch Support, Non-U.S. Gov'tEnglandSoc Cogn Affect Neurosci. 2013 Mar;8(3):341-50. doi: 10.1093/scan/nss002. Epub 2012 Jan 24.},
	annote = {The following values have no corresponding Zotero field:auth-address: Department of Psychology, New York University, 6 Washington Place, New York, NY 10003, USA.edition: 2012/01/26accession-num: 22275168},
	file = {Sokol-Hessner et al. - 2013 - Emotion regulati:/Users/jt/Zotero/storage/WMY97REL/Sokol-Hessner et al. - 2013 - Emotion regulati.pdf:application/pdf},
}

@article{tom_neural_2007,
	title = {The {Neural} {Basis} of {Loss} {Aversion} in {Decision}-{Making} {Under} {Risk}},
	volume = {315},
	copyright = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/315/5811/515},
	doi = {10.1126/science.1134239},
	abstract = {Overlapping brain networks respond more to gambling losses than to gains, correlating with behavioral observations about risk aversion.
Overlapping brain networks respond more to gambling losses than to gains, correlating with behavioral observations about risk aversion.},
	language = {en},
	number = {5811},
	urldate = {2020-01-22},
	journal = {Science},
	author = {Tom, Sabrina M. and Fox, Craig R. and Trepel, Christopher and Poldrack, Russell A.},
	month = jan,
	year = {2007},
	pmid = {17255512},
	pages = {515--518},
	file = {Full Text PDF:/Users/jt/Zotero/storage/GBVG5A2A/Tom et al. - 2007 - The Neural Basis of Loss Aversion in Decision-Maki.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/QGMGTTZ7/tab-figures-data.html:text/html},
}


@article{montague_efficiency_2016,
	title = {An efficiency framework for valence processing systems inspired by soft cross-wiring},
	volume = {11},
	issn = {2352-1546},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5300026/},
	doi = {10.1016/j.cobeha.2016.08.002},
	abstract = {Serotonin has been proposed as an opponent to dopamine. This review explores positive and negative value pathways for structuring this opponency.The positive and negative pathways co-mingle through transmitter cross-loading. Cross-loading is proposed as a way to tile ‘'valence space'. Recent experiments suggest that subsecond dopamine delivery to human striatum encodes a combination of reward prediction errors and counterfactual errors thus composing the actual with the possible into one neurochemical signal. Here, we present a model where the counterfactual part of these striatal dopamine fluctuations originates in another valuation system that shadows the dopamine system by acting as its near-antipode in terms of spike-rate encoding yet co-releases dopamine alongside its own native neurotransmitter. We show that such a hypothesis engenders important representational consequences where valence processing appears subject to the efficient encoding considerations common to the visual and auditory systems. This new perspective opens up important computational consequences for understanding how value-predicting information should integrate with sensory processing streams.},
	urldate = {2019-02-09},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Montague, P Read and Kishida, Kenneth T and Moran, Rosalyn J and Lohrenz, Terry M},
	month = oct,
	year = {2016},
	pmid = {28191489},
	pmcid = {PMC5300026},
	pages = {121--129},
	file = {PubMed Central Full Text PDF:/Users/jt/Zotero/storage/LIT8TG36/Montague et al. - 2016 - An efficiency framework for valence processing sys.pdf:application/pdf},
}

@article{zhou_corelease_2005,
	title = {Corelease of {Dopamine} and {Serotonin} from {Striatal} {Dopamine} {Terminals}},
	volume = {46},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627305001261},
	doi = {10.1016/j.neuron.2005.02.010},
	abstract = {The striatum receives rich dopaminergic and more moderate serotonergic innervation. After vesicular release, dopamine and serotonin (5-hydroxytryptamine, 5-HT) signaling is controlled by transporter-mediated reuptake. Dopamine is taken up by dopamine transporters (DATs), which are expressed at the highest density in the striatum. Although DATs also display a low affinity for 5-HT, that neurotransmitter is normally efficiently taken up by the 5-HT transporters. We found that when extracellular 5-HT is elevated by exogenous application or by using antidepressants (e.g., fluoxetine) to inhibit the 5-HT transporters, the extremely dense striatal DATs uptake 5-HT into dopamine terminals. Immunohistochemical results and measurements using fast cyclic voltammetry showed that elevated 5-HT is taken up by DATs into striatal dopamine terminals that subsequently release 5-HT and dopamine together. These results suggest that antidepressants that block serotonin transporters or other factors that elevate extracellular 5-HT alter the temporal and spatial relationship between dopamine and 5-HT signaling in the striatum.},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {Neuron},
	author = {Zhou, Fu-Ming and Liang, Yong and Salas, Ramiro and Zhang, Lifen and De Biasi, Mariella and Dani, John A.},
	month = apr,
	year = {2005},
	pages = {65--74},
	file = {ScienceDirect Full Text PDF:/Users/jt/Zotero/storage/2R2DCRIK/Zhou et al. - 2005 - Corelease of Dopamine and Serotonin from Striatal .pdf:application/pdf;ScienceDirect Snapshot:/Users/jt/Zotero/storage/SXB89ZNY/S0896627305001261.html:text/html},
}


@incollection{kishida_dynamic_2021,
	address = {Cham},
	title = {A {Dynamic} {Affective} {Core} to {Bind} the {Contents}, {Context}, and {Value} of {Conscious} {Experience}},
	isbn = {978-3-030-82965-0},
	url = {https://doi.org/10.1007/978-3-030-82965-0_12},
	abstract = {The private and dynamic nature of conscious subjective experience poses an empirical challenge that has led neuroscience-based theories about consciousness to note the importance of ‘the hard problem’ of explaining how subjective phenomenal experience can arise from neural activity but set it aside and focus on the ‘easier’ problems associated with information representation and behavior. This approach leaves a major gap in our understanding of the neural mechanisms underlying conscious subjective experience and its dynamic nature. However, computational methods integrated with a variety of tools for measuring human brain activity are beginning to link dynamic changes in subjective affect with reproducible neurobehavioral signals in humans. In particular, research applying computational reinforcement learning theory has shown tremendous utility in investigating human choice behavior and the role the dopaminergic system plays in dynamic behavioral control. This research is beginning to reveal an explicit connection between the dynamics of dopaminergic signals and dynamic changes in subjective affect. However, it should be obvious that the dopaminergic system alone is not sufficient to explain all of the complexities of affective dynamics. We review foundational work, highlight current problems and open questions, and propose a Dynamic Affective Core Hypothesis that integrates advances in our understanding of the representation of the content and context of conscious experiences with our nascent understanding about how these representations acquire and retain affective subjective value.},
	language = {en},
	urldate = {2021-12-06},
	booktitle = {Affect {Dynamics}},
	publisher = {Springer International Publishing},
	author = {Kishida, Kenneth T. and Sands, L. Paul},
	editor = {Waugh, Christian E. and Kuppens, Peter},
	year = {2021},
	doi = {10.1007/978-3-030-82965-0_12},
	keywords = {Dopamine, Reinforcement learning, Serotonin, Norepinephrine, Consciousness, Qualia, Reward prediction error, Subjective experience},
	pages = {293--328},
	file = {Submitted Version:/Users/jt/Zotero/storage/QRUKNUD4/Kishida and Sands - 2021 - A Dynamic Affective Core to Bind the Contents, Con.pdf:application/pdf},
}

@article{christopoulos_neural_2009,
	title = {Neural {Correlates} of {Value}, {Risk}, and {Risk} {Aversion} {Contributing} to {Decision} {Making} under {Risk}},
	volume = {29},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2794196/},
	doi = {10.1523/JNEUROSCI.2614-09.2009},
	abstract = {Decision making under risk is central to human behavior. Economic decision theory suggests that value, risk, and risk aversion influence choice behavior. Although previous studies identified neural correlates of decision parameters, the contribution of these correlates to actual choices is unknown. In two different experiments, participants chose between risky and safe options. We identified discrete blood oxygen level-dependent (BOLD) correlates of value and risk in the ventral striatum and anterior cingulate, respectively. Notably, increasing inferior frontal gyrus activity to low risk and safe options correlated with higher risk aversion. Importantly, the combination of these BOLD responses effectively decoded the behavioral choice. Striatal value and cingulate risk responses increased the probability of a risky choice, whereas inferior frontal gyrus responses showed the inverse relationship. These findings suggest that the BOLD correlates of decision factors are appropriate for an ideal observer to detect behavioral choices. More generally, these biological data contribute to the validity of the theoretical decision parameters for actual decisions under risk.},
	number = {40},
	urldate = {2022-04-03},
	journal = {The Journal of Neuroscience},
	author = {Christopoulos, George I. and Tobler, Philippe N. and Bossaerts, Peter and Dolan, Raymond J. and Schultz, Wolfram},
	month = oct,
	year = {2009},
	pmid = {19812332},
	pmcid = {PMC2794196},
	pages = {12574--12583},
	file = {Full Text:/Users/jt/Zotero/storage/F339T2SW/Christopoulos et al. - 2009 - Neural Correlates of Value, Risk, and Risk Aversio.pdf:application/pdf},
}


@article{niv_neural_2012,
	title = {Neural {Prediction} {Errors} {Reveal} a {Risk}-{Sensitive} {Reinforcement}-{Learning} {Process} in the {Human} {Brain}},
	volume = {32},
	copyright = {Copyright © 2012 the authors 0270-6474/12/320551-12\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/32/2/551},
	doi = {10.1523/JNEUROSCI.5498-10.2012},
	abstract = {Humans and animals are exquisitely, though idiosyncratically, sensitive to risk or variance in the outcomes of their actions. Economic, psychological, and neural aspects of this are well studied when information about risk is provided explicitly. However, we must normally learn about outcomes from experience, through trial and error. Traditional models of such reinforcement learning focus on learning about the mean reward value of cues and ignore higher order moments such as variance. We used fMRI to test whether the neural correlates of human reinforcement learning are sensitive to experienced risk. Our analysis focused on anatomically delineated regions of a priori interest in the nucleus accumbens, where blood oxygenation level-dependent (BOLD) signals have been suggested as correlating with quantities derived from reinforcement learning. We first provide unbiased evidence that the raw BOLD signal in these regions corresponds closely to a reward prediction error. We then derive from this signal the learned values of cues that predict rewards of equal mean but different variance and show that these values are indeed modulated by experienced risk. Moreover, a close neurometric–psychometric coupling exists between the fluctuations of the experience-based evaluations of risky options that we measured neurally and the fluctuations in behavioral risk aversion. This suggests that risk sensitivity is integral to human learning, illuminating economic models of choice, neuroscientific models of affective learning, and the workings of the underlying neural mechanisms.},
	language = {en},
	number = {2},
	urldate = {2022-04-03},
	journal = {Journal of Neuroscience},
	author = {Niv, Yael and Edlund, Jeffrey A. and Dayan, Peter and O'Doherty, John P.},
	month = jan,
	year = {2012},
	pmid = {22238090},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	pages = {551--562},
	file = {Full Text PDF:/Users/jt/Zotero/storage/BJ7CGPYK/Niv et al. - 2012 - Neural Prediction Errors Reveal a Risk-Sensitive R.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/6NZZS5WC/551.html:text/html},
}


@article{matthew_rabin_anomalies_2001,
	title = {Anomalies: {Risk} {Aversion}},
	volume = {15},
	language = {en},
	number = {1},
	journal = {Journal of Economic Perspectives},
	author = {{Matthew Rabin} and {Richard H. Thaler}},
	year = {2001},
	pages = {219--232},
	file = {Anomalies Risk Aversion.pdf:/Users/jt/Zotero/storage/9BDSX79Y/Anomalies Risk Aversion.pdf:application/pdf},
}

@article{shoda_predicting_1990,
	title = {Predicting adolescent cognitive and self-regulatory competencies from preschool delay of gratification: {Identifying} diagnostic conditions},
	volume = {26},
	issn = {1939-0599},
	shorttitle = {Predicting adolescent cognitive and self-regulatory competencies from preschool delay of gratification},
	doi = {10.1037/0012-1649.26.6.978},
	abstract = {Variations of the self-imposed delay-of-gratification situation in preschool were compared to determine when individual differences in this situation may predict aspects of cognitive and self-regulatory competence and coping in adolescence. Preschool children from a university community participated in experiments that varied features of the self-imposed delay situation. Experimental analyses of the cognitive–attentional processes that affect waiting in this situation helped identify conditions in which delay behavior would be most likely to reflect relevant cognitive and attentional competencies. As hypothesized, in those conditions, coherent patterns of statistically significant correlations were found between seconds of delay time in such conditions in preschool and cognitive and academic competence and ability to cope with frustration and stress in adolescence. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Developmental Psychology},
	author = {Shoda, Yuichi and Mischel, Walter and Peake, Philip K.},
	year = {1990},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Cognitive Ability, Competence, Coping Behavior, Delay of Gratification, Early Experience, Longitudinal Studies, Self-Control},
	pages = {978--986},
	file = {Full Text:/Users/jt/Zotero/storage/YCYWRCJQ/Shoda et al. - 1990 - Predicting adolescent cognitive and self-regulator.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/QASEHFDJ/1991-06927-001.html:text/html},
}

@article{watts_revisiting_2018,
	title = {Revisiting the {Marshmallow} {Test}: {A} {Conceptual} {Replication} {Investigating} {Links} {Between} {Early} {Delay} of {Gratification} and {Later} {Outcomes}},
	volume = {29},
	issn = {0956-7976},
	shorttitle = {Revisiting the {Marshmallow} {Test}},
	url = {https://doi.org/10.1177/0956797618761661},
	doi = {10.1177/0956797618761661},
	abstract = {We replicated and extended Shoda, Mischel, and Peake’s (1990) famous marshmallow study, which showed strong bivariate correlations between a child’s ability to delay gratification just before entering school and both adolescent achievement and socioemotional behaviors. Concentrating on children whose mothers had not completed college, we found that an additional minute waited at age 4 predicted a gain of approximately one tenth of a standard deviation in achievement at age 15. But this bivariate correlation was only half the size of those reported in the original studies and was reduced by two thirds in the presence of controls for family background, early cognitive ability, and the home environment. Most of the variation in adolescent achievement came from being able to wait at least 20 s. Associations between delay time and measures of behavioral outcomes at age 15 were much smaller and rarely statistically significant.},
	language = {en},
	number = {7},
	urldate = {2022-04-03},
	journal = {Psychological Science},
	author = {Watts, Tyler W. and Duncan, Greg J. and Quan, Haonan},
	month = jul,
	year = {2018},
	note = {Publisher: SAGE Publications Inc},
	keywords = {achievement, behavioral problems, early childhood, gratification delay, longitudinal analysis, marshmallow test, open data},
	pages = {1159--1177},
	file = {Full Text:/Users/jt/Zotero/storage/SNWMUVFC/Watts et al. - 2018 - Revisiting the Marshmallow Test A Conceptual Repl.pdf:application/pdf},
}


@article{w_mischel_attention_1970,
	title = {Attention in delay of gratification},
	url = {https://content.apa.org/doiLanding?doi=10.1037%2Fh0029815},
	abstract = {Explored the role of attentional processes in voluntary delay of reward by manipulating children's attention to the rewards for which they were waiting in a delay-of-gratification paradigm. 32 preschool children waited for a preferred but delayed reward while facing either the delayed reward, a less preferred but immediately available reward, both rewards, or no rewards. The dependent measure was the amount of time they waited for the preferred outcome before forfeiting it for the sake of the less desired but immediately available one. Results contradict predictions from psychodynamic theory and from speculations concerning self-instructions during time binding. Unexpectedly, but in accord with frustrative nonreward theory, voluntary waiting time was substantially increased when Ss could not attend to rewards during the waiting period. Implications are discussed for a theory of the development of delay of gratification.},
	language = {en},
	urldate = {2022-04-03},
	journal = {Journal of Personality and Social Psychology},
	author = {{W. Mischel} and {E. B. Ebbesen}},
	year = {1970},
	file = {Snapshot:/Users/jt/Zotero/storage/UJSQRMNI/doiLanding.html:text/html},
}


@article{van_de_schoot_bayesian_2021,
	title = {Bayesian statistics and modelling},
	volume = {1},
	copyright = {2021 Springer Nature Limited},
	issn = {2662-8449},
	url = {https://www.nature.com/articles/s43586-020-00001-2},
	doi = {10.1038/s43586-020-00001-2},
	abstract = {Bayesian statistics is an approach to data analysis based on Bayes’ theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events. This Primer describes the stages involved in Bayesian analysis, from specifying the prior and data models to deriving inference, model checking and refinement. We discuss the importance of prior and posterior predictive checking, selecting a proper technique for sampling from a posterior distribution, variational inference and variable selection. Examples of successful applications of Bayesian analysis across various research fields are provided, including in social sciences, ecology, genetics, medicine and more. We propose strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist. Finally, we outline the impact of Bayesian analysis on artificial intelligence, a major goal in the next decade.},
	language = {en},
	number = {1},
	urldate = {2022-04-01},
	journal = {Nature Reviews Methods Primers},
	author = {van de Schoot, Rens and Depaoli, Sarah and King, Ruth and Kramer, Bianca and Märtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
	month = jan,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Scientific community, Statistics},
	pages = {1--26},
	file = {Snapshot:/Users/jt/Zotero/storage/AIHA8HPJ/s43586-020-00001-2.html:text/html;Submitted Version:/Users/jt/Zotero/storage/BBSZH3Z5/van de Schoot et al. - 2021 - Bayesian statistics and modelling.pdf:application/pdf;van de Schoot et al. - 2021 - Bayesian statistics and modelling.pdf:/Users/jt/Zotero/storage/EZF6VTHV/van de Schoot et al. - 2021 - Bayesian statistics and modelling.pdf:application/pdf},
}


@article{agranov_stochastic_2017,
	title = {Stochastic {Choice} and {Preferences} for {Randomization}},
	volume = {125},
	issn = {0022-3808},
	url = {https://www.journals.uchicago.edu/doi/10.1086/689774},
	doi = {10.1086/689774},
	abstract = {We conduct an experiment in which subjects face the same questions repeated multiple times, with repetitions of two types: (1) following the literature, the repetitions are distant from each other; (2) in a novel treatment, the repetitions are in a row, and subjects are told that the questions will be repeated. We find that a large majority of subjects exhibit stochastic choice in both cases. We discuss the implications for models of stochastic choice.},
	number = {1},
	urldate = {2022-05-01},
	journal = {Journal of Political Economy},
	author = {Agranov, Marina and Ortoleva, Pietro},
	month = feb,
	year = {2017},
	note = {Publisher: The University of Chicago Press},
	pages = {40--68},
	file = {Full Text PDF:/Users/jt/Zotero/storage/Z7DVY8TC/Agranov and Ortoleva - 2017 - Stochastic Choice and Preferences for Randomizatio.pdf:application/pdf},
}

@article{tversky_intransitivity_1969,
	title = {Intransitivity of preferences.},
	volume = {76},
	issn = {0033-295X},
	url = {http://content.apa.org/journals/rev/76/1/31},
	doi = {10.1037/h0026750},
	language = {en},
	number = {1},
	urldate = {2022-05-01},
	journal = {Psychological Review},
	author = {Tversky, Amos},
	year = {1969},
	pages = {31--48},
	file = {Tversky - 1969 - Intransitivity of preferences..pdf:/Users/jt/Zotero/storage/HZZ3E696/Tversky - 1969 - Intransitivity of preferences..pdf:application/pdf},
}
