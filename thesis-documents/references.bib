
@book{vonneumann1947,
	title = {Theory of Games and Economic Behavior, 2nd edn.},
	author = {von Neumann, J. and {Morgenstern, O.}, },
	year = {1947},
	date = {1947},
	publisher = {Princeton University Press}
}

@article{danielbernoulli1954,
	title = {Exposition of a New Theory on the Measurement of Risk},
	author = {Daniel Bernoulli, },
	year = {1954},
	date = {1954},
	journal = {Econometrica},
	pages = {23--36},
	volume = {22},
	number = {1}
}

@article{allais1953,
	title = {Le Comportement de l'Homme Rationnel devant le Risque: Critique des Postulats et Axiomes de l'Ecole Americaine},
	author = {Allais, M.},
	year = {1953},
	date = {1953},
	journal = {Econometrica},
	pages = {503--546},
	volume = {21},
	number = {4},
	doi = {10.2307/1907921},
	url = {https://www.jstor.org/stable/1907921}
}

@article{kahneman1979,
	title = {Prospect Theory: An Analysis of Decision under Risk},
	author = {Kahneman, Daniel and Tversky, Amos},
	year = {1979},
	month = {03},
	date = {1979-03},
	journal = {Econometrica},
	pages = {263},
	volume = {47},
	number = {2},
	doi = {10.2307/1914185},
	url = {https://www.jstor.org/stable/1914185?origin=crossref},
	langid = {en}
}

@article{loomes1982,
	title = {Regret Theory: An Alternative Theory of Rational Choice Under Uncertainty},
	author = {Loomes, Graham and Sugden, Robert},
	year = {1982},
	date = {1982},
	journal = {The Economic Journal},
	pages = {805--824},
	volume = {92},
	number = {368},
	doi = {10.2307/2232669},
	url = {https://www.jstor.org/stable/2232669},
	note = {Publisher: [Royal Economic Society, Wiley]}
}

@article{bell1982,
	title = {Regret in Decision Making under Uncertainty},
	author = {Bell, David E.},
	year = {1982},
	date = {1982},
	journal = {Operations Research},
	pages = {961--981},
	volume = {30},
	number = {5},
	url = {https://www.jstor.org/stable/170353},
	note = {Publisher: INFORMS}
}

@article{liu2016,
	title = {The neural basis of regret and relief during a sequential risk-taking task},
	author = {Liu, Zhiyuan and Li, Lin and Zheng, Li and Hu, Zengxi and Roberts, Ian D. and Guo, Xiuyan and Yang, Guang},
	year = {2016},
	month = {07},
	date = {2016-07-07},
	journal = {Neuroscience},
	pages = {136--145},
	volume = {327},
	doi = {10.1016/j.neuroscience.2016.04.018},
	url = {http://www.sciencedirect.com/science/article/pii/S0306452216300835},
	langid = {en}
}

@article{nealj.roese1997,
	title = {Counterfactual Thinking},
	author = {Neal J. Roese, },
	year = {1997},
	date = {1997},
	journal = {Psychological Bulletin},
	volume = {121}
}

@article{liu2016a,
	title = {The neural basis of regret and relief during a sequential risk-taking task},
	author = {Liu, Zhiyuan and Li, Lin and Zheng, Li and Hu, Zengxi and Roberts, Ian D. and Guo, Xiuyan and Yang, Guang},
	year = {2016},
	month = {07},
	date = {2016-07-07},
	journal = {Neuroscience},
	pages = {136--145},
	volume = {327},
	doi = {10.1016/j.neuroscience.2016.04.018},
	url = {http://www.sciencedirect.com/science/article/pii/S0306452216300835},
	langid = {en}
}

@article{wise2004,
	title = {Dopamine, learning and motivation},
	author = {Wise, R. A.},
	year = {2004},
	month = {06},
	date = {2004-06},
	journal = {Nat Rev Neurosci},
	pages = {483--94},
	volume = {5},
	number = {6},
	doi = {10.1038/nrn1406}
}

@article{montague2004,
	title = {Computational roles for dopamine in behavioural control},
	author = {Montague, P. Read and Hyman, Steven E. and Cohen, Jonathan D.},
	year = {2004},
	month = {10},
	date = {2004-10-14},
	journal = {Nature},
	pages = {760--767},
	volume = {431},
	number = {7010},
	doi = {10.1038/nature03015},
	note = {PMID: 15483596},
	langid = {eng}
}

@article{glimcher2011,
	title = {Understanding dopamine and reinforcement learning: The dopamine reward prediction error hypothesis},
	author = {Glimcher, P. W.},
	year = {2011},
	date = {2011},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {15647--15654},
	volume = {108},
	number = {Supplement{\_}3},
	doi = {10.1073/pnas.1014269108}
}

@article{barron2003a,
	title = {Small feedback-based decisions and their limited correspondence to description-based decisions},
	author = {Barron, Greg and Erev, Ido},
	year = {2003},
	date = {2003},
	journal = {Journal of Behavioral Decision Making},
	pages = {215--233},
	volume = {16},
	number = {3},
	doi = {10.1002/bdm.443}
}

@book{thorndike1911,
	title = {Animal intelligence : experimental studies},
	author = {Thorndike, Edward L.},
	year = {1911},
	date = {1911},
	langid = {English}
}

@article{pavlov_conditioned_1927,
	title = {Conditioned reflexes: {An} investigation of the physiological activity of the cerebral cortex},
	volume = {17},
	issn = {0972-7531},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4116985/},
	doi = {10.5214/ans.0972-7531.1017309},
	number = {3},
	journal = {Annals of Neurosciences},
	author = {Pavlov, Ivan P.},
	year = {1927},
	annote = {The following values have no corresponding Zotero field:publisher: SAGE Publications},
	file = {Pavlov-2010-Conditioned-reflexes-an-investigat:/Users/jt/Zotero/storage/K6GH47YL/Pavlov-2010-Conditioned-reflexes-an-investigat.pdf:application/pdf},
}
@book{b.f.skinner1938,
	title = {The Behavior of Organisms: An Experimental Analysis},
	author = {B. F. Skinner, },
	year = {1938},
	date = {1938},
	publisher = {Appleton-Century},
	address = {New York}
}

@article{bush1951,
	title = {A mathematical model for simple learning},
	author = {Bush, Robert R. and Mosteller, Frederick},
	year = {1951},
	date = {1951},
	journal = {Psychological Review},
	pages = {313--323},
	volume = {58},
	number = {5},
	doi = {10.1037/h0054388},
	note = {Place: US
Publisher: American Psychological Association}
}

@article{bush1951a,
	title = {A model for stimulus generalization and discrimination},
	author = {Bush, Robert R. and Mosteller, Frederick},
	year = {1951},
	date = {1951},
	journal = {Psychological Review},
	pages = {413--423},
	volume = {58},
	number = {6},
	doi = {10.1037/h0054576},
	note = {Place: US
Publisher: American Psychological Association}
}

@article{glimcher2011a,
	title = {Understanding dopamine and reinforcement learning: The dopamine reward prediction error hypothesis},
	author = {Glimcher, P. W.},
	year = {2011},
	date = {2011},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {15647--15654},
	volume = {108},
	number = {Supplement{\_}3},
	doi = {10.1073/pnas.1014269108}
}

@book{sutton-barto-2018,
	title = {Reinforcement Learning: An Introduction},
	author = {{Richard S. Sutton; Andrew G. Barto}, },
	year = {2018},
	date = {2018},
	publisher = {MIT Press},
	edition = {2}
}

@article{sutton1988,
	title = {Learning to predict by the methods of temporal differences},
	author = {Sutton, Richard S.},
	year = {1988},
	month = {08},
	date = {1988-08},
	journal = {Machine Learning},
	pages = {9--44},
	volume = {3},
	number = {1},
	doi = {10.1007/BF00115009},
	url = {http://link.springer.com/10.1007/BF00115009},
	langid = {en}
}

@article{montague1996,
	title = {A framework for mesencephalic dopamine systems based on predictive Hebbian learning},
	author = {Montague, Pr and Dayan, P and Sejnowski, Tj},
	year = {1996},
	month = {03},
	date = {1996-03-01},
	journal = {The Journal of Neuroscience},
	pages = {1936--1947},
	volume = {16},
	number = {5},
	doi = {10.1523/JNEUROSCI.16-05-01936.1996},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.16-05-01936.1996},
	langid = {en}
}

@article{schultz1997,
	title = {A neural substrate of prediction and reward},
	author = {Schultz, W. and Dayan, P. and Montague, P. R.},
	year = {1997},
	month = {03},
	date = {1997-03-14},
	journal = {Science (New York, N.Y.)},
	pages = {1593--1599},
	volume = {275},
	number = {5306},
	doi = {10.1126/science.275.5306.1593},
	note = {PMID: 9054347},
	langid = {eng}
}

@article{tomasljunberg1992,
	title = {Responses of Monkey Dopamine Neurons During Learning of Behavioral Reactions},
	author = {Tomas Ljunberg,  and Paul Apicella,  and Wolfram Schultz, },
	year = {1992},
	date = {1992},
	journal = {Journal of Neurophysiology},
	volume = {67}
}

@article{schultz1993,
	title = {Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task},
	author = {Schultz, W and Apicella, P and Ljungberg, T},
	year = {1993},
	month = {03},
	date = {1993-03-01},
	journal = {The Journal of Neuroscience},
	pages = {900--913},
	volume = {13},
	number = {3},
	doi = {10.1523/JNEUROSCI.13-03-00900.1993},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.13-03-00900.1993},
	langid = {en}
}

@article{bayer2005,
	title = {Midbrain dopamine neurons encode a quantitative reward prediction error signal},
	author = {Bayer, Hannah M. and Glimcher, Paul W.},
	year = {2005},
	month = {07},
	date = {2005-07-07},
	journal = {Neuron},
	pages = {129--141},
	volume = {47},
	number = {1},
	doi = {10.1016/j.neuron.2005.05.020},
	note = {PMID: 15996553
PMCID: PMC1564381},
	langid = {eng}
}

@article{hart2014,
	title = {Phasic dopamine release in the rat nucleus accumbens symmetrically encodes a reward prediction error term},
	author = {Hart, Andrew S. and Rutledge, Robb B. and Glimcher, Paul W. and Phillips, Paul E. M.},
	year = {2014},
	month = {01},
	date = {2014-01-15},
	journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	pages = {698--704},
	volume = {34},
	number = {3},
	doi = {10.1523/JNEUROSCI.2489-13.2014},
	note = {PMID: 24431428
PMCID: PMC3891951},
	langid = {eng}
}

@article{schultz1998,
	title = {Reward prediction in primate basal ganglia and frontal cortex},
	author = {Schultz, W. and Tremblay, L. and Hollerman, J. R.},
	year = {1998},
	month = {05},
	date = {1998-05},
	journal = {Neuropharmacology},
	pages = {421--429},
	volume = {37},
	number = {4-5},
	doi = {10.1016/s0028-3908(98)00071-9},
	note = {PMID: 9704983},
	langid = {eng}
}

@article{zaghloul2009,
	title = {Human Substantia Nigra Neurons Encode Unexpected Financial Rewards},
	author = {Zaghloul, K. A. and Blanco, J. A. and Weidemann, C. T. and McGill, K. and Jaggi, J. L. and Baltuch, G. H. and Kahana, M. J.},
	year = {2009},
	date = {2009},
	journal = {Science},
	pages = {1496--1499},
	volume = {323},
	number = {5920},
	doi = {10.1126/science.1167342}
}

@article{kishida2011,
	title = {Sub-Second Dopamine Detection in Human Striatum},
	author = {Kishida, Kenneth T. and Sandberg, Stefan G. and Lohrenz, Terry and Comair, Youssef G. and {Sáez}, Ignacio and Phillips, Paul E. M. and Montague, P. Read},
	year = {2011},
	month = {08},
	date = {2011-08-04},
	journal = {PLOS ONE},
	pages = {e23291},
	volume = {6},
	number = {8},
	doi = {10.1371/journal.pone.0023291},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0023291},
	langid = {en}
}

@article{moran2018,
	title = {The Protective Action Encoding of Serotonin Transients in the Human Brain},
	author = {Moran, Rosalyn J and Kishida, Kenneth T and Lohrenz, Terry and Saez, Ignacio and Laxton, Adrian W and Witcher, Mark R and Tatter, Stephen B and Ellis, Thomas L and Phillips, Paul EM and Dayan, Peter and Montague, P Read},
	year = {2018},
	month = {05},
	date = {2018-05},
	journal = {Neuropsychopharmacology},
	pages = {1425--1435},
	volume = {43},
	number = {6},
	doi = {10.1038/npp.2017.304},
	url = {http://www.nature.com/articles/npp2017304},
	langid = {en}
}

@article{bang2020,
	title = {Sub-second Dopamine and Serotonin Signaling in Human Striatum during Perceptual Decision-Making},
	author = {Bang, Dan and Kishida, Kenneth T. and Lohrenz, Terry and White, Jason P. and Laxton, Adrian W. and Tatter, Stephen B. and Fleming, Stephen M. and Montague, P. Read},
	year = {2020},
	month = {10},
	date = {2020-10-12},
	journal = {Neuron},
	doi = {10.1016/j.neuron.2020.09.015},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627320307157},
	langid = {en}
}

@article{kishida2016,
	title = {Subsecond dopamine fluctuations in human striatum encode superposed error signals about actual and counterfactual reward},
	author = {Kishida, Kenneth T. and Saez, Ignacio and Lohrenz, Terry and Witcher, Mark R. and Laxton, Adrian W. and Tatter, Stephen B. and White, Jason P. and Ellis, Thomas L. and Phillips, Paul E. M. and Montague, P. Read},
	year = {2016},
	month = {01},
	date = {2016-01-05},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {200--205},
	volume = {113},
	number = {1},
	doi = {10.1073/pnas.1513619112},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1513619112},
	langid = {en}
}

@article{schultz1997a,
	title = {A neural substrate of prediction and reward},
	author = {Schultz, W. and Dayan, P. and Montague, P. R.},
	year = {1997},
	month = {03},
	date = {1997-03-14},
	journal = {Science (New York, N.Y.)},
	pages = {1593--1599},
	volume = {275},
	number = {5306},
	doi = {10.1126/science.275.5306.1593},
	note = {PMID: 9054347},
	langid = {eng}
}

@article{bayer2005a,
	title = {Midbrain dopamine neurons encode a quantitative reward prediction error signal},
	author = {Bayer, Hannah M. and Glimcher, Paul W.},
	year = {2005},
	month = {07},
	date = {2005-07-07},
	journal = {Neuron},
	pages = {129--141},
	volume = {47},
	number = {1},
	doi = {10.1016/j.neuron.2005.05.020},
	note = {PMID: 15996553
PMCID: PMC1564381},
	langid = {eng}
}

@article{roesch2007,
	title = {Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards},
	author = {Roesch, Matthew R. and Calu, Donna J. and Schoenbaum, Geoffrey},
	year = {2007},
	month = {12},
	date = {2007-12},
	journal = {Nature Neuroscience},
	pages = {1615--1624},
	volume = {10},
	number = {12},
	doi = {10.1038/nn2013},
	note = {PMID: 18026098
PMCID: PMC2562672},
	langid = {eng}
}

@misc{liebenow2021,
	title = {The {\textquoteleft}Expected Value{\textquoteright} (not the surprising outcomes) of risky choices drives subjective pleasure of risky decision making in patients with Impulse Control Disorder},
	author = {B. Liebenow,  and A. Jiang,  and E. DiMarco,  and L. P. Sands,  and M. Moya-Mendez,  and M. S. Siddiqui,  and I. HAQ,  and K.T. Kishida, },
	year = {2021},
	month = {11},
	date = {2021-11-09},
	url = {https://www.abstractsonline.com/pp8/#!/10485/presentation/17371}
}

@article{wilson2019,
	title = {Ten simple rules for the computational modeling of behavioral data},
	author = {Wilson, Robert C and Collins, Anne GE},
	editor = {Behrens, Timothy E},
	year = {2019},
	month = {11},
	date = {2019-11-26},
	journal = {eLife},
	pages = {e49547},
	volume = {8},
	doi = {10.7554/eLife.49547},
	url = {https://doi.org/10.7554/eLife.49547},
	note = {Publisher: eLife Sciences Publications, Ltd}
}

@book{richardmcelreath2020,
	title = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan},
	author = {Richard McElreath, },
	year = {2020},
	date = {2020},
	publisher = {CRC Press}
}

@book{dogucu,
	title = {Bayes Rules! An Introduction to Applied Bayesian Modeling},
	author = {Dogucu, {Alicia A. Johnson, Miles Q. Ott, Mine}},
	url = {https://www.bayesrulesbook.com/},
	year = {2022},
	date = {2022},
	publisher = {CRC Press}
}

@article{sokol-hessner2009,
	title = {Thinking like a trader selectively reduces individuals' loss aversion},
	author = {Sokol-Hessner, P. and Hsu, M. and Curley, N. G. and Delgado, M. R. and Camerer, C. F. and Phelps, E. A.},
	year = {2009},
	month = {03},
	date = {2009-03-31},
	journal = {Proc Natl Acad Sci U S A},
	pages = {5035--40},
	volume = {106},
	number = {13},
	doi = {10.1073/pnas.0806761106},
	note = {PMCID: PMC2656558}
}

@misc{haines2018,
	title = {Human Choice and Reinforcement Learning (3)},
	author = {Haines, Nathaniel},
	year = {2018},
	month = {09},
	date = {2018-09-08},
	url = {http://haines-lab.com/post/2018-03-24-human-choice-and-reinforcement-learning-3/2018-03-24-human-choice-and-reinforcement-learning-3/},
	langid = {en-us}
}

@book{standevelopmentteam2022,
	title = {Stan Modeling Language Users Guide and Reference Manual},
	author = {Stan Development Team, },
	year = {2022},
	date = {2022},
	url = {https://mc-stan.org}
}

@article{ahn2011,
	title = {A model-based fMRI analysis with hierarchical Bayesian parameter estimation.},
	author = {Ahn, Woo-Young and Krawitz, Adam and Kim, Woojae and Busemeyer, Jerome R. and Brown, Joshua W.},
	year = {2011},
	month = {05},
	date = {2011-05},
	journal = {Journal of Neuroscience, Psychology, and Economics},
	pages = {95--110},
	volume = {4},
	number = {2},
	doi = {10.1037/a0020684},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0020684},
	langid = {en}
}

@article{ahn2017,
	title = {Revealing Neurocomputational Mechanisms of Reinforcement Learning and Decision-Making With the hBayesDM Package},
	author = {Ahn, Woo-Young and Haines, Nathaniel and Zhang, Lei},
	year = {2017},
	month = {10},
	date = {2017-10-01},
	journal = {Computational Psychiatry},
	pages = {24--57},
	volume = {1},
	doi = {10.1162/CPSY_a_00002},
	url = {https://doi.org/10.1162/CPSY_a_00002}
}

@article{ahn2014,
	title = {Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users},
	author = {Ahn, Woo-Young and Vasilev, Georgi and Lee, Sung-Ha and Busemeyer, Jerome R. and Kruschke, John K. and Bechara, Antoine and Vassileva, Jasmin},
	year = {2014},
	month = {08},
	date = {2014-08-12},
	journal = {Frontiers in Psychology},
	pages = {849},
	volume = {5},
	doi = {10.3389/fpsyg.2014.00849},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4129374/},
	note = {PMID: 25161631
PMCID: PMC4129374}
}

@article{gelman1992,
	title = {Inference from Iterative Simulation Using Multiple Sequences},
	author = {Gelman, Andrew and Rubin, Donald B.},
	year = {1992},
	month = {11},
	date = {1992-11},
	journal = {Statistical Science},
	pages = {457--472},
	volume = {7},
	number = {4},
	doi = {10.1214/ss/1177011136},
	url = {https://projecteuclid.org/journals/statistical-science/volume-7/issue-4/Inference-from-Iterative-Simulation-Using-Multiple-Sequences/10.1214/ss/1177011136.full},
	note = {Publisher: Institute of Mathematical Statistics}
}

@article{gronau2020,
	title = {bridgesampling: An R Package for Estimating Normalizing Constants},
	author = {Gronau, Quentin F. and Singmann, Henrik and Wagenmakers, Eric-Jan},
	year = {2020},
	month = {02},
	date = {2020-02-27},
	journal = {Journal of Statistical Software},
	pages = {1--29},
	volume = {92},
	doi = {10.18637/jss.v092.i10},
	url = {https://doi.org/10.18637/jss.v092.i10},
	langid = {en}
}

@article{vehtari2017,
	title = {Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	year = {2017},
	month = {09},
	date = {2017-09-01},
	journal = {Statistics and Computing},
	pages = {1413--1432},
	volume = {27},
	number = {5},
	doi = {10.1007/s11222-016-9696-4},
	url = {https://doi.org/10.1007/s11222-016-9696-4},
	langid = {en}
}

@article{plummer2008,
	title = {Penalized loss functions for Bayesian model comparison},
	author = {Plummer, Martyn},
	year = {2008},
	month = {07},
	date = {2008-07},
	journal = {Biostatistics},
	pages = {523--539},
	volume = {9},
	number = {3},
	doi = {10.1093/biostatistics/kxm049},
	url = {https://academic.oup.com/biostatistics/article-lookup/doi/10.1093/biostatistics/kxm049},
	langid = {en}
}


@article{sokol-hessner_psychological_2019,
	title = {The {Psychological} and {Neural} {Basis} of {Loss} {Aversion}},
	volume = {28},
	issn = {0963-7214},
	url = {https://doi.org/10.1177/0963721418806510},
	doi = {10.1177/0963721418806510},
	abstract = {Loss aversion is a central element of prospect theory, the dominant theory of decision making under uncertainty for the past four decades, and refers to the overweighting of potential losses relative to equivalent gains, a critical determinant of risky decision making. Recent advances in affective and decision neuroscience have shed new light on the psychological and neurobiological mechanisms underlying loss aversion. Here, integrating disparate literatures from the level of neurotransmitters to subjective reports of emotion, we propose a novel neural and computational framework that links norepinephrine to loss aversion and identifies a distinct role for dopamine in risk taking for rewards. We also propose that loss aversion specifically relates to anticipated emotions and aspects of the immediate experience of realized gains and losses but not their long-term emotional consequences, highlighting an underappreciated temporal structure. Finally, we discuss challenges to loss aversion and the relevance of loss aversion to understanding psychiatric disorders. Refining models of loss aversion will have broad consequences for the science of decision making and for how we understand individual variation in economic preferences and psychological well-being across both healthy and psychiatric populations.},
	language = {en},
	number = {1},
	urldate = {2022-04-03},
	journal = {Current Directions in Psychological Science},
	author = {Sokol-Hessner, Peter and Rutledge, Robb B.},
	month = feb,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	keywords = {decision making, emotion, loss aversion, prospect theory, well-being},
	pages = {20--27},
	file = {SAGE PDF Full Text:/Users/jt/Zotero/storage/6EYVS6PT/Sokol-Hessner and Rutledge - 2019 - The Psychological and Neural Basis of Loss Aversio.pdf:application/pdf},
}

@article{sokol-hessner_emotion_2013,
	title = {Emotion regulation reduces loss aversion and decreases amygdala responses to losses},
	volume = {8},
	issn = {1749-5024 (Electronic) 1749-5016 (Linking)},
	doi = {10.1093/scan/nss002},
	abstract = {Emotion regulation strategies can alter behavioral and physiological responses to emotional stimuli and the neural correlates of those responses in regions such as the amygdala or striatum. The current study investigates the brain systems engaged when using an emotion regulation technique during financial decisions. In decision making, regulating emotion with reappraisal-focused strategies that encourage taking a different perspective has been shown to reduce loss aversion as observed both in choices and in the relative arousal responses to actual loss and gain outcomes. In the current study, we find using fMRI that behavioral loss aversion correlates with amygdala activity in response to losses relative to gains. Success in regulating loss aversion also correlates with the reduction in amygdala responses to losses but not to gains. Furthermore, across both decisions and outcomes, we find the reappraisal strategy increases baseline activity in dorsolateral and ventromedial prefrontal cortex and the striatum. The similarity of the neural circuitry observed to that seen in emotion regulation, despite divergent tasks, serves as further evidence for a role of emotion in decision making, and for the power of reappraisal to change assessments of value and thereby choices.},
	number = {3},
	journal = {Soc Cogn Affect Neurosci},
	author = {Sokol-Hessner, P. and Camerer, C. F. and Phelps, E. A.},
	month = mar,
	year = {2013},
	pmcid = {PMC3594725},
	keywords = {Adolescent, Female, Humans, Male, Young Adult, Magnetic Resonance Imaging, Image Processing, Computer-Assisted, Statistics as Topic, *Decision Making, Oxygen/blood, Emotions/*physiology, *Brain Mapping, Amygdala/blood supply/*physiology, Neural Inhibition/*physiology},
	pages = {341--50},
	annote = {Sokol-Hessner, PeterCamerer, Colin FPhelps, Elizabeth AengR01 AG039283/AG/NIA NIH HHS/R01 MH080756/MH/NIMH NIH HHS/AG039283/AG/NIA NIH HHS/MH080756/MH/NIMH NIH HHS/Research Support, N.I.H., ExtramuralResearch Support, Non-U.S. Gov'tEnglandSoc Cogn Affect Neurosci. 2013 Mar;8(3):341-50. doi: 10.1093/scan/nss002. Epub 2012 Jan 24.},
	annote = {The following values have no corresponding Zotero field:auth-address: Department of Psychology, New York University, 6 Washington Place, New York, NY 10003, USA.edition: 2012/01/26accession-num: 22275168},
	file = {Sokol-Hessner et al. - 2013 - Emotion regulati:/Users/jt/Zotero/storage/WMY97REL/Sokol-Hessner et al. - 2013 - Emotion regulati.pdf:application/pdf},
}

@article{tom_neural_2007,
	title = {The {Neural} {Basis} of {Loss} {Aversion} in {Decision}-{Making} {Under} {Risk}},
	volume = {315},
	copyright = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/315/5811/515},
	doi = {10.1126/science.1134239},
	abstract = {Overlapping brain networks respond more to gambling losses than to gains, correlating with behavioral observations about risk aversion.
Overlapping brain networks respond more to gambling losses than to gains, correlating with behavioral observations about risk aversion.},
	language = {en},
	number = {5811},
	urldate = {2020-01-22},
	journal = {Science},
	author = {Tom, Sabrina M. and Fox, Craig R. and Trepel, Christopher and Poldrack, Russell A.},
	month = jan,
	year = {2007},
	pmid = {17255512},
	pages = {515--518},
	file = {Full Text PDF:/Users/jt/Zotero/storage/GBVG5A2A/Tom et al. - 2007 - The Neural Basis of Loss Aversion in Decision-Maki.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/QGMGTTZ7/tab-figures-data.html:text/html},
}


@article{montague_efficiency_2016,
	title = {An efficiency framework for valence processing systems inspired by soft cross-wiring},
	volume = {11},
	issn = {2352-1546},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5300026/},
	doi = {10.1016/j.cobeha.2016.08.002},
	abstract = {Serotonin has been proposed as an opponent to dopamine. This review explores positive and negative value pathways for structuring this opponency.The positive and negative pathways co-mingle through transmitter cross-loading. Cross-loading is proposed as a way to tile ‘'valence space'. Recent experiments suggest that subsecond dopamine delivery to human striatum encodes a combination of reward prediction errors and counterfactual errors thus composing the actual with the possible into one neurochemical signal. Here, we present a model where the counterfactual part of these striatal dopamine fluctuations originates in another valuation system that shadows the dopamine system by acting as its near-antipode in terms of spike-rate encoding yet co-releases dopamine alongside its own native neurotransmitter. We show that such a hypothesis engenders important representational consequences where valence processing appears subject to the efficient encoding considerations common to the visual and auditory systems. This new perspective opens up important computational consequences for understanding how value-predicting information should integrate with sensory processing streams.},
	urldate = {2019-02-09},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Montague, P Read and Kishida, Kenneth T and Moran, Rosalyn J and Lohrenz, Terry M},
	month = oct,
	year = {2016},
	pmid = {28191489},
	pmcid = {PMC5300026},
	pages = {121--129},
	file = {PubMed Central Full Text PDF:/Users/jt/Zotero/storage/LIT8TG36/Montague et al. - 2016 - An efficiency framework for valence processing sys.pdf:application/pdf},
}

@article{zhou_corelease_2005,
	title = {Corelease of {Dopamine} and {Serotonin} from {Striatal} {Dopamine} {Terminals}},
	volume = {46},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627305001261},
	doi = {10.1016/j.neuron.2005.02.010},
	abstract = {The striatum receives rich dopaminergic and more moderate serotonergic innervation. After vesicular release, dopamine and serotonin (5-hydroxytryptamine, 5-HT) signaling is controlled by transporter-mediated reuptake. Dopamine is taken up by dopamine transporters (DATs), which are expressed at the highest density in the striatum. Although DATs also display a low affinity for 5-HT, that neurotransmitter is normally efficiently taken up by the 5-HT transporters. We found that when extracellular 5-HT is elevated by exogenous application or by using antidepressants (e.g., fluoxetine) to inhibit the 5-HT transporters, the extremely dense striatal DATs uptake 5-HT into dopamine terminals. Immunohistochemical results and measurements using fast cyclic voltammetry showed that elevated 5-HT is taken up by DATs into striatal dopamine terminals that subsequently release 5-HT and dopamine together. These results suggest that antidepressants that block serotonin transporters or other factors that elevate extracellular 5-HT alter the temporal and spatial relationship between dopamine and 5-HT signaling in the striatum.},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {Neuron},
	author = {Zhou, Fu-Ming and Liang, Yong and Salas, Ramiro and Zhang, Lifen and De Biasi, Mariella and Dani, John A.},
	month = apr,
	year = {2005},
	pages = {65--74},
	file = {ScienceDirect Full Text PDF:/Users/jt/Zotero/storage/2R2DCRIK/Zhou et al. - 2005 - Corelease of Dopamine and Serotonin from Striatal .pdf:application/pdf;ScienceDirect Snapshot:/Users/jt/Zotero/storage/SXB89ZNY/S0896627305001261.html:text/html},
}


@incollection{kishida_dynamic_2021,
	address = {Cham},
	title = {A {Dynamic} {Affective} {Core} to {Bind} the {Contents}, {Context}, and {Value} of {Conscious} {Experience}},
	isbn = {978-3-030-82965-0},
	url = {https://doi.org/10.1007/978-3-030-82965-0_12},
	abstract = {The private and dynamic nature of conscious subjective experience poses an empirical challenge that has led neuroscience-based theories about consciousness to note the importance of ‘the hard problem’ of explaining how subjective phenomenal experience can arise from neural activity but set it aside and focus on the ‘easier’ problems associated with information representation and behavior. This approach leaves a major gap in our understanding of the neural mechanisms underlying conscious subjective experience and its dynamic nature. However, computational methods integrated with a variety of tools for measuring human brain activity are beginning to link dynamic changes in subjective affect with reproducible neurobehavioral signals in humans. In particular, research applying computational reinforcement learning theory has shown tremendous utility in investigating human choice behavior and the role the dopaminergic system plays in dynamic behavioral control. This research is beginning to reveal an explicit connection between the dynamics of dopaminergic signals and dynamic changes in subjective affect. However, it should be obvious that the dopaminergic system alone is not sufficient to explain all of the complexities of affective dynamics. We review foundational work, highlight current problems and open questions, and propose a Dynamic Affective Core Hypothesis that integrates advances in our understanding of the representation of the content and context of conscious experiences with our nascent understanding about how these representations acquire and retain affective subjective value.},
	language = {en},
	urldate = {2021-12-06},
	booktitle = {Affect {Dynamics}},
	publisher = {Springer International Publishing},
	author = {Kishida, Kenneth T. and Sands, L. Paul},
	editor = {Waugh, Christian E. and Kuppens, Peter},
	year = {2021},
	doi = {10.1007/978-3-030-82965-0_12},
	keywords = {Dopamine, Reinforcement learning, Serotonin, Norepinephrine, Consciousness, Qualia, Reward prediction error, Subjective experience},
	pages = {293--328},
	file = {Submitted Version:/Users/jt/Zotero/storage/QRUKNUD4/Kishida and Sands - 2021 - A Dynamic Affective Core to Bind the Contents, Con.pdf:application/pdf},
}

@article{christopoulos_neural_2009,
	title = {Neural {Correlates} of {Value}, {Risk}, and {Risk} {Aversion} {Contributing} to {Decision} {Making} under {Risk}},
	volume = {29},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2794196/},
	doi = {10.1523/JNEUROSCI.2614-09.2009},
	abstract = {Decision making under risk is central to human behavior. Economic decision theory suggests that value, risk, and risk aversion influence choice behavior. Although previous studies identified neural correlates of decision parameters, the contribution of these correlates to actual choices is unknown. In two different experiments, participants chose between risky and safe options. We identified discrete blood oxygen level-dependent (BOLD) correlates of value and risk in the ventral striatum and anterior cingulate, respectively. Notably, increasing inferior frontal gyrus activity to low risk and safe options correlated with higher risk aversion. Importantly, the combination of these BOLD responses effectively decoded the behavioral choice. Striatal value and cingulate risk responses increased the probability of a risky choice, whereas inferior frontal gyrus responses showed the inverse relationship. These findings suggest that the BOLD correlates of decision factors are appropriate for an ideal observer to detect behavioral choices. More generally, these biological data contribute to the validity of the theoretical decision parameters for actual decisions under risk.},
	number = {40},
	urldate = {2022-04-03},
	journal = {The Journal of Neuroscience},
	author = {Christopoulos, George I. and Tobler, Philippe N. and Bossaerts, Peter and Dolan, Raymond J. and Schultz, Wolfram},
	month = oct,
	year = {2009},
	pmid = {19812332},
	pmcid = {PMC2794196},
	pages = {12574--12583},
	file = {Full Text:/Users/jt/Zotero/storage/F339T2SW/Christopoulos et al. - 2009 - Neural Correlates of Value, Risk, and Risk Aversio.pdf:application/pdf},
}


@article{niv_neural_2012,
	title = {Neural {Prediction} {Errors} {Reveal} a {Risk}-{Sensitive} {Reinforcement}-{Learning} {Process} in the {Human} {Brain}},
	volume = {32},
	copyright = {Copyright © 2012 the authors 0270-6474/12/320551-12\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/32/2/551},
	doi = {10.1523/JNEUROSCI.5498-10.2012},
	abstract = {Humans and animals are exquisitely, though idiosyncratically, sensitive to risk or variance in the outcomes of their actions. Economic, psychological, and neural aspects of this are well studied when information about risk is provided explicitly. However, we must normally learn about outcomes from experience, through trial and error. Traditional models of such reinforcement learning focus on learning about the mean reward value of cues and ignore higher order moments such as variance. We used fMRI to test whether the neural correlates of human reinforcement learning are sensitive to experienced risk. Our analysis focused on anatomically delineated regions of a priori interest in the nucleus accumbens, where blood oxygenation level-dependent (BOLD) signals have been suggested as correlating with quantities derived from reinforcement learning. We first provide unbiased evidence that the raw BOLD signal in these regions corresponds closely to a reward prediction error. We then derive from this signal the learned values of cues that predict rewards of equal mean but different variance and show that these values are indeed modulated by experienced risk. Moreover, a close neurometric–psychometric coupling exists between the fluctuations of the experience-based evaluations of risky options that we measured neurally and the fluctuations in behavioral risk aversion. This suggests that risk sensitivity is integral to human learning, illuminating economic models of choice, neuroscientific models of affective learning, and the workings of the underlying neural mechanisms.},
	language = {en},
	number = {2},
	urldate = {2022-04-03},
	journal = {Journal of Neuroscience},
	author = {Niv, Yael and Edlund, Jeffrey A. and Dayan, Peter and O'Doherty, John P.},
	month = jan,
	year = {2012},
	pmid = {22238090},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	pages = {551--562},
	file = {Full Text PDF:/Users/jt/Zotero/storage/BJ7CGPYK/Niv et al. - 2012 - Neural Prediction Errors Reveal a Risk-Sensitive R.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/6NZZS5WC/551.html:text/html},
}


@article{matthew_rabin_anomalies_2001,
	title = {Anomalies: {Risk} {Aversion}},
	volume = {15},
	language = {en},
	number = {1},
	journal = {Journal of Economic Perspectives},
	author = {{Matthew Rabin} and {Richard H. Thaler}},
	year = {2001},
	pages = {219--232},
	file = {Anomalies Risk Aversion.pdf:/Users/jt/Zotero/storage/9BDSX79Y/Anomalies Risk Aversion.pdf:application/pdf},
}

@article{shoda_predicting_1990,
	title = {Predicting adolescent cognitive and self-regulatory competencies from preschool delay of gratification: {Identifying} diagnostic conditions},
	volume = {26},
	issn = {1939-0599},
	shorttitle = {Predicting adolescent cognitive and self-regulatory competencies from preschool delay of gratification},
	doi = {10.1037/0012-1649.26.6.978},
	abstract = {Variations of the self-imposed delay-of-gratification situation in preschool were compared to determine when individual differences in this situation may predict aspects of cognitive and self-regulatory competence and coping in adolescence. Preschool children from a university community participated in experiments that varied features of the self-imposed delay situation. Experimental analyses of the cognitive–attentional processes that affect waiting in this situation helped identify conditions in which delay behavior would be most likely to reflect relevant cognitive and attentional competencies. As hypothesized, in those conditions, coherent patterns of statistically significant correlations were found between seconds of delay time in such conditions in preschool and cognitive and academic competence and ability to cope with frustration and stress in adolescence. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Developmental Psychology},
	author = {Shoda, Yuichi and Mischel, Walter and Peake, Philip K.},
	year = {1990},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Cognitive Ability, Competence, Coping Behavior, Delay of Gratification, Early Experience, Longitudinal Studies, Self-Control},
	pages = {978--986},
	file = {Full Text:/Users/jt/Zotero/storage/YCYWRCJQ/Shoda et al. - 1990 - Predicting adolescent cognitive and self-regulator.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/QASEHFDJ/1991-06927-001.html:text/html},
}

@article{watts_revisiting_2018,
	title = {Revisiting the {Marshmallow} {Test}: {A} {Conceptual} {Replication} {Investigating} {Links} {Between} {Early} {Delay} of {Gratification} and {Later} {Outcomes}},
	volume = {29},
	issn = {0956-7976},
	shorttitle = {Revisiting the {Marshmallow} {Test}},
	url = {https://doi.org/10.1177/0956797618761661},
	doi = {10.1177/0956797618761661},
	abstract = {We replicated and extended Shoda, Mischel, and Peake’s (1990) famous marshmallow study, which showed strong bivariate correlations between a child’s ability to delay gratification just before entering school and both adolescent achievement and socioemotional behaviors. Concentrating on children whose mothers had not completed college, we found that an additional minute waited at age 4 predicted a gain of approximately one tenth of a standard deviation in achievement at age 15. But this bivariate correlation was only half the size of those reported in the original studies and was reduced by two thirds in the presence of controls for family background, early cognitive ability, and the home environment. Most of the variation in adolescent achievement came from being able to wait at least 20 s. Associations between delay time and measures of behavioral outcomes at age 15 were much smaller and rarely statistically significant.},
	language = {en},
	number = {7},
	urldate = {2022-04-03},
	journal = {Psychological Science},
	author = {Watts, Tyler W. and Duncan, Greg J. and Quan, Haonan},
	month = jul,
	year = {2018},
	note = {Publisher: SAGE Publications Inc},
	keywords = {achievement, behavioral problems, early childhood, gratification delay, longitudinal analysis, marshmallow test, open data},
	pages = {1159--1177},
	file = {Full Text:/Users/jt/Zotero/storage/SNWMUVFC/Watts et al. - 2018 - Revisiting the Marshmallow Test A Conceptual Repl.pdf:application/pdf},
}


@article{w_mischel_attention_1970,
	title = {Attention in delay of gratification},
	url = {https://content.apa.org/doiLanding?doi=10.1037%2Fh0029815},
	abstract = {Explored the role of attentional processes in voluntary delay of reward by manipulating children's attention to the rewards for which they were waiting in a delay-of-gratification paradigm. 32 preschool children waited for a preferred but delayed reward while facing either the delayed reward, a less preferred but immediately available reward, both rewards, or no rewards. The dependent measure was the amount of time they waited for the preferred outcome before forfeiting it for the sake of the less desired but immediately available one. Results contradict predictions from psychodynamic theory and from speculations concerning self-instructions during time binding. Unexpectedly, but in accord with frustrative nonreward theory, voluntary waiting time was substantially increased when Ss could not attend to rewards during the waiting period. Implications are discussed for a theory of the development of delay of gratification.},
	language = {en},
	urldate = {2022-04-03},
	journal = {Journal of Personality and Social Psychology},
	author = {{W. Mischel} and {E. B. Ebbesen}},
	year = {1970},
	file = {Snapshot:/Users/jt/Zotero/storage/UJSQRMNI/doiLanding.html:text/html},
}


@article{van_de_schoot_bayesian_2021,
	title = {Bayesian statistics and modelling},
	volume = {1},
	copyright = {2021 Springer Nature Limited},
	issn = {2662-8449},
	url = {https://www.nature.com/articles/s43586-020-00001-2},
	doi = {10.1038/s43586-020-00001-2},
	abstract = {Bayesian statistics is an approach to data analysis based on Bayes’ theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events. This Primer describes the stages involved in Bayesian analysis, from specifying the prior and data models to deriving inference, model checking and refinement. We discuss the importance of prior and posterior predictive checking, selecting a proper technique for sampling from a posterior distribution, variational inference and variable selection. Examples of successful applications of Bayesian analysis across various research fields are provided, including in social sciences, ecology, genetics, medicine and more. We propose strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist. Finally, we outline the impact of Bayesian analysis on artificial intelligence, a major goal in the next decade.},
	language = {en},
	number = {1},
	urldate = {2022-04-01},
	journal = {Nature Reviews Methods Primers},
	author = {van de Schoot, Rens and Depaoli, Sarah and King, Ruth and Kramer, Bianca and Märtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
	month = jan,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Scientific community, Statistics},
	pages = {1--26},
	file = {Snapshot:/Users/jt/Zotero/storage/AIHA8HPJ/s43586-020-00001-2.html:text/html;Submitted Version:/Users/jt/Zotero/storage/BBSZH3Z5/van de Schoot et al. - 2021 - Bayesian statistics and modelling.pdf:application/pdf;van de Schoot et al. - 2021 - Bayesian statistics and modelling.pdf:/Users/jt/Zotero/storage/EZF6VTHV/van de Schoot et al. - 2021 - Bayesian statistics and modelling.pdf:application/pdf},
}


@article{agranov_stochastic_2017,
	title = {Stochastic {Choice} and {Preferences} for {Randomization}},
	volume = {125},
	issn = {0022-3808},
	url = {https://www.journals.uchicago.edu/doi/10.1086/689774},
	doi = {10.1086/689774},
	abstract = {We conduct an experiment in which subjects face the same questions repeated multiple times, with repetitions of two types: (1) following the literature, the repetitions are distant from each other; (2) in a novel treatment, the repetitions are in a row, and subjects are told that the questions will be repeated. We find that a large majority of subjects exhibit stochastic choice in both cases. We discuss the implications for models of stochastic choice.},
	number = {1},
	urldate = {2022-05-01},
	journal = {Journal of Political Economy},
	author = {Agranov, Marina and Ortoleva, Pietro},
	month = feb,
	year = {2017},
	note = {Publisher: The University of Chicago Press},
	pages = {40--68},
	file = {Full Text PDF:/Users/jt/Zotero/storage/Z7DVY8TC/Agranov and Ortoleva - 2017 - Stochastic Choice and Preferences for Randomizatio.pdf:application/pdf},
}

@article{tversky_intransitivity_1969,
	title = {Intransitivity of preferences.},
	volume = {76},
	issn = {0033-295X},
	url = {http://content.apa.org/journals/rev/76/1/31},
	doi = {10.1037/h0026750},
	language = {en},
	number = {1},
	urldate = {2022-05-01},
	journal = {Psychological Review},
	author = {Tversky, Amos},
	year = {1969},
	pages = {31--48},
	file = {Tversky - 1969 - Intransitivity of preferences..pdf:/Users/jt/Zotero/storage/HZZ3E696/Tversky - 1969 - Intransitivity of preferences..pdf:application/pdf},
}


@article{box_science_1976,
	title = {Science and {Statistics}},
	volume = {71},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2286841},
	doi = {10.2307/2286841},
	abstract = {Aspects of scientific method are discussed: In particular, its representation as a motivated iteration in which, in succession, practice confronts theory, and theory, practice. Rapid progress requires sufficient flexibility to profit from such confrontations, and the ability to devise parsimonious but effective models, to worry selectively about model inadequacies and to employ mathematics skillfully but appropriately. The development of statistical methods at Rothamsted Experimental Station by Sir Ronald Fisher is used to illustrate these themes.},
	number = {356},
	urldate = {2022-05-02},
	journal = {Journal of the American Statistical Association},
	author = {Box, George E. P.},
	year = {1976},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {791--799},
	file = {Boxonmaths 2.pdf:/Users/jt/Zotero/storage/HGAW4YFP/Boxonmaths 2.pdf:application/pdf},
}


@incollection{fox_prospect_2009,
	address = {San Diego, CA, US},
	title = {Prospect theory and the brain},
	isbn = {978-0-12-374176-9},
	abstract = {In this chapter, we explore behavioral and neuroeconomic perspectives on decisions under risk. For simplicity we will confine most of our attention to how people evaluate simple prospects with a single non-zero outcome that occurs with known probability (e.g., a 50-50 chance of winning \$100 or nothing), though we will also mention extensions to multiple outcomes and to vague or unknown probabilities. In the remainder of this section we provide a brief overview of economic models of decision making under risk, culminating in prospect theory (Kahneman and Tversky, 1979; Tversky and Kahneman, 1992), the most influential descriptive account that has emerged to date. In subsequent sections, we provide an overview of various parameterizations of prospect theory's functions, and review methods for eliciting them. We then take stock of the early neuroeconomic studies of prospect theory, before providing some suggested directions for future research. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	booktitle = {Neuroeconomics: {Decision} making and the brain},
	publisher = {Elsevier Academic Press},
	author = {Fox, Craig R. and Poldrack, Russell A.},
	year = {2009},
	doi = {10.1016/B978-0-12-374176-9.00011-7},
	keywords = {Brain, Decision Making, Economics, Neuropsychology, Risk Perception, Theories},
	pages = {145--173},
	file = {Snapshot:/Users/jt/Zotero/storage/3HKRGF5F/2010-01173-011.html:text/html},
}

@article{lohrenz_neural_2007,
	title = {Neural signature of fictive learning signals in a sequential investment task},
	volume = {104},
	copyright = {© 2007 by The National Academy of Sciences of the USA.                    Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/104/22/9493},
	doi = {10.1073/pnas.0608842104},
	abstract = {Reinforcement learning models now provide principled guides for a wide range of reward learning experiments in animals and humans. One key learning (error) signal in these models is experiential and reports ongoing temporal differences between expected and experienced reward. However, these same abstract learning models also accommodate the existence of another class of learning signal that takes the form of a fictive error encoding ongoing differences between experienced returns and returns that “could-have-been-experienced” if decisions had been different. These observations suggest the hypothesis that, for all real-world learning tasks, one should expect the presence of both experiential and fictive learning signals. Motivated by this possibility, we used a sequential investment game and fMRI to probe ongoing brain responses to both experiential and fictive learning signals generated throughout the game. Using a large cohort of subjects (n = 54), we report that fictive learning signals strongly predict changes in subjects' investment behavior and correlate with fMRI signals measured in dopaminoceptive structures known to be involved in valuation and choice.},
	language = {en},
	number = {22},
	urldate = {2019-12-01},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Lohrenz, Terry and McCabe, Kevin and Camerer, Colin F. and Montague, P. Read},
	month = may,
	year = {2007},
	pmid = {17519340},
	keywords = {neuroeconomics, decision-making, counterfactual signals, reinforcement learning},
	pages = {9493--9498},
	file = {Full Text PDF:/Users/jt/Zotero/storage/RIRFYJGT/Lohrenz et al. - 2007 - Neural signature of fictive learning signals in a .pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/IR9PE6QE/9493.html:text/html},
}

@article{rick_losses_2011,
	title = {Losses, gains, and brains: {Neuroeconomics} can help to answer open questions about loss aversion},
	volume = {21},
	issn = {1057-7408},
	doi = {10.1016/j.jcps.2010.04.004},
	number = {4},
	journal = {Journal of Consumer Psychology},
	author = {Rick, Scott},
	year = {2011},
	pages = {453--463},
	annote = {The following values have no corresponding Zotero field:publisher: Wiley},
	file = {Rick-2011-Losses-gains-and-brains-neuroeconom:/Users/jt/Zotero/storage/VB6GACZ7/Rick-2011-Losses-gains-and-brains-neuroeconom.pdf:application/pdf},
}


@article{hsu_neural_2009,
	title = {Neural {Response} to {Reward} {Anticipation} under {Risk} {Is} {Nonlinear} in {Probabilities}},
	volume = {29},
	copyright = {Copyright © 2009 Society for Neuroscience 0270-6474/09/292231-07\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/29/7/2231},
	doi = {10.1523/JNEUROSCI.5296-08.2009},
	abstract = {A widely observed phenomenon in decision making under risk is the apparent overweighting of unlikely events and the underweighting of nearly certain events. This violates standard assumptions in expected utility theory, which requires that expected utility be linear (objective) in probabilities. Models such as prospect theory have relaxed this assumption and introduced the notion of a “probability weighting function,” which captures the key properties found in experimental data. This study reports functional magnetic resonance imaging (fMRI) data that neural response to expected reward is nonlinear in probabilities. Specifically, we found that activity in the striatum during valuation of monetary gambles are nonlinear in probabilities in the pattern predicted by prospect theory, suggesting that probability distortion is reflected at the level of the reward encoding process. The degree of nonlinearity reflected in individual subjects' decisions is also correlated with striatal activity across subjects. Our results shed light on the neural mechanisms of reward processing, and have implications for future neuroscientific studies of decision making involving extreme tails of the distribution, where probability weighting provides an explanation for commonly observed behavioral anomalies.},
	language = {en},
	number = {7},
	urldate = {2019-09-06},
	journal = {Journal of Neuroscience},
	author = {Hsu, Ming and Krajbich, Ian and Zhao, Chen and Camerer, Colin F.},
	month = feb,
	year = {2009},
	pmid = {19228976},
	keywords = {fMRI, decision making, expected utility theory, probability weighting, prospect theory, reward},
	pages = {2231--2237},
	file = {Full Text PDF:/Users/jt/Zotero/storage/W8JQU3U3/Hsu et al. - 2009 - Neural Response to Reward Anticipation under Risk .pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/79TXVKDA/2231.html:text/html},
}


@article{coricelli_brain_2007,
	title = {Brain, emotion and decision making: the paradigmatic example of regret},
	volume = {11},
	issn = {13646613},
	shorttitle = {Brain, emotion and decision making},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661307000861},
	doi = {10.1016/j.tics.2007.04.003},
	language = {en},
	number = {6},
	urldate = {2022-05-03},
	journal = {Trends in Cognitive Sciences},
	author = {Coricelli, Giorgio and Dolan, Raymond J. and Sirigu, Angela},
	month = jun,
	year = {2007},
	pages = {258--265},
	file = {Coricelli et al. - 2007 - Brain, emotion and decision making the paradigmat.pdf:/Users/jt/Zotero/storage/FEAAC4F7/Coricelli et al. - 2007 - Brain, emotion and decision making the paradigmat.pdf:application/pdf},
}

@article{hintze_risk_2015,
	title = {Risk sensitivity as an evolutionary adaptation},
	volume = {5},
	copyright = {2015 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep08242},
	doi = {10.1038/srep08242},
	abstract = {Risk aversion is a common behavior universal to humans and animals alike. Economists have traditionally defined risk preferences by the curvature of the utility function. Psychologists and behavioral economists also make use of concepts such as loss aversion and probability weighting to model risk aversion. Neurophysiological evidence suggests that loss aversion has its origins in relatively ancient neural circuitries (e.g., ventral striatum). Could there thus be an evolutionary origin to risk aversion? We study this question by evolving strategies that adapt to play the equivalent mean payoff gamble. We hypothesize that risk aversion in this gamble is beneficial as an adaptation to living in small groups and find that a preference for risk averse strategies only evolves in small populations of less than 1,000 individuals, or in populations segmented into groups of 150 individuals or fewer – numbers thought to be comparable to what humans encountered in the past. We observe that risk aversion only evolves when the gamble is a rare event that has a large impact on the individual's fitness. As such, we suggest that rare, high-risk, high-payoff events such as mating and mate competition could have driven the evolution of risk averse behavior in humans living in small groups.},
	language = {en},
	number = {1},
	urldate = {2022-05-03},
	journal = {Scientific Reports},
	author = {Hintze, Arend and Olson, Randal S. and Adami, Christoph and Hertwig, Ralph},
	month = feb,
	year = {2015},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Biological anthropology, Human behaviour},
	pages = {8242},
	file = {Full Text PDF:/Users/jt/Zotero/storage/Y6HDND8J/Hintze et al. - 2015 - Risk sensitivity as an evolutionary adaptation.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/6GITQEF7/srep08242.html:text/html},
}


@article{kurnianingsih_neural_2016,
	title = {Neural {Mechanisms} of the {Transformation} from {Objective} {Value} to {Subjective} {Utility}: {Converting} from {Count} to {Worth}},
	volume = {10},
	issn = {1662-453X},
	shorttitle = {Neural {Mechanisms} of the {Transformation} from {Objective} {Value} to {Subjective} {Utility}},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2016.00507},
	abstract = {When deciding, we aim to choose the “best” possible outcome. This is not just selection of the option that is the most numerous or physically largest, as options are translated from objective value (count) to subjective value (worth or utility). We localized the neural instantiation of the value-to-utility transformation to the dorsal anterior midcingulate cortex (daMCC), with independent replication. The daMCC encodes the context-specific information necessary to convert from count to worth. This encoding is not simply a representation of utility or preference, but the interaction of the two. Specifically, the relationship of brain activation to value is dependent on individual preference, with both positive and negative slopes across the population depending on whether each individual's preference results in enhancement or diminishment of the valuation. For a given value, across participants, enhanced daMCC activation corresponds to diminished subjective valuation, deactivation to enhanced subjective valuation, and non-modulated activation with non-modulated subjective valuation. Further, functional connectivity analyses identified brain regions (positive connectivity with the inferior frontal gyrus and negative connectivity with the nucleus accumbens) through which contextual information may be integrated into the daMCC and allow for outputs to modulate valuation signals. All analyses were replicated through an independent within-study replication, with initial testing in the gains domain and replication in the intermixed and mirrored losses trials. We also present and discuss an ancillary finding: we were unable to identify parametric value signals for losses through whole-brain analyses, and ROI analyses of the vmPFC presented non-modulation across loss value levels. These results identify the neural locus of the value-to-utility transformation, and provide a specific computational function for the daMCC in the production of subjective valuation through the integration of value, context, and preferences.},
	urldate = {2022-05-03},
	journal = {Frontiers in Neuroscience},
	author = {Kurnianingsih, Yoanna A. and Mullette-Gillman, O'Dhaniel A.},
	year = {2016},
	file = {Full Text PDF:/Users/jt/Zotero/storage/EDVPRZZM/Kurnianingsih and Mullette-Gillman - 2016 - Neural Mechanisms of the Transformation from Objec.pdf:application/pdf},
}


@article{nachev_dynamic_2015,
	title = {Dynamic risk control by human nucleus accumbens},
	volume = {138},
	issn = {0006-8950},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4655342/},
	doi = {10.1093/brain/awv285},
	abstract = {The nucleus accumbens is a key node in the network linking reward to action. Studying a rare series of patients with bilaterally implanted electrodes in the nucleus accumbens, Nachev et al. show that external electrical stimulation of the accumbens dynamically shifts behaviour towards more risky decision making.,
The nucleus accumbens is a key node in the network linking reward to action. Studying a rare series of patients with bilaterally implanted electrodes in the nucleus accumbens, Nachev et al. show that external electrical stimulation of the accumbens dynamically shifts behaviour towards more risky decision making.
, Real-world decisions about reward often involve a complex counterbalance of risk and value. Although the nucleus accumbens has been implicated in the underlying neural substrate, its criticality to human behaviour remains an open question, best addressed with interventional methodology that probes the behavioural consequences of focal neural modulation. Combining a psychometric index of risky decision-making with transient electrical modulation of the nucleus accumbens, here we reveal profound, highly dynamic alteration of the relation between probability of reward and choice during therapeutic deep brain stimulation in four patients with treatment-resistant psychiatric disease. Short-lived phasic electrical stimulation of the region of the nucleus accumbens dynamically altered risk behaviour, transiently shifting the psychometric function towards more risky decisions only for the duration of stimulation. A critical, on-line role of human nucleus accumbens in dynamic risk control is thereby established.},
	number = {12},
	urldate = {2022-05-03},
	journal = {Brain},
	author = {Nachev, Parashkev and Lopez-Sosa, Fernando and Gonzalez-Rosa, Javier Jesus and Galarza, Ana and Avecillas, Josue and Pineda-Pardo, Jose Angel and Lopez-Ibor, Juan José and Reneses, Blanca and Barcia, Juan Antonio and Strange, Bryan},
	month = dec,
	year = {2015},
	pmid = {26428667},
	pmcid = {PMC4655342},
	pages = {3496--3502},
	file = {Full Text:/Users/jt/Zotero/storage/KMWQYX9Z/Nachev et al. - 2015 - Dynamic risk control by human nucleus accumbens.pdf:application/pdf},
}


@article{thaler_homo_2000,
	title = {From {Homo} {Economicus} to {Homo} {Sapiens}},
	volume = {14},
	issn = {0895-3309},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.14.1.133},
	doi = {10.1257/jep.14.1.133},
	abstract = {In responding to a request for predictions about the future of economics, I predict that Homo Economicus will evolve into Homo Sapiens, or, more simply put, economics will become more related to human behavior. My specific predictions are that Homo Economicus will start to lose IQ, will become a slower learner, will start interacting with other species, and that economists will start to study human cognition, human emotion, and will distinguish more clearly between normative and descriptive theories.},
	language = {en},
	number = {1},
	urldate = {2022-05-03},
	journal = {Journal of Economic Perspectives},
	author = {Thaler, Richard H.},
	month = mar,
	year = {2000},
	keywords = {Role of Economics, Role of Economists},
	pages = {133--141},
	file = {Full Text PDF:/Users/jt/Zotero/storage/4W2YBGBG/Thaler - 2000 - From Homo Economicus to Homo Sapiens.pdf:application/pdf;Snapshot:/Users/jt/Zotero/storage/RRQCXGQW/articles.html:text/html},
}


@article{weiss_impulse_2012,
	title = {Impulse control disorders and compulsive behaviors associated with dopaminergic therapies in {Parkinson} disease},
	volume = {2},
	issn = {2163-0402},
	doi = {10.1212/CPJ.0b013e318278be9b},
	abstract = {Impulse control disorders (ICD) (most commonly pathologic gambling, hypersexuality, and uncontrollable spending) and compulsive behaviors can be triggered by dopaminergic therapies in Parkinson disease (PD). ICD are especially prevalent in patients receiving a dopamine agonist as part of their treatment regimen for PD, and have also been reported when dopamine agonists are used for other indications (e.g., restless legs syndrome). Although these iatrogenic disorders are common, affecting 1 in 7 patients with PD on dopamine agonists, they often elude detection by the treating physician. ICD lead to serious consequences, causing significant financial loss and psychosocial morbidity for many patients and families. ICD can appear at any time during treatment with dopamine agonists, sometimes within the first few months, but most often after years of treatment, particularly when patients receive dopamine agonists and levodopa together. In most cases ICD resolve if the dopamine agonist is withdrawn, and PD motor symptoms are managed with levodopa monotherapy. Familiarity with the clinical aspects, risk factors, pathophysiology, and management of ICD is essential for physicians using dopaminergic therapies to treat PD and other disorders.},
	language = {eng},
	number = {4},
	journal = {Neurology. Clinical Practice},
	author = {Weiss, Howard D. and Marsh, Laura},
	month = dec,
	year = {2012},
	pmid = {23634371},
	pmcid = {PMC3613210},
	pages = {267--274},
	file = {Full Text:/Users/jt/Zotero/storage/7KYZ8RFZ/Weiss and Marsh - 2012 - Impulse control disorders and compulsive behaviors.pdf:application/pdf},
}


@article{lerner_emotion_2015,
	title = {Emotion and {Decision} {Making}},
	volume = {66},
	url = {https://doi.org/10.1146/annurev-psych-010213-115043},
	doi = {10.1146/annurev-psych-010213-115043},
	abstract = {A revolution in the science of emotion has emerged in recent decades, with the potential to create a paradigm shift in decision theories. The research reveals that emotions constitute potent, pervasive, predictable, sometimes harmful and sometimes beneficial drivers of decision making. Across different domains, important regularities appear in the mechanisms through which emotions influence judgments and choices. We organize and analyze what has been learned from the past 35 years of work on emotion and decision making. In so doing, we propose the emotion-imbued choice model, which accounts for inputs from traditional rational choice theory and from newer emotion research, synthesizing scientific models.},
	number = {1},
	urldate = {2022-01-14},
	journal = {Annual Review of Psychology},
	author = {Lerner, Jennifer S. and Li, Ye and Valdesolo, Piercarlo and Kassam, Karim S.},
	year = {2015},
	pmid = {25251484},
	note = {\_eprint: https://doi.org/10.1146/annurev-psych-010213-115043},
	pages = {799--823},
	file = {Full Text PDF:/Users/jt/Zotero/storage/GLNISTEK/Lerner et al. - 2015 - Emotion and Decision Making.pdf:application/pdf},
}
