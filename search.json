[{"path":"index.html","id":"hello-world","chapter":"Hello, World","heading":"Hello, World","text":"name Jonathan Trattner. May 2022, graduate Master’s Science Degree Neuroscience Wake Forest School Medicine. website embodiment master’s thesis.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"make choices every day. eat, whether take one route work, go sleep, just examples. Every decision associated consequences. Consequences inherently rewarding (appetitive), punishing (aversive), . understand processes involved human decision-making, use quantitative frameworks study choice behavior. analytic approaches primarily formalized three disciplines: economics, psychology, neuroscience.experimental literature, two types decision contexts described. “decisions risk,” decision-maker knows precision probability distribution possible outcomes. “decisions uncertainty,” decision-maker must infer probabilities potential outcomes. thesis, combine insights economics, psychology, neuroscience propose neurobiologically-plausible theory decision-making risk.first chapter, introduce notation used throughout thesis. outline evolution decision-theory classical economic models behavioral economic ones. second chapter, describe influences behavioral economic theories neuroscience research. cover relation (neuro)biology behavior. third chapter, propose new theory decision-making risk called ‘Counterfactual Predicted Utility Theory’ builds upon foundational work chapters one two. fourth chapter, assess predictive accuracy Counterfactual Predicted Utility Theory human choice data sure-bet gamble task. chapter five, conclude thesis discussions next steps.","code":""},{"path":"evolution-of-decision-theory.html","id":"evolution-of-decision-theory","chapter":"2 Evolution of Decision Theory","heading":"2 Evolution of Decision Theory","text":"Imagine casino. asked play new type roulette. time , cost participating. rules simple: pick red option black option. choose red option, dealer give three-thousand dollars. pick black option, dealer spin wheel release ball. wheel weighted 80% chance getting four-thousand dollars 20% chance getting zero dollars. option choose? ?economic theorist, bet choose black option higher expected value. Expected values, \\(EV\\), calculated multiplying magnitude, \\(x\\), outcome probability, \\(p\\), occur. example, red option leads three-thousand dollars certainty. black option leads four-thousand dollars 80% chance (probability 0.8).Looking expected values option calculated (2.1), see \\(\\text{EV}(\\text{Red}) > \\text{EV(Black)}\\). Therefore, rational choice according classical economist black option.new type roulette presented prototypical example prospect – choice two options explicit probabilities outcomes – used investigate decision-making risk. normative measure monetary reinforcements allows decision-researchers probe mechanisms underlying choice behavior. participants similar reference point, choosing option higher expected monetary payout straightforward (least mathematically speaking). However, decision accept risky gamble like may change ask someone annual income one-million dollars compared someone income fifty-thousand dollars.introduces idea diminishing marginal returns. value millionaire places certain three-thousand dollars (option 1 ) may enough dissuade probable four-thousand dollars. person, assured three-thousand dollars, though, much valuable gamble. idea formalized term ‘utility,’ coined Swiss mathematician Daniel Bernoulli. Utiity refers subjective “moral value” decision’s outcome. Bernoulli wrote: (Daniel Bernoulli 1954)price item dependent thing equal everyone; utility, however, dependent particular circumstances person making estimate.Bernoulli’s concept formed basis von Neumman Morgenstern’s Expected Utility Theory (EUT). (Neumann Morgenstern, O. 1947) EUT suggest people – – choose manner maximizes expected utility. EUT axiomatized, validity called question. Notably, Allais paradox suggests rationality defined maximizing expected utility neglects specific element psychology risk: variance individuals’ psychological values.(Allais 1953)1979, Daniel Kahneman Amos Tversky published Prospect Theory: Analysis Decision Risk.(Kahneman Tversky 1979) Prospect theory critiqued descriptive validity EUT. Kahneman Tversky highlighted systematic ways people violated EUT. , instantiated field behavioral economics – wedding insights psychology quantitative models economics – better understand human choice behavior.Kahneman Tversky describe multiple deviations EUT. Notably, discuss certainty reflection effects. certainty effect describes people overweight outcomes considered certain relative probable ones. reflection effect – commonly known ‘loss aversion’ – accounts peoples tendency risk averse positive prospects risk seeking negative ones. addition effects, one key takeaway prospect theory value function corresponds changes wealth welfare, rather final states. value function, concave gains convex losses, losses steeper gains (goes hand--hand reflection effect).application behavioral insights theories human decision-making necessitate emotional component. discussed Graham Loomes Robert Sugden 1982 paper, Regret Theory: Alternative Rational Choice Uncertainty, anticipatory feelings regret used inform decisions. (Loomes Sugden 1982)1 Loomes Sugden’s describe idea choosing one option preference cost forgoing opportunities.2 theory introduces concept counterfactual thinking, explicit comparison present state world alternative states.(Neal J. Roese 1997; Liu et al. 2016)revisit casino example, feel chose black option (gambling four-thousand dollars) lost? chosen red option three-thousand dollars certain, forewent opportunity chance something . comparison “” vs. “might ” captures idea counterfactual information.chapter, recounted high-level overview choice theory. example prospect, described expected values calculated importance subjective measures (utility) studying choice behavior. introduced EUT classical economist’s theory decision-making risk. Next, covered origin behavioral economics Kahneman Tversky’s prospect theory improve descriptive models choice behavior. concluded chapter covering regret theory necessity accounting subjective emotions choice models. next chapter, outline recent work looking neurobiological basis decision-making show evidence specific neural systems track counterfactual signals.","code":""},{"path":"neurobiology-of-decision-making.html","id":"neurobiology-of-decision-making","chapter":"3 Neurobiology of Decision-Making","heading":"3 Neurobiology of Decision-Making","text":"last chapter, used term prospect describe problem two options stated probabilities outcomes. experimental literature, prospects ‘description-based.’ Formally, researchers use description-based prospects experiments ask participants select one available options presented along complete description non-trivial problem.(Barron Erev 2003)looking towards neuroscientific literature decision-making, different type experimental paradigm perhaps common: ‘experiential’ ‘feedback-based’ decisions.(Barron Erev 2003). interacting environment, humans (animals) associate consequences different actions adapt behavior accordingly. words, learn. learn time want eat sushi dinner, ’s faster take highway work, ’re better go sleep midnight.3Looking towards animal learning field, see many accounts experiential learning. list :Thorndike’s Law Effect states animal’s behavior can modified consequences action.(Thorndike 1911)Thorndike’s Law Effect states animal’s behavior can modified consequences action.(Thorndike 1911)Classical (Pavlovian) conditioning details learning predict rewards punishments stimuli independent action-taken.(Pavlov 2010)Classical (Pavlovian) conditioning details learning predict rewards punishments stimuli independent action-taken.(Pavlov 2010)Operant (instrumental) conditioning involves learning rewards punishments contingent upon one’s actions.(B. F. Skinner 1938)Operant (instrumental) conditioning involves learning rewards punishments contingent upon one’s actions.(B. F. Skinner 1938)behavior (action decision) predicated upon prior experiences allows us formalize relationship states. , use state reference representation stimuli. example, state \\(s \\S\\) time \\(t\\) (\\(s_t\\)) may comprised internal states (hunger, thirst, fatigue) external ones (light, music, temperature).Consider Pavlov’s experiment showed repeatedly giving dog food ringing bell condition dog salivate bell rung.(Pavlov 2010) means , time, behavior elicited stimulus (food) can evoked – previously – neutral stimulus (bell). one first attempts empirically describe process, Bush Mosteller suggest probability Pavlov’s dog salivating, \\(P(\\text{sal})\\), next presentation food bell (next trial, \\(tr+1\\)) function happened last presentation (last trial, \\(tr-1\\)) discounted experienced presentation (food reward trial, \\(R_{tr}\\).(Bush Mosteller 1951a, 1951b)Equation (3.1) computes average previously experienced rewards. \\(0 \\leq \\alpha \\leq 1\\) learning rate, modulates influence recent rewards. Bush Mosteller’s work forms basis modern approaches problem reinforcement learning.(Glimcher 2011)4 discretizing learning trials logical first step modeling behavior experimental settings, ’s easily applied biological systems continuously interact environments.1988 paper, Learning Predict Methods Temporal Differences, Richard Sutton introduces antecedent temporal-difference reinforcement learning (TDRL) algorithms.(Sutton 1988) TDRL algorithm provides computational framework optimally learning experience actions associated stimuli lead rewards. (Richard S. Sutton; Andrew G. Barto 2018)‘goal’ TDRL algorithms estimate value state use information maximize rewards. achieved ‘teaching signal,’ called temporal-difference reward prediction error (TD-RPE), relates value state time \\(t\\) expected previously.current value state sum outcome experienced time \\(t\\) plus expectation future outcomes said state. expectation future values, \\(V(S_{t+1})\\) modulated temporal-discounting parameter \\(0 \\leq \\gamma \\leq 1\\) can preferentially weight immediate outcomes relative future ones.total, Equation (3.2) shows TD-RPE, \\(\\delta_t\\), difference current value state recent expectation state’s value, \\(V(S_t)\\). time step, \\(\\delta_t\\) used update estimated value current state formulated (3.3). , \\(0 \\leq \\alpha \\leq 1\\) learning rate controls much weight individual places estimated value current state light TD-RPE.1990s, Read Montague, Peter Dayan, colleagues show evidence suggesting TD-RPEs reflected fluctuations activity mesencephalic dopaminergic neurons.(P. Montague, Dayan, Sejnowski 1996; W. Schultz, Dayan, Montague 1997a) TD-RPE hypothesis dopamine neurons consistent behavioral neural results rodents, (Hart et al. 2014) non-human primates, (Tomas Ljunberg, Paul Apicella, Wolfram Schultz 1992; W. Schultz, Apicella, Ljungberg 1993; W. Schultz, Tremblay, Hollerman 1998; Bayer Glimcher 2005a) humans.(Zaghloul et al. 2009; Kishida et al. 2011; Moran et al. 2018; Bang et al. 2020) biologically conserved mechanism experiential learning, can investigate neural basis choice behavior empirically TDRL algorithms. 2011, experiments saw exciting development Ken Kishida colleagues used fast-scan cyclic voltammetry measure dopamine fluctuations human striatum sub-second temporal resolution. (Kishida et al. 2011)combination 2016 paper, Kishida colleagues studied dopamine levels humans undergoing elective surgery part deep-brain stimulation treatment.(Kishida et al. 2011, 2016) Participants viewed graphical depiction (fictitous) stock market’s price history (Figure 3.1; B) asked choose much portfolio (initially valued $100) invest. six ‘markets,’ twenty-decisions, participants used handheld button boxes (Figure 3.1; ) increase decrease investment ten-percent increments. Decision made dopamine recorded striatum light three pieces information:history market price (Figure 3.1; red-trace panel B)current portfolio value (Figure 3.1; bottom left box, 126, panel B)recent fractional change portfolio value (Figure 3.1; bottom right box, 15.2%, panel B).\nFigure 3.1: () Participants played sequential-choice game surgery using button boxes (Left) visual display (Right). patient, bet size adjustments (e.g., increase bet decrease bet) decision submit one’s answer performed button boxes. (B) Investment game (19, 21): participants view graphical depiction market price history (red trace), current portfolio value (bottom left box), recent outcome (bottom right box) decide submit investment decisions (bets) using slider bar 10% increments (bottom center). Bet sizes limited 0–100% (10% increments) participant’s portfolio—shorting market allowed. experiment, participant played 6 markets 20 decisions made per market. (C) Timeline events single round investment game.Reprinted permission Kishida et al., 2016.\n2011 paper, asked one person, MH, complete sequential investment task. line prior work relating dopamine unexpected financial outcomes (Zaghloul et al. 2009), Kishida colleagues observed strong correlation MH’s dopamine levels market value investment task.(Kishida et al. 2011) 2016, Kishida colleagues published results seventeen humans. , explicitly tested hypothesis fluctuations dopamine released human striatum encode TD-RPEs.(Kishida et al. 2016) sequential investment task, RPEs calculated difference investment’s return given trial relative expectation defined average return preceding trials.Contrary hypothesis dopamine fluctuations striatum track TD-RPEs,(P. R. Montague, Hyman, Cohen 2004; P. Montague, Dayan, Sejnowski 1996; W. Schultz, Dayan, Montague 1997b; Bayer Glimcher 2005b; Hart et al. 2014; Roesch, Calu, Schoenbaum 2007) authors found dopamine fluctuations encode integration RPEs counterfactual prediction errors (CPEs). discussed last chapter, counterfactual signals explicit comparison present state alternative ones.(Neal J. Roese 1997; Liu et al. 2016) sequential investment task, CPEs defined difference participant’s actual return trial invested less. means dopamine release result integration RPEs CPEs given trial. Formally:\\(b_{tr}\\) individual’s factional investment trial \\(tr\\) \\(r_{tr}\\) relative change market price. Kishida colleagues note, intuition Equation (3.4) better--expected outcomes (positive RPEs, increased dopamine release), even better (positive CPEs) reduced value. Similarly, worse--expected outcomes (negative RPEs, decreased dopamine release), even worse (negative CPEs) increased value. Importantly, empirical terms consistent subjective feelings (e.g., regret relief), one experiences light given outcome.Figure 3.2 depicts changes dopamine levels function bet size. Consider ‘higher bets’ panel (left) individuals bet close maximum amount possible. rewarded positive change portfolio value, dopamine concentrations increased (green; positive RPEs). Similarly, portfolio value decreased, dopamine levels dipped (red; negative RPEs). high bets, difference earned earned bet minimal, CPE. medium bets (middle panel), however, difference individuals experienced experienced bet increases. means absolute magnitude CPE goes subtracts dopamine release predicted positive negative RPEs. CPEs maximal (small bets; right panel), observe inversion dopamine release response positive negative RPEs.\nFigure 3.2: RPE encoding dopamine transients invert function bet size. Dopamine responses equal absolute magnitude positive negative RPEs (−0.75 > RPE > +0.75) bets high (higher bets, 100–90%) (Left), medium (medium bets, 80–60%) (Center), low (lower bets, 50–10%) (Right). three plots, mean normalized dopamine responses (±SEM) positive RPEs (green traces) negative RPEs (red traces). Inset legends show sample sizes event types. Two-way ANOVA (RPE-sign time: 700 ms following including outcome reveal) reveals significant difference comparing dopamine responses positive negative RPEs following higher bets [FRPE-sign(1,7) = 21.17, P = 0.00] lower bets [FRPE-sign(1,7) = 32.64, P = 0.00] medium bet sizes [FRPE-sign(1,7) = 0.15, P = 0.6957]. Asterisks indicate significant difference red green traces: P < 0.05, post hoc, two-sample t test following ANOVA time RPE-sign two main factors. Asterisks parentheses indicate Bonferroni correction multiple comparisons. low bets (.e., large CPEs), events market price change RPE-sign considered. Horizontal axis: time (ms) outcome reveal (blue arrowhead); vertical axis: mean change normalized dopamine response.Reprinted permission Kishida et al., 2016.\n‘superposed error signals actual counterfactual reward’ described Kishida colleagues’ paper(Kishida et al. 2016) directly inspired thesis work. provide empirical, neurobiologically plausible framework investigating decision-making risk. theoretical quantitative underpinnings classical behavioral economic theories decision-making align well computational reinforcement learning literature described chapter. explicit probability outcome structure risky prospects afford opportunity internalize future states (potentially) incorporate anticipated counterfactual events decision-making process. next chapter, derive ‘Counterfactual Predicted Utility Theory’ new theory decision-making risk.","code":""},{"path":"counterfactual-predicted-utility-theory.html","id":"counterfactual-predicted-utility-theory","chapter":"4 Counterfactual Predicted Utility Theory","heading":"4 Counterfactual Predicted Utility Theory","text":"discussed last chapter, neurotransmitter dopamine seemingly encodes information actual counterfactual rewards,(Kishida et al. 2016) integration may play guiding role decision-making. neural evidence, combined behavioral economic theories offering descriptive models people making risky decisions,(Kahneman Tversky 1979; Loomes Sugden 1982) propose ‘Counterfactual Predicted Utility Theory’ (CPUT) neurobiologically-plausible theory decision-making risk.intuition behind CPUT idea people account counterfactual outcomes faced prospect integration factual counterfactual signals brain may discount invert preference choosing one option another. hypothesize preference-reversal modulated counterfactual weighting term, \\(\\gamma\\), may vary across people.formally derive CPUT, can revisit prospect introduced first chapter hypothetical casino game. two options: choosing one certainly three-thousand dollars; choosing another give 80% chance four-thousand dollars nothing. prospect commonly denoted follows first option leads outcome \\(x_1\\) probability \\(p_1\\) second option leads outcomes \\(x_2\\) probability \\(p_2\\).Unless otherwise stated, alternative outcomes option assumed zero. , choosing Option 1 choice receiving \\(x_1\\) probability \\(p_1\\) nothing probability \\((1 - p_1)\\). explicit, generalizable, representation prospect can seen Figure 4.1. , Option 1 choice receiving \\(x_{1a}\\) probability \\(p_1\\) \\(x_{1b}\\) probability \\((1 - p_1)\\). Similarly, Option 2 choice receiving \\(x_{2a}\\) probability \\(p_2\\) \\(x_{2b}\\) probability \\((1 - p_2)\\).\nFigure 4.1: Explicit representation prospect two options. Choosing option 1 may lead outcome \\(x_{1a}\\) probability \\(p_1\\) outcome \\(x_{1b}\\) probability \\((1 - p_1)\\). Choosing option 2 may lead outcome \\(x_{2a}\\) probability \\(p_2\\) outcome \\(x_{2b}\\) probability \\((1 - p_2)\\).\nrepresentation, can begin formally define option’s counterfactual utility, \\(U_C\\), follows:Expected Utility Theory, option’s utility expected value transformed value. expected utility definition Equation (4.3) represents weighting Equation (4.2). difference stems estimated counterfactual utility value, \\(V_C\\) compares estimated expected utility value, \\(V_E\\).EUT, prospect theory, transformation stated outcome exponentiated risk-aversion parameter, \\(\\rho\\). Conversely, CPUT, define transformation stated outcome face value minus weighted sum option’s alternative outcome option’s expected value. transformations theory presented Equation (4.4), shows prospect form depicted Figure 4.1 represented.Unlike estimated expected utility value, \\(V_E\\), estimated counterfactual utility value, \\(V_C\\) one--one mapping stated outcomes. provide better intuition within- -option dependency, helpful consider concrete example. adapting Figure 4.1 include values casino example initially described, can better see possible outcome may integrate evaluating given prospect.\nFigure 4.2: Example prospect diagram visualize counterfactual integration. Choosing option 1 may lead outcome \\(\\$3000\\) probability \\(1.0\\) outcome \\(\\$0\\) probability \\((1 - 1.0)\\). Choosing option 2 may lead outcome \\(\\$4000\\) probability \\(0.8\\) outcome \\(\\$0\\) probability \\((1 - 0.8)\\). Estimating counterfactual utility value possible outcomes dependent one-another.\nillustrate CPUT walking-Figure 4.2, let’s assume counterfactual-weighting term \\(\\gamma = 0.1\\). means stated outcomes transformed given available counterfactual information potential outcome follows:values combined Equation (4.2), see \\(U_C(\\text{Option 2}) > U_C(\\text{Option 1})\\):maximize utility, choose Option 2 progress diagram first node right-hand side. , forwent opportunity Option 1. chose differently, reached node left, expected value $3000, didn’t. current position, 80% chance find red node, $4000. proverbial coin-flip goes , however, find cyan node nothing show . walking-example, hoped convey possible outcomes relate one-another factual counterfactual information may integrated inform one’s decision.Importantly, equations suggest \\(\\gamma = 0\\), one places weight counterfactual events, counterfactual utility equivalent expected value. words, \\(\\gamma = 0\\), \\(U_C(\\text{Option 1}) = EV(\\text{Option 1})\\) \\(U_C(\\text{Option 2}) = EV(\\text{Option 2})\\). people don’t place weight counterfactual information, might expect choice behavior consistent maximizing expected value (, better compare theories decision-making, maximizing expected utility). provide evidence support CPUT generative theory decision-making, test hypothesis \\(\\gamma > 0\\) means people consider counterfactual outcomes faced risky prospect. , use choice data ‘Sure Bet Gamble’ task.","code":""},{"path":"computational-modeling-concepts.html","id":"computational-modeling-concepts","chapter":"5 Computational Modeling Concepts","heading":"5 Computational Modeling Concepts","text":"last chapter, addressed first thesis aim developing counterfactual predicted utility theory (CPUT) alternative expected utility theory explain decision-making risk. showed information potential outcome (terminal node Figure 4.1) integrates counterfactual weighting parameter, \\(\\gamma\\), adjust utility one option another. walked-example calculation assuming \\(\\gamma = 0.1\\) (diagrammed Figure 4.1). chapter, begin address second thesis aim assessing predictive accuracy CPUT using human choice data ‘Sure Bet Gamble’ task.(B. Liebenow et al. 2021)attempt robustly, transparently, fit CPUT behavioral data, follow general guidelines presented Robert Wilson Anne Collins’s paper Ten simple rules computational modeling behavioral data.(Wilson Collins 2019)high level, state computational modeling allows us make better sense behavioral data mathematical models may provide insight mechanisms underlying behavior. Although exact form models differ, basic steps assess model’s descriptive predictive efficacy similar.first two steps Wilson Collins discuss designing experiment developing model. thesis, fit CPUT, formulated last chapter, data collected ongoing study Brittany Liebenow colleagues(B. Liebenow et al. 2021) forty-five healthy adults (ages 18-65) recruited complete sure-bet gamble task (Figure 5.1).\nFigure 5.1: Schematic trial Sure Bet Gamble task subjective rating prompt.\nthirty minutes, participants indicated preference sure bet (values $1-$6 $1 increments) fifty-fifty gamble two non-identical values ($0 - $6 $1 increments). lateral presentation sure bet gambles randomized, prospect presented random duration based Poisson distribution \\((\\lambda = 6\\text{s})\\). participant answered within alloted time, choice displayed two seconds shown outcome one second. answer time, shown late screen one second. Rounds separated fixation cross whose inter-trial interval Poisson distribution \\((\\lambda = 6\\text{s}\\), zeros removed\\()\\). -third rounds choices made, respondents asked “feel last outcome?” adjusted slider ranging ‘bad’ ‘good.’ Participants paid $20 per hour told receive winnings randomly selected round bonus compensation.Using data task, can group remaining computational modeling steps three stages:(Wilson Collins 2019)Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Simulation & Parameter Recovery: Use candidate model (CPUT) generate ‘fake’ behavioral data attempt recover parameters interest following proposed analysis method experimental data.Parameter Estimation: Find set parameters best account experimental data given candidate model.Parameter Estimation: Find set parameters best account experimental data given candidate model.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.Model Comparison: Compare candidate models others (EUT) may provide alternative explanations behavioral data.detailing methods results stage analysis, important understand mathematics behind model-fitting. general case, estimating model’s parameters decision-making task, want know parameter(s) best explain observed choices. tasks two outcomes, can represented binary choice vector choice option indicated 1 chosen 0 .Consider prospect depicted Figure 5.1. Given stated outcomes probabilities, can calculate counterfactual utilities option \\(\\gamma\\) value according Equations (4.2) (4.4). \\(0 \\leq \\gamma \\leq 0.5\\), can see utilities sure bet option ($3) gamble (50% chance $2 $5) Figure 5.2). , might assume people place low weight counterfactual information often choose gamble. point (\\(\\gamma \\approx 0.16\\)), individual equally likely choose either option. people place weight counterfactual information, likely choose sure bet prospect.\nFigure 5.2: Counterfactual utilities sample prospect sure bet gamble task simulated \\(0 \\leq \\gamma \\leq 0.5\\). Blue line represents counterfactual utility choosing ‘Sure Bet’ receiving three dollars; red line represents counterfactual utility choosing ‘Gamble’ 50% chance receiving two dollars five dollars. ‘indifference’ point choosing one option occurs \\(\\gamma \\approx 0.16\\)\nAlthough can determine utility option, peoples’ choice behavior fit model. means need determine likely parameter value give us observed data. help answer question, looked towards Bayesian statistics, offers way incorporate prior information parameters statistical model observed data define posterior probability distribution representing plausible parameter values.5The first step performing Bayesian inference construct prior probability model parameters interest. end fitting multiple models (e.g., perform model comparison), outline procedure general case using \\(\\theta\\) represent given model’s parameters. prior probability model, \\(\\pi(\\theta)\\) contains available information parameter’s distribution observing data. information come , example, previous experiments. information available, might assume uniform prior distribution, assigns equal probability values within defined range.next step Bayesian inference involves calculating likelihood observing data given set parameters, \\(\\theta\\). analysis, focused likelihood individual chose Option 1 (sure bet), represent follows:translate binary choice behavior likelihood, need way relating option’s utilities probability. can done softmax choice rule, logistic transformation difference utilities option:(Sokol-Hessner et al. 2009)\\(U_1, U_2\\) utilities (according proposed model CPUT EUT), \\(\\tau > 0\\) sensitivity parameter relates sensitive one’s choice difference utilities. complement Figure 5.2, can see probability choosing sure bet changes \\(\\gamma\\) (subsequently utility Option 1) increases:\nFigure 5.3: Probability choosing Option 1 (‘Sure Bet’) calculated logistic transformation difference utilities counterfactual utilities option shown Figure 5.2 across \\(0 \\leq \\gamma \\leq 0.5\\). \\(\\tau\\) increases, individuals likely maximize utility. Note ‘indifference’ point choosing one option occurs \\(\\gamma \\approx 0.16\\), regardless \\(\\tau\\).\nthird step Bayesian inference generate posterior distribution, \\(Pr(\\theta|\\text{Choices})\\), represents range likely range parameter values given observed choices. terms analysis, posterior distribution defined follows:probability \\(\\theta\\) value given observed choice data, posterior distribution \\(Pr(\\theta|\\text{Choices})\\), proportional to6 likelihood observing data given parameter value, \\(L(\\text{Chose Option 1}|\\theta)\\), times prior plausibility parameter value, \\(\\pi(\\theta)\\).estimate posterior distribution, used two ‘Markov Chain Monte Carlo’ methods. first attempt, manually implemented Metropolis-Hastings algorithm.(Haines 2018; Dogucu 2022) high level, Metropolis-Hastings algorithm involves following steps:iteration \\(n \\1:N\\) following:Propose value, \\(\\theta_n^*\\) near current estimate \\(\\theta_n\\), propose value \\(\\theta^*\\)Calculate acceptance probability proposal \\(\\theta_n^*\\) defined ratio posterior distribution evaluated \\(\\theta_n^*\\) \\(\\theta_n\\)Draw random number zero one. less equal acceptance probability, set \\(\\theta_{n+1} = \\theta_n^*\\), otherwise \\(\\theta_{n+1} = \\theta_n\\).validated implementation comparing posterior distributions computed hierarchical Bayesian approach. Hierarchical Bayesian Analysis implemented probabilistic programming language, Stan, implements efficient variant Markov Chain Monte Carlo called Hamiltonian Monte Carlo sampler.(Stan Development Team 2022) Hierarchical Bayesian Analysis allows simultaneous estimation individual group-level parameters mutually-constraining fashion. shown improve parameter estimates relative methods (e.g., maximum likelihood estimation), resulting stable reliable estimates individual-level parameters informed group trends.(Ahn et al. 2011)specific implementation hierarchical models follow detailed elsewhere.(Ahn, Haines, Zhang 2017) high level, individual-participant parameters assumed drawn normally distributed group-level distributions. Bounded parameters, \\(\\gamma\\), estimated unconstrained space transformed ‘Matt Trick,’(Stan Development Team 2022) inverse Probit transformation. optimize MCMC sampling.(Ahn, Haines, Zhang 2017) formally,\\(- \\infty < \\mu_\\theta < + \\infty\\) \\(- \\infty < \\sigma_\\theta < + \\infty\\) group-level mean standard deviation, respectively; \\(\\theta^\\prime\\) unconstrained parameter gets transformed via inverse Probit transformation scaled upper bound, \\(U.B\\). example, \\(\\gamma\\), \\(U.B. = 1\\); \\(\\tau\\), \\(U.B. = 30\\). non-centered reparameterization results uniform prior individual participants’ parameters across full range.(Ahn et al. 2014; Ahn, Haines, Zhang 2017)better grasp concepts employed thesis, ’s time revisit three stages computational modeling introduced chapter introduction. (Wilson Collins 2019) next chapter, outline methods results simulating choice data according counterfactual predicted utility theory, estimating parameters observed data, comparing evidence seven candidate models.","code":""},{"path":"modeling-methods-and-results.html","id":"modeling-methods-and-results","chapter":"6 Modeling Methods and Results","heading":"6 Modeling Methods and Results","text":"Using computational modeling techniques introduced last chapter, examined ability counterfactual predicted utility theory explain human choice behavior sure bet gamble task(B. Liebenow et al. 2021). , first simulated choice behavior generated counterfactual predicted utility theory confirm experimental design elicits behaviors assumed model.(Wilson Collins 2019) confirmation, fit variations counterfactual predicted utility theory without risk-aversion parameter expected utility theory counterfactual predicted utility theory task able relative veracity counterfactual predicted utility theory generative theory decision-making risk. comparing modeFirst explicit simulation parameter recovery. order determine whether sure bet gamble task capture parameters interest, simulated fifty subjects","code":""},{"path":"modeling-methods-and-results.html","id":"simulating-choice-data","chapter":"6 Modeling Methods and Results","heading":"6.1 Simulating Choice Data","text":"first step simulate choice data sure-bet gamble task, looked results Kahneman Tversky’s prospect theory(Kahneman Tversky 1979) paper search information inform prior distribution. Although record subject’s response specific prospects, Kahneman Tversky report proportion people chose option. nine prospects follow form depicted Figures 4.1 4.2, used reported proportions simulate choice behavior one-hundred subjects.assumed \\(\\gamma\\) uniformly distributed zero one fixed softmax sensitivity parameter, \\(\\tau = 1\\). ran ten-thousand iterations using Metropolis-Hastings algorithm described previous chapter. posterior distribution, depicted Figure 6.1, approximates \\(\\text{Beta}(1.1,1.1)\\) distribution. means , estimating \\(\\gamma\\) choice proportion data Kahneman Tversky, ’s plausible \\(\\gamma\\) value zero one, though little less likely towards tails.\nFigure 6.1: Posterior distribution \\(\\gamma\\) estimated ten-thousand iterations Metropolis-Hastings algorithm assuming uniform prior choice proportion data Kahneman Tversyk’s prospect theory(Kahneman Tversky 1979). posterior distribution (orange-red line) approximated \\(\\text{Beta}(1.1,1.1)\\) distribution (blue-gray), indicating slightly less plausibility \\(\\gamma\\) values near bounds zero--one interval relative central values.\nGiven task design, participants saw random subset 252 prospects. posterior distribution \\(\\gamma\\) recovered Kahneman Tversky’s choice proportion data used generate \\(\\gamma\\) values fifty subjects. simulated choices 252 prospects, fixing softmax sensitivity parameter \\(\\tau = 1\\). five-thousand iterations Metropolis-Hastings algorithm, sampled posterior distribution simulated subject.7 simulated choice data, also fit hierarchical Bayesian model Stan non-centered reparameterization described last chapter. ran Hamiltonian Monte Carlo (Stan) sampler 5000 iterations across four parallel sampling chains total 20,000 samples posterior.8 Figure 6.2 shows 95% highest density interval recovered sampler’s posterior distribution.\nFigure 6.2: 95% highest density interval posterior distribution \\(\\gamma\\) estimated five-thousand iterations Metropolis-Hastings algorithm five-thousand iterations across four parallel chains Hamiltonian Monte Carlo Sampler (estimated using Stan(Stan Development Team 2022)). simulated gamma values subject represented sky-blue dots fall within 95% highest density interval red dots fall outside .\nsubjects, simulated \\(\\gamma\\) values within highest-density interval. suggests sure-bet gamble task able elicit behaviors interest way measurable counterfactual predicted utility theory.","code":""},{"path":"modeling-methods-and-results.html","id":"parameter-recovery","chapter":"6 Modeling Methods and Results","heading":"6.2 Parameter Recovery","text":"","code":""},{"path":"modeling-methods-and-results.html","id":"model-comparison","chapter":"6 Modeling Methods and Results","heading":"6.3 Model Comparison","text":"","code":""},{"path":"references.html","id":"references","chapter":"7 References","heading":"7 References","text":"","code":""}]
